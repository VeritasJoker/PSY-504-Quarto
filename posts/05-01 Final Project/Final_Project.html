<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.30">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="KW">
<meta name="dcterms.date" content="2025-05-03">

<title>Final Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="Final_Project_files/libs/clipboard/clipboard.min.js"></script>
<script src="Final_Project_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="Final_Project_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="Final_Project_files/libs/quarto-html/popper.min.js"></script>
<script src="Final_Project_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Final_Project_files/libs/quarto-html/anchor.min.js"></script>
<link href="Final_Project_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Final_Project_files/libs/quarto-html/quarto-syntax-highlighting-de070a7b0ab54f8780927367ac907214.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Final_Project_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Final_Project_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Final_Project_files/libs/bootstrap/bootstrap-83837c041b80f026fb76b1201b2b9e7e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#loading-packages-dataset" id="toc-loading-packages-dataset" class="nav-link active" data-scroll-target="#loading-packages-dataset">Loading Packages &amp; Dataset</a></li>
  <li><a href="#eda" id="toc-eda" class="nav-link" data-scroll-target="#eda">EDA</a></li>
  <li><a href="#embedding-extraction" id="toc-embedding-extraction" class="nav-link" data-scroll-target="#embedding-extraction">Embedding Extraction</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="../../../../../scratch/gpfs/kw1166/247/05-01 Final Project/Final_Project.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Final Project</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Princeton University</p>
  <div class="quarto-categories">
    <div class="quarto-category">code</div>
    <div class="quarto-category">analysis</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>KW </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 3, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<hr>
<p>This is a tutorial to perform binary classifications for the <a href="https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews/data">Amazon Reviews</a> dataset.</p>
<p>The Amazon reviews dataset consists of reviews from amazon. The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review. Here, we take review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 are ignored.</p>
<section id="loading-packages-dataset" class="level2">
<h2 class="anchored" data-anchor-id="loading-packages-dataset">Loading Packages &amp; Dataset</h2>
<div id="7b6f8b75" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># os</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># nlp</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># classification</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostClassifier, RandomForestClassifier</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.colors <span class="im">as</span> mcolors</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="6fca26fc" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.read_csv(<span class="st">"train.csv"</span>, header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.read_csv(<span class="st">"test.csv"</span>, header<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="eda" class="level2">
<h2 class="anchored" data-anchor-id="eda">EDA</h2>
<div id="6161c25a" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out NaNs</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>train_df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>test_df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Name the columns</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>train_df.columns <span class="op">=</span> [<span class="st">"rating"</span>, <span class="st">"title"</span>, <span class="st">"review"</span>]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>test_df.columns <span class="op">=</span> [<span class="st">"rating"</span>, <span class="st">"title"</span>, <span class="st">"review"</span>]</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Change the rating values to "positive" and "negative"</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"rating"</span>] <span class="op">=</span> train_df[<span class="st">"rating"</span>].<span class="bu">map</span>({<span class="dv">1</span>: <span class="st">"negative"</span>, <span class="dv">2</span>: <span class="st">"positive"</span>})</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"rating"</span>] <span class="op">=</span> test_df[<span class="st">"rating"</span>].<span class="bu">map</span>({<span class="dv">1</span>: <span class="st">"negative"</span>, <span class="dv">2</span>: <span class="st">"positive"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="131395fc" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Length of the data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(train_df))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(test_df))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>3599793
399976</code></pre>
</div>
</div>
<p>The data is too huge. To save computational resources, we are going to sample 1% of the data to analyze. All the methods should still work on the full dataset though.</p>
<div id="9aab4968" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample 1% of the data for each rating category</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>random_state <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> (</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    train_df.groupby(<span class="st">"rating"</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.sample(frac<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span>random_state))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> (</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    test_df.groupby(<span class="st">"rating"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.sample(frac<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span>random_state))</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshuffle the sampled data</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> train_df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span>random_state).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> test_df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span>random_state).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Just want to double check that the dataset is still balanced after sampling.</p>
<div id="d40f11ab" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the distribution of ratings</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>train_rating_counts <span class="op">=</span> train_df[<span class="st">"rating"</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>test_rating_counts <span class="op">=</span> test_df[<span class="st">"rating"</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame for plotting</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>rating_distribution <span class="op">=</span> pd.DataFrame(</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"Train"</span>: train_rating_counts, <span class="st">"Test"</span>: test_rating_counts}</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>).T</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the stacked bar plot</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>rating_distribution.plot(kind<span class="op">=</span><span class="st">"bar"</span>, stacked<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>[<span class="st">"#13bc05"</span>, <span class="st">"#ff5733"</span>])</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribution of Ratings (Train vs Test)"</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Dataset"</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Proportion"</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">"Rating"</span>, labels<span class="op">=</span>[<span class="st">"Positive"</span>, <span class="st">"Negative"</span>])</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Final_Project_files/figure-html/cell-7-output-1.png" class="figure-img" width="663" height="395"></p>
</figure>
</div>
</div>
</div>
<p>Here are some example reviews from the sampled data:</p>
<p>::: {#4c36fd14 .cell execution_count=7} ``` {.python .cell-code} print(train_df.head())</p>
<p>#Example of a negative review print(train_df.loc[0,“review”][:500])</p>
<p>#Example of a positive review print(train_df.loc[1,“review”][:500]) ```</p>
<p>::: {.cell-output .cell-output-stdout} ``` rating title<br>
0 positive Give it as a gift<br>
1 negative Prevention pillbox disappointment<br>
2 negative Disappointing<br>
3 positive Why… did they discontinue this?<br>
4 negative booo john woo. zero stars for you</p>
<pre><code>                                           review  </code></pre>
<p>0 For fourteen years I’ve given this book as a g…<br>
1 I just bought this pillbox/timer so I would no…<br>
2 I enjoy novels set in 19th century England and…<br>
3 I find this fragrance irresistable. My husband…<br>
4 What’s worse than making a really bad movie is…<br>
For fourteen years I’ve given this book as a gift when friends lose loved ones. This is not an intense read, and very comforting. There is something for everyone. I just bought this pillbox/timer so I would not forget to take my pills anymore, unfortunately the alarm did not work. It kept good time, but the alarm never went off. It has a warranty, however you have to send a check for $3.95 to cover shipping &amp; handling, and to send it back I would have to pay another $5.00 so I rather take this one as a loss, and spend that money to buy another brand. Very disappointed. ``` ::: :::</p>
<p>Makes sense! Let’s get to the modeling.</p>
</section>
<section id="embedding-extraction" class="level2">
<h2 class="anchored" data-anchor-id="embedding-extraction">Embedding Extraction</h2>
<p>Let’s first extract features, in this case embeddings, which are internal activations of Large Language Models (LLMs). LLMs relies on the Transformer architecture to sculpt the embedding of a given word based on the surrounding context. The model is composed of a repeated circuit motif—called the “attention head” — by which the model can “attend” to surrounding words in the context window when determining the meaning of the current word.</p>
<p>Here we use a model named <a href="https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L3-v2">paraphrase-MiniLM-L3-v2</a>. This is a really small model (relative to the other current LLMs) with about 61 million parameters. It is composed of 3 layers, each of which contains each of which contains 12 attention heads that influence the embedding as it proceeds to the subsequent layer. The embeddings at each layer of the model comprise 384 features and the context window includes the surrounding 512 tokens.</p>
<p>Note that usually we get word embeddings from the LLMs. To simply things, here we directly gets a 768 dimension vector for the whole sentence or paragraph, using the <a href="https://sbert.net/index.html">sentence transformer</a> library.</p>
<p>To access this model, we have to register an account on Huggingface and get an access token. If you are curious, <a href="https://huggingface.co/docs/hub/en/security-tokens">this page</a> are more information about it. Here, we store the access token in a <code>.env</code> file under the variable <code>HUG_KEY</code> and load it through the <code>dotenv</code> package.</p>
<div id="afff5e36" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>load_dotenv()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SentenceTransformer(</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"paraphrase-MiniLM-L3-v2"</span>, use_auth_token<span class="op">=</span>os.environ[<span class="st">"HUG_KEY"</span>]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now that we loaded the model, we are going to generate three types of embeddings. First, we use the titles of the reviews to generate embeddings, which we call <code>title_emb</code>. Second, we use the full reviews to generate embeddings, which we call <code>review_emb</code>. Note that if a review is longer than 514 words, then model will only use the first 514 words. One way to improve this is to seperate the full reviews into sentences, generate embeddings for each sentence, and then average the sentence embeddings. This we call <code>sent_emb</code>.</p>
<p>We first look at what <code>sent_tokenize</code> from the <code>nltk</code> package does:</p>
<div id="05e0ca0a" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of a negative review</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_df.loc[<span class="dv">0</span>, <span class="st">"review"</span>][:<span class="dv">500</span>])</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Sentence tokenizer</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>nltk.sent_tokenize(train_df.loc[<span class="dv">0</span>, <span class="st">"review"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>For fourteen years I've given this book as a gift when friends lose loved ones. This is not an intense read, and very comforting. There is something for everyone.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>["For fourteen years I've given this book as a gift when friends lose loved ones.",
 'This is not an intense read, and very comforting.',
 'There is something for everyone.']</code></pre>
</div>
</div>
<p>Now we will define the functions for embedding extractions and extract the three types of embeddings.</p>
<div id="8daabf26" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> full_text_emb(model, text):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> model.encode(text, show_progress_bar<span class="op">=</span><span class="va">True</span>)  <span class="co"># encode the full text</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> emb</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sent_text_emb(model, text):</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    sent_text <span class="op">=</span> nltk.sent_tokenize(text)  <span class="co"># tokenize the text into sentences</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> model.encode(sent_text, show_progress_bar<span class="op">=</span><span class="va">True</span>)  <span class="co"># batch encode</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> np.mean(emb, axis<span class="op">=</span><span class="dv">0</span>).shape  <span class="co"># mean of the sentence embeddings</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> emb</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract embeddings</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"title_emb"</span>] <span class="op">=</span> train_df[<span class="st">"title"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"review_emb"</span>] <span class="op">=</span> train_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"sent_emb"</span>] <span class="op">=</span> train_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: sent_text_emb(model, x))</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"title_emb"</span>] <span class="op">=</span> test_df[<span class="st">"title"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"review_emb"</span>] <span class="op">=</span> test_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"sent_emb"</span>] <span class="op">=</span> test_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: sent_text_emb(model, x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Because we have so much data, generating embeddings still takes a lot of computational resources even after the 1% sampling. Thus, we are just going to load the already generated <code>title_emb</code> and <code>review_emb</code> here and ignore <code>sent_emb</code> for now. If you are interested, here is the <a href="">script</a> we used to batch the input and speed up the embedding extraction process.</p>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb14" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Final Project"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Princeton University"</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2025-05-03"</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "KW"</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [code, analysis]</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">    self-contained: false</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">    anchor-sections: true</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-width: 8</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-height: 4</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co">    code-block-bg: "#f1f3f5"</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co">    code-block-border-left: "#31BAE9"</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="co">    mainfont: Source Sans Pro</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: journal</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-location: left</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co">    captions: true</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co">    cap-location: margin</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="co">    table-captions: true</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="co">    tbl-cap-location: margin</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co">    reference-location: margin</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="co">  pdf:</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="co">    pdf-engine: lualatex</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: false</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="co">    number-depth: 2</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="co">    top-level-division: section</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="co">    reference-location: document</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="co">    listings: false</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="co">    header-includes:</span></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="co">      \usepackage{marginnote, here, relsize, needspace, setspace}</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="co">      \def\it{\emph}</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a><span class="co">  freeze: auto</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="co">  message: false</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="co">  fig-align: center</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a><span class="co">  fig-width: 12</span></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a><span class="co">  fig-height: 8</span></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a><span class="co">  editor_options: </span></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a><span class="co">  chunk_output_type: inline</span></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a><span class="co">  code-overflow: wrap</span></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> visual</span></span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>This is a tutorial to perform binary classifications for the <span class="co">[</span><span class="ot">Amazon Reviews</span><span class="co">](https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews/data)</span> dataset.</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>The Amazon reviews dataset consists of reviews from amazon. The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review. Here, we take review score 1 and 2 as negative, and 4 and 5 as positive. Samples of score 3 are ignored.</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a><span class="fu">## Loading Packages &amp; Dataset</span></span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a><span class="in">```{python, warning=FALSE}</span></span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a><span class="co"># os</span></span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a><span class="co"># nlp</span></span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a><span class="co"># classification</span></span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostClassifier, RandomForestClassifier</span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting</span></span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.colors <span class="im">as</span> mcolors</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.read_csv(<span class="st">"train.csv"</span>, header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.read_csv(<span class="st">"test.csv"</span>, header<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a><span class="fu">## EDA</span></span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out NaNs</span></span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a>train_df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a>test_df.dropna(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Name the columns</span></span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a>train_df.columns <span class="op">=</span> [<span class="st">"rating"</span>, <span class="st">"title"</span>, <span class="st">"review"</span>]</span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a>test_df.columns <span class="op">=</span> [<span class="st">"rating"</span>, <span class="st">"title"</span>, <span class="st">"review"</span>]</span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Change the rating values to "positive" and "negative"</span></span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"rating"</span>] <span class="op">=</span> train_df[<span class="st">"rating"</span>].<span class="bu">map</span>({<span class="dv">1</span>: <span class="st">"negative"</span>, <span class="dv">2</span>: <span class="st">"positive"</span>})</span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"rating"</span>] <span class="op">=</span> test_df[<span class="st">"rating"</span>].<span class="bu">map</span>({<span class="dv">1</span>: <span class="st">"negative"</span>, <span class="dv">2</span>: <span class="st">"positive"</span>})</span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a><span class="co"># Length of the data</span></span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(train_df))</span>
<span id="cb14-118"><a href="#cb14-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(test_df))</span>
<span id="cb14-119"><a href="#cb14-119" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-120"><a href="#cb14-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-121"><a href="#cb14-121" aria-hidden="true" tabindex="-1"></a>The data is too huge. To save computational resources, we are going to sample 1% of the data to analyze. All the methods should still work on the full dataset though.</span>
<span id="cb14-122"><a href="#cb14-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-125"><a href="#cb14-125" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-126"><a href="#cb14-126" aria-hidden="true" tabindex="-1"></a><span class="co"># | warning: false</span></span>
<span id="cb14-127"><a href="#cb14-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-128"><a href="#cb14-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample 1% of the data for each rating category</span></span>
<span id="cb14-129"><a href="#cb14-129" aria-hidden="true" tabindex="-1"></a>random_state <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb14-130"><a href="#cb14-130" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> (</span>
<span id="cb14-131"><a href="#cb14-131" aria-hidden="true" tabindex="-1"></a>    train_df.groupby(<span class="st">"rating"</span>)</span>
<span id="cb14-132"><a href="#cb14-132" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.sample(frac<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span>random_state))</span>
<span id="cb14-133"><a href="#cb14-133" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-134"><a href="#cb14-134" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-135"><a href="#cb14-135" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> (</span>
<span id="cb14-136"><a href="#cb14-136" aria-hidden="true" tabindex="-1"></a>    test_df.groupby(<span class="st">"rating"</span>)</span>
<span id="cb14-137"><a href="#cb14-137" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.sample(frac<span class="op">=</span><span class="fl">0.01</span>, random_state<span class="op">=</span>random_state))</span>
<span id="cb14-138"><a href="#cb14-138" aria-hidden="true" tabindex="-1"></a>    .reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-139"><a href="#cb14-139" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-140"><a href="#cb14-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-141"><a href="#cb14-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshuffle the sampled data</span></span>
<span id="cb14-142"><a href="#cb14-142" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> train_df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span>random_state).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-143"><a href="#cb14-143" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> test_df.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span>random_state).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-144"><a href="#cb14-144" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-145"><a href="#cb14-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-146"><a href="#cb14-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-147"><a href="#cb14-147" aria-hidden="true" tabindex="-1"></a>Just want to double check that the dataset is still balanced after sampling.</span>
<span id="cb14-148"><a href="#cb14-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-151"><a href="#cb14-151" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-152"><a href="#cb14-152" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the distribution of ratings</span></span>
<span id="cb14-153"><a href="#cb14-153" aria-hidden="true" tabindex="-1"></a>train_rating_counts <span class="op">=</span> train_df[<span class="st">"rating"</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-154"><a href="#cb14-154" aria-hidden="true" tabindex="-1"></a>test_rating_counts <span class="op">=</span> test_df[<span class="st">"rating"</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-155"><a href="#cb14-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-156"><a href="#cb14-156" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame for plotting</span></span>
<span id="cb14-157"><a href="#cb14-157" aria-hidden="true" tabindex="-1"></a>rating_distribution <span class="op">=</span> pd.DataFrame(</span>
<span id="cb14-158"><a href="#cb14-158" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"Train"</span>: train_rating_counts, <span class="st">"Test"</span>: test_rating_counts}</span>
<span id="cb14-159"><a href="#cb14-159" aria-hidden="true" tabindex="-1"></a>).T</span>
<span id="cb14-160"><a href="#cb14-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-161"><a href="#cb14-161" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the stacked bar plot</span></span>
<span id="cb14-162"><a href="#cb14-162" aria-hidden="true" tabindex="-1"></a>rating_distribution.plot(kind<span class="op">=</span><span class="st">"bar"</span>, stacked<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>[<span class="st">"#13bc05"</span>, <span class="st">"#ff5733"</span>])</span>
<span id="cb14-163"><a href="#cb14-163" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Distribution of Ratings (Train vs Test)"</span>)</span>
<span id="cb14-164"><a href="#cb14-164" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Dataset"</span>)</span>
<span id="cb14-165"><a href="#cb14-165" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Proportion"</span>)</span>
<span id="cb14-166"><a href="#cb14-166" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">"Rating"</span>, labels<span class="op">=</span>[<span class="st">"Positive"</span>, <span class="st">"Negative"</span>])</span>
<span id="cb14-167"><a href="#cb14-167" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-168"><a href="#cb14-168" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-169"><a href="#cb14-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-170"><a href="#cb14-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-171"><a href="#cb14-171" aria-hidden="true" tabindex="-1"></a>Here are some example reviews from the sampled data:</span>
<span id="cb14-172"><a href="#cb14-172" aria-hidden="true" tabindex="-1"></a> <span class="in">```{python}</span></span>
<span id="cb14-173"><a href="#cb14-173" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_df.head())</span>
<span id="cb14-174"><a href="#cb14-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-175"><a href="#cb14-175" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of a negative review</span></span>
<span id="cb14-176"><a href="#cb14-176" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_df.loc[<span class="dv">0</span>, <span class="st">"review"</span>][:<span class="dv">500</span>])</span>
<span id="cb14-177"><a href="#cb14-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-178"><a href="#cb14-178" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of a positive review</span></span>
<span id="cb14-179"><a href="#cb14-179" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_df.loc[<span class="dv">1</span>, <span class="st">"review"</span>][:<span class="dv">500</span>])</span>
<span id="cb14-180"><a href="#cb14-180" aria-hidden="true" tabindex="-1"></a> <span class="in">```</span></span>
<span id="cb14-181"><a href="#cb14-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-182"><a href="#cb14-182" aria-hidden="true" tabindex="-1"></a>Makes sense! Let's get to the modeling.</span>
<span id="cb14-183"><a href="#cb14-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-184"><a href="#cb14-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-185"><a href="#cb14-185" aria-hidden="true" tabindex="-1"></a><span class="fu">## Embedding Extraction</span></span>
<span id="cb14-186"><a href="#cb14-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-187"><a href="#cb14-187" aria-hidden="true" tabindex="-1"></a>Let's first extract features, in this case embeddings, which are internal activations of Large Language Models (LLMs). LLMs relies on the Transformer architecture to sculpt the embedding of a given word based on the surrounding context. The model is composed of a repeated circuit motif—called the "attention head" — by which the model can "attend" to surrounding words in the context window when determining the meaning of the current word. </span>
<span id="cb14-188"><a href="#cb14-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-189"><a href="#cb14-189" aria-hidden="true" tabindex="-1"></a>Here we use a model named <span class="co">[</span><span class="ot">paraphrase-MiniLM-L3-v2</span><span class="co">](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L3-v2)</span>. This is a really small model (relative to the other current LLMs) with about 61 million parameters. It is composed of 3 layers, each of which contains each of which contains 12 attention heads that influence the embedding as it proceeds to the subsequent layer. The embeddings at each layer of the model comprise 384 features and the context window includes the surrounding 512 tokens. </span>
<span id="cb14-190"><a href="#cb14-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-191"><a href="#cb14-191" aria-hidden="true" tabindex="-1"></a>Note that usually we get word embeddings from the LLMs. To simply things, here we directly gets a 768 dimension vector for the whole sentence or paragraph, using the <span class="co">[</span><span class="ot">sentence transformer</span><span class="co">](https://sbert.net/index.html)</span> library.</span>
<span id="cb14-192"><a href="#cb14-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-193"><a href="#cb14-193" aria-hidden="true" tabindex="-1"></a>To access this model, we have to register an account on Huggingface and get an access token. If you are curious, <span class="co">[</span><span class="ot">this page</span><span class="co">](https://huggingface.co/docs/hub/en/security-tokens)</span> are more information about it. Here, we store the access token in a <span class="in">`.env`</span> file under the variable <span class="in">`HUG_KEY`</span> and load it through the <span class="in">`dotenv`</span> package.</span>
<span id="cb14-194"><a href="#cb14-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-195"><a href="#cb14-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{python, eval=FALSE}</span></span>
<span id="cb14-196"><a href="#cb14-196" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-197"><a href="#cb14-197" aria-hidden="true" tabindex="-1"></a>load_dotenv()</span>
<span id="cb14-198"><a href="#cb14-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-199"><a href="#cb14-199" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SentenceTransformer(</span>
<span id="cb14-200"><a href="#cb14-200" aria-hidden="true" tabindex="-1"></a>    <span class="st">"paraphrase-MiniLM-L3-v2"</span>, use_auth_token<span class="op">=</span>os.environ[<span class="st">"HUG_KEY"</span>]</span>
<span id="cb14-201"><a href="#cb14-201" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-202"><a href="#cb14-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-203"><a href="#cb14-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-204"><a href="#cb14-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-205"><a href="#cb14-205" aria-hidden="true" tabindex="-1"></a>Now that we loaded the model, we are going to generate three types of embeddings. First, we use the titles of the reviews to generate embeddings, which we call <span class="in">`title_emb`</span>. Second, we use the full reviews to generate embeddings, which we call <span class="in">`review_emb`</span>. Note that if a review is longer than 514 words, then model will only use the first 514 words. One way to improve this is to seperate the full reviews into sentences, generate embeddings for each sentence, and then average the sentence embeddings. This we call <span class="in">`sent_emb`</span>.</span>
<span id="cb14-206"><a href="#cb14-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-207"><a href="#cb14-207" aria-hidden="true" tabindex="-1"></a>We first look at what <span class="in">`sent_tokenize`</span> from the <span class="in">`nltk`</span> package does:</span>
<span id="cb14-208"><a href="#cb14-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-211"><a href="#cb14-211" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-212"><a href="#cb14-212" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of a negative review</span></span>
<span id="cb14-213"><a href="#cb14-213" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_df.loc[<span class="dv">0</span>, <span class="st">"review"</span>][:<span class="dv">500</span>])</span>
<span id="cb14-214"><a href="#cb14-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-215"><a href="#cb14-215" aria-hidden="true" tabindex="-1"></a><span class="co"># Sentence tokenizer</span></span>
<span id="cb14-216"><a href="#cb14-216" aria-hidden="true" tabindex="-1"></a>nltk.sent_tokenize(train_df.loc[<span class="dv">0</span>, <span class="st">"review"</span>])</span>
<span id="cb14-217"><a href="#cb14-217" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-218"><a href="#cb14-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-219"><a href="#cb14-219" aria-hidden="true" tabindex="-1"></a>Now we will define the functions for embedding extractions and extract the three types of embeddings.</span>
<span id="cb14-220"><a href="#cb14-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-223"><a href="#cb14-223" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-224"><a href="#cb14-224" aria-hidden="true" tabindex="-1"></a><span class="co"># | eval: false</span></span>
<span id="cb14-225"><a href="#cb14-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-226"><a href="#cb14-226" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> full_text_emb(model, text):</span>
<span id="cb14-227"><a href="#cb14-227" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> model.encode(text, show_progress_bar<span class="op">=</span><span class="va">True</span>)  <span class="co"># encode the full text</span></span>
<span id="cb14-228"><a href="#cb14-228" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> emb</span>
<span id="cb14-229"><a href="#cb14-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-230"><a href="#cb14-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-231"><a href="#cb14-231" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sent_text_emb(model, text):</span>
<span id="cb14-232"><a href="#cb14-232" aria-hidden="true" tabindex="-1"></a>    sent_text <span class="op">=</span> nltk.sent_tokenize(text)  <span class="co"># tokenize the text into sentences</span></span>
<span id="cb14-233"><a href="#cb14-233" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> model.encode(sent_text, show_progress_bar<span class="op">=</span><span class="va">True</span>)  <span class="co"># batch encode</span></span>
<span id="cb14-234"><a href="#cb14-234" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> np.mean(emb, axis<span class="op">=</span><span class="dv">0</span>).shape  <span class="co"># mean of the sentence embeddings</span></span>
<span id="cb14-235"><a href="#cb14-235" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> emb</span>
<span id="cb14-236"><a href="#cb14-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-237"><a href="#cb14-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-238"><a href="#cb14-238" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract embeddings</span></span>
<span id="cb14-239"><a href="#cb14-239" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"title_emb"</span>] <span class="op">=</span> train_df[<span class="st">"title"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb14-240"><a href="#cb14-240" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"review_emb"</span>] <span class="op">=</span> train_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb14-241"><a href="#cb14-241" aria-hidden="true" tabindex="-1"></a>train_df[<span class="st">"sent_emb"</span>] <span class="op">=</span> train_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: sent_text_emb(model, x))</span>
<span id="cb14-242"><a href="#cb14-242" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"title_emb"</span>] <span class="op">=</span> test_df[<span class="st">"title"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb14-243"><a href="#cb14-243" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"review_emb"</span>] <span class="op">=</span> test_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: full_text_emb(model, x))</span>
<span id="cb14-244"><a href="#cb14-244" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">"sent_emb"</span>] <span class="op">=</span> test_df[<span class="st">"review"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: sent_text_emb(model, x))</span>
<span id="cb14-245"><a href="#cb14-245" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-246"><a href="#cb14-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-247"><a href="#cb14-247" aria-hidden="true" tabindex="-1"></a>Because we have so much data, generating embeddings still takes a lot of computational resources even after the 1% sampling. Thus, we are just going to load the already generated <span class="in">`title_emb`</span> and <span class="in">`review_emb`</span> here and ignore <span class="in">`sent_emb`</span> for now. If you are interested, here is the <span class="co">[</span><span class="ot">script</span><span class="co">]()</span> we used to batch the input and speed up the embedding extraction process.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>