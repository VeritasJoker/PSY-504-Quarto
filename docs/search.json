[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-post/index.html",
    "href": "posts/new-post/index.html",
    "title": "Millie",
    "section": "",
    "text": "Hello, I am Millie üêà\n\nprint(\"I code in R\")\n\n[1] \"I code in R\"\n\n\n\nprint(\"And in Python\")\n\nAnd in Python"
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html",
    "title": "Lab: Logistic Regression",
    "section": "",
    "text": "Assignment requirements:\n\nIf you are using Github (recommended), make sure to commit and push your work to GitHub regularly, at least after each exercise. Write short and informative commit messages, and share the link to your assignment with me. If not, you can also send me the rmd & rendered file via Canvas.\nIn this assignment, you will not need to code from scratch. Rather, you‚Äôll need to fill in code where needed. This assignment has a logisitic regression implementation for a scenario from EDA down to model comparison (and would be useful for whenever you may encounter such a situation in the future).\nI want the assignments to begin reflecting a bit more of how you‚Äôd be doing things on your own, where you have some prior knowledge and you figure other things out (by referring to documentation, etc.) . In addition to the rmd, I also want you to submit to me notes of anything new that you learn while finishing the assignment. And any pain-points, and we‚Äôll discuss more.\n\nNote:\n\nIf you are fitting a model, display the model output in a neatly formatted table. (The gt tidy and kable functions can help!). Modelsummary also looks good(https://vincentarelbundock.github.io/modelsummary/articles/modelsummary.html)\nMake sure that your plots are clearly labeled ‚Äì for all axes, titles, etc."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#data-general-social-survey",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#data-general-social-survey",
    "title": "Lab: Logistic Regression",
    "section": "Data: General Social Survey",
    "text": "Data: General Social Survey\nThe General Social Survey (GSS) has been used to measure trends in attitudes and behaviors in American society since 1972. In addition to collecting demographic information, the survey includes questions used to gauge attitudes about government spending priorities, confidence in institutions, lifestyle, and many other topics. A full description of the survey may be found here.\nThe data for this lab are from the 2016 General Social Survey. The original data set contains 2867 observations and 935 variables. We will use and abbreviated data set that includes the following variables:\nnatmass: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe are faced with many problems in this country, none of which can be solved easily or inexpensively. I‚Äôm going to name some of these problems, and for each one I‚Äôd like you to tell me whether you think we‚Äôre spending too much money on it, too little money, or about the right amount‚Ä¶are we spending too much, too little, or about the right amount on mass transportation?‚Äù\nage: Age in years.\nsex: Sex recorded as male or female\nsei10: Socioeconomic index from 0 to 100\nregion: Region where interview took place\npolviews: Respondent‚Äôs answer to the following prompt:\n‚ÄúWe hear a lot of talk these days about liberals and conservatives. I‚Äôm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal - point 1 - to extremely conservative - point 7. Where would you place yourself on this scale?‚Äù\nThe data are in gss2016.csv in the data folder."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#eda",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#eda",
    "title": "Lab: Logistic Regression",
    "section": "EDA",
    "text": "EDA\n\nLet‚Äôs begin by making a binary variable for respondents‚Äô views on spending on mass transportation. Create a new variable that is equal to ‚Äú1‚Äù if a respondent said spending on mass transportation is about right and ‚Äú0‚Äù otherwise. Then plot the proportion of the response variable, using informative labels for each category.\n\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(readr)\nlibrary(tidyr)\nlibrary(knitr)\nlibrary(easystats)\nlibrary(broom)\nlibrary(emmeans)\nlibrary(marginaleffects)\nlibrary(performance)\nlibrary(arm)\nlibrary(modelsummary)\n\n\n\n\nCode\n# load data\ndata &lt;- read.csv(\"gss2016.csv\")\n\n\nFill in the ‚Äú____‚Äù below to encode the binary variable\n\n\nCode\ndata &lt;- data %&gt;%\n   mutate(mass_trans_spend_right = ifelse(natmass==\"About right\", 1, 0))\n\n\n\n\nCode\n#Get proportions\nmass_spend_summary &lt;- data %&gt;%\n  count(mass_trans_spend_right) %&gt;%\n  mutate(proportion = n / sum(n))\n\n#Look at the dataframe structure. And make sure it's in a format that you can use for plotting.\n#Change structure if neederd\nmass_spend_long &lt;- mass_spend_summary %&gt;% mutate(opinion=\"Opinion\")\n\n#Factorise for plot\nmass_spend_long$mass_trans_spend_right &lt;- as.factor(mass_spend_long$mass_trans_spend_right)\n\n#Make plot\n#Hint: geom_bar lets you make stacked bar charts\nggplot(mass_spend_long, aes(x = opinion, y = proportion, fill = mass_trans_spend_right)) +\n geom_bar(stat='identity') +\n  geom_text(aes(label=proportion),\n            vjust=ifelse(mass_spend_long$mass_trans_spend_right==0, -7, 7)\n            ) + \n  labs(x=\"Views on mass transportation spending\", y=\"Proportion\")\n\n\n\n\n\n\n\n\n\n\nRecode polviews so it is a factor with levels that are in an order that is consistent with question on the survey. Note how the categories are spelled in the data.\n\n\n\nCode\ndata &lt;- data %&gt;%\n  mutate(polviews = factor(polviews,\n                           levels = c(\"Extremely liberal\",\"Liberal\", \"Slightly liberal\", \"Moderate\", \"Slghtly conservative\", \"Conservative\", \"Extrmly conservative\"),\n                           ordered = TRUE))\n\n\n\nMake a plot of the distribution of polviews\n\n\n\nCode\n#Get proportions, format, and produce a plot like you did previously for \n\nmass_spend_summary &lt;- data %&gt;%\n  count(polviews) %&gt;%\n  mutate(proportion = n / sum(n))\n\n#Look at the dataframe structure. And make sure it's in a format that you can use for plotting.\n#Change structure if neederd\nmass_spend_long &lt;- mass_spend_summary %&gt;% mutate(opinion=\"Opinion\")\n\n#Make plot\n#Hint: geom_bar lets you make stacked bar charts\nggplot(mass_spend_long, aes(x = opinion, y = proportion, fill = polviews)) +\n geom_bar(stat='identity') + \n  labs(x=\"Views on mass transportation spending\", y=\"Proportion\")\n\n\n\n\n\n\n\n\n\n\nWhich political view occurs most frequently in this data set?\nModerate occurs most frequently.\n\n\nMake a plot displaying the relationship between satisfaction with mass transportation spending and political views. Use the plot to describe the relationship the two variables.\n\n\n\nCode\nmass_spend_summary &lt;- data %&gt;%\n  count(polviews, mass_trans_spend_right) %&gt;%\n  mutate(proportion = n / sum(n))\n\nmass_spend_summary$mass_trans_spend_right &lt;- as.factor(mass_spend_summary$mass_trans_spend_right)\n\nggplot(mass_spend_summary, aes(x = polviews, y = proportion, fill = mass_trans_spend_right)) +\n geom_bar(stat='identity', position='fill') +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) + \n  labs(x=\"Political Views\", y=\"Satisfaction Proportion\")\n\n\n\n\n\n\n\n\n\nThe more conservative one‚Äôs political views are the more they think the amount of spending on mass transportation is correct.\n\nWe‚Äôd like to use age as a quantitative variable in your model; however, it is currently a character data type because some observations are coded as ‚Äú89 or older‚Äù.\n\n\nRecode age so that is a numeric variable. Note: Before making the variable numeric, you will need to replace the values ‚Äú89 or older‚Äù with a single value.\n\n\n\nCode\ndata &lt;- data %&gt;%\n  mutate(age = ifelse(age == \"89 or older\", 89, age), \n         age = as.numeric(age))\n\n\n\nPlot the frequency distribution of age.\n\n\n\nCode\nggplot(data, aes(x = age)) +\n  geom_histogram(bins=30, fill=\"lightblue\", color=\"grey\") +\n  labs(x=\"Age\", y=\"Frequency\")"
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#logistic-regression",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#logistic-regression",
    "title": "Lab: Logistic Regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nLet‚Äôs start by fitting a logistic regression model with just the intercept\n\n\n\nCode\nintercept_only_model &lt;- glm(\n  mass_trans_spend_right ~ 1,\n  family=binomial,\n  data=data\n  ) \n\nintercept_only_model %&gt;% \n  tidy() %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.1190594\n0.0393685\n3.024229\n0.0024927\n\n\n\n\n\n\nInterpret the intercept in the context of the data. You can do this by converting the \\(\\beta_0\\) parameter out of the log-odds metric to the probability metric. Make sure to include the 95% confidence intervals. Then interpret the results in a sentence or two‚Äìwhat is the basic thing this probability tells us about?\n\n\n\nCode\nb0 &lt;- coef(intercept_only_model) # get coef\n\nb0_transformed &lt;- exp(b0) / (1 + exp(b0)) # logistic transform\n\nci_lower = b0 - 1.96 * 0.0393685\nci_upper = b0 + 1.96 * 0.0393685\n\n#transforming confidence intervals of coefficients into probabilities\np_lower = exp(ci_lower) / (1 + exp(ci_lower))\np_upper = exp(ci_upper) / (1 + exp(ci_upper))\n\n\nlogit_to_prob &lt;- function(logit){\n  return(exp(logit) / (1 + exp(logit)))\n}\n\nlogit_to_prob(coef(intercept_only_model))\n\n\n(Intercept) \n  0.5297297 \n\n\nCode\nlogit_to_prob(confint(intercept_only_model))\n\n\n    2.5 %    97.5 % \n0.5104854 0.5489153 \n\n\nInterpretation: The converted \\(\\beta_0\\) parameter in probability is 0.5297 (95%CI [ 0.5105, 0.5489]). This probability should just be the proportion of mass_trans_spend_right = 1 in the data.\n\nNow let‚Äôs fit a model using the demographic factors - age,sex, sei10 - to predict the odds a person is satisfied with spending on mass transportation. Make any necessary adjustments to the variables so the intercept will have a meaningful interpretation. Neatly display the model coefficients (do not display the summary output)\n\n\n\nCode\n#make sure that sex is a factor (i.e. to make sure R knows it's binary/categorical, and not continuous)\ndata = data %&gt;%\n  mutate(sex=factor(sex, levels=c(\"Male\", \"Female\")))\n\n#fit with glm()\nm1 &lt;- glm(\n  mass_trans_spend_right ~ 1 + age + sex + sei10,\n  family=binomial,\n  data=data\n  ) \n\n#produce tidy output of model coefficients\nm1 %&gt;% \n  tidy() %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.5697071\n0.1409061\n4.043169\n0.0000527\n\n\nage\n-0.0061659\n0.0022824\n-2.701502\n0.0069027\n\n\nsexFemale\n0.2557439\n0.0798020\n3.204732\n0.0013519\n\n\nsei10\n-0.0062271\n0.0016609\n-3.749229\n0.0001774\n\n\n\n\n\n\nConsider the relationship between sex and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of sex in terms of the logs odds and OR of being satisfied with spending on mass transportation. What are the predicted probabilities for males and females on support for spending on mass transportation? Please include the 95% CIs around each estimate.\n\n\n\nCode\n# m1 %&gt;% \n#   tidy() %&gt;%\n#   kable()\n\nm1 %&gt;% \n  tidy(exponentiate = TRUE) %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n1.7677492\n0.1409061\n4.043169\n0.0000527\n\n\nage\n0.9938530\n0.0022824\n-2.701502\n0.0069027\n\n\nsexFemale\n1.2914219\n0.0798020\n3.204732\n0.0013519\n\n\nsei10\n0.9937922\n0.0016609\n-3.749229\n0.0001774\n\n\n\n\n\nCode\nbsex &lt;- coef(m1)[\"sexFemale\"]\nstdsex = m1 %&gt;%\n  tidy %&gt;%\n  filter(`term` == \"sexFemale\") %&gt;%\n  pull(`std.error`)\n\nci_lower_lo = bsex - 1.96 * stdsex\nci_upper_lo = bsex + 1.96 * stdsex\n\nci_lower_or = 1.29 - 1.96 * stdsex\nci_upper_or = 1.29 + 1.96 * stdsex\nprint(paste0(\"Increase in log odds: \", round(bsex,4), \" (95% CI [\", round(ci_lower_lo,4), \" \", round(ci_upper_lo,4), \"])\"))\n\n\n[1] \"Increase in log odds: 0.2557 (95% CI [0.0993 0.4122])\"\n\n\nCode\nprint(paste0(\"Odds ratio: \", round(exp(bsex),4), \" (95% CI [\", round(ci_lower_or,4), \" \", round(ci_upper_or,4), \"])\"))\n\n\n[1] \"Odds ratio: 1.2914 (95% CI [1.1336 1.4464])\"\n\n\nCode\nemm_sex &lt;- emmeans(m1, \"sex\", type = \"response\")\nemm_sex\n\n\n sex     prob     SE  df asymp.LCL asymp.UCL\n Male   0.495 0.0147 Inf     0.467     0.524\n Female 0.559 0.0133 Inf     0.533     0.585\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the logit scale \n\n\nIf you did this right, you‚Äôll find that being female (as compared to male) is associated with an increase in the log-odds of being satisfied with spending on mass transportation by 0.2557439 units (95% CI [0.09, 0.41]), holding all other variables constant. This equates to the odds of thinking the spending amount is right in females being 1.29 times the odds of thinking this in men (95% CI [1.13, 1.44]).\nThe predicted probability for females to be satisfied with spending on mass transportation is 55.9% (95% CI [53.3%, 58.5%]) and that of males is 49.5% (95% CI [46.7%, 52.4%]).\n\nVerify this.\n\nNext, consider the relationship between age and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of age in terms of the logs odds and OR of being satisfied with spending on mass transportation. Please include the 95% CIs around each estimate.\n\n\n\nCode\nbage &lt;- coef(m1)[\"age\"]\nstdage = m1 %&gt;%\n  tidy %&gt;%\n  filter(`term` == \"age\") %&gt;%\n  pull(`std.error`)\n\nci_lower_lo = bage - 1.96 * stdage\nci_upper_lo = bage + 1.96 * stdage\n\nor = exp(bage)\nci_lower_or = exp(bage) - 1.96 * stdage\nci_upper_or = exp(bage) + 1.96 * stdage\n\nprint(paste0(\"Increase in log odds: \", round(bage,4), \" (95% CI [\", round(ci_lower_lo,4), \" \", round(ci_upper_lo,4), \"])\"))\n\n\n[1] \"Increase in log odds: -0.0062 (95% CI [-0.0106 -0.0017])\"\n\n\nCode\nprint(paste0(\"Odds ratio: \", round(or,4), \" (95% CI [\", round(ci_lower_or,4), \" \", round(ci_upper_or,4), \"])\"))\n\n\n[1] \"Odds ratio: 0.9939 (95% CI [0.9894 0.9983])\"\n\n\nA one unit increase in age is associated with a decrease in the log-odds of being satisfied with spending on mass transportation by 0.00617 (95% CI [-0.0106, -0.0017]), holding all other variables constant. The odds ratio is 0.993853 (95% CI [0.9894, 0.9983]) which confirms the inverse relationship implied by the log-odds coefficient. Specifically, for each additional unit of age, the odds of being satisfied with mass transportation spending decrease by a factor of about 0.993853, or approximately 0.617% per unit increase in age, holding other factors constant.\n\nConsider the relationship between SES and one‚Äôs opinion about spending on mass transportation. Interpret the coefficient of SES in terms of the logs odds and OR of being satisfied with spending on mass transportation. Please include the 95% CIs around each estimate. √ü\n\n\n\nCode\nbses &lt;- coef(m1)[\"sei10\"]\nstdses = m1 %&gt;%\n  tidy %&gt;%\n  filter(`term` == \"sei10\") %&gt;%\n  pull(`std.error`)\n\nci_lower_lo = bses - 1.96 * stdses\nci_upper_lo = bses + 1.96 * stdses\n\nor = exp(bses)\nci_lower_or = exp(bses) - 1.96 * stdses\nci_upper_or = exp(bses) + 1.96 * stdses\n\nprint(paste0(\"Increase in log odds: \", round(bses,4), \" (95% CI [\", round(ci_lower_lo,4), \" \", round(ci_upper_lo,4), \"])\"))\n\n\n[1] \"Increase in log odds: -0.0062 (95% CI [-0.0095 -0.003])\"\n\n\nCode\nprint(paste0(\"Odds ratio: \", round(or,4), \" (95% CI [\", round(ci_lower_or,4), \" \", round(ci_upper_or,4), \"])\"))\n\n\n[1] \"Odds ratio: 0.9938 (95% CI [0.9905 0.997])\"\n\n\nA one unit increase in SES index is associated with a decrease in the log-odds of being satisfied with spending on mass transportation by 0.0062 units (95% CI [-0.0095, -0.003]), holding all other variables constant. The odds ratio is less than 1 (0.9937922), which confirms the negative relationship implied by the log-odds coefficient. Specifically, for each additional unit of SES index, the odds of being satisfied with mass transportation spending decrease by a factor of about 0.993, or approximately 0.7% per unit increase in SES index, holding other factors constant (95% CI [0.989, 0.998])."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#marginal-effects",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#marginal-effects",
    "title": "Lab: Logistic Regression",
    "section": "Marginal effects",
    "text": "Marginal effects\n\nLet‚Äôs examine the results on the probability scale.\n\n\nCalculate the marginal effects of sex, age, and SES on mass transportation spending. You can use the margins package function margins discussed in your textbook or you can use the marginaleffects package avg_slope avg_comparisons discussed in lecture. Interpret each estimate.\n\n\n\nCode\navg_comparisons(m1, comparison = \"difference\") %&gt;% \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\ncontrast\nestimate\nstd.error\nstatistic\np.value\ns.value\nconf.low\nconf.high\n\n\n\n\nage\n+1\n-0.0015153\n0.0005579\n-2.716128\n0.0066050\n7.242217\n-0.0026088\n-0.0004219\n\n\nsei10\n+1\n-0.0015304\n0.0004039\n-3.789362\n0.0001510\n12.692835\n-0.0023219\n-0.0007388\n\n\nsex\nFemale - Male\n0.0630688\n0.0196461\n3.210251\n0.0013262\n9.558494\n0.0245632\n0.1015743\n\n\n\n\n\n\nThe marginal effect of age is -0.001515 (95% CI [-0.002609, -0.0004219]). So, for each additional unit increase of age, the probability of being satisfied with mass transportation spending decreases by approximately 0.1515 percentage points, holding other factors constant (p = 0.006605).\nThe marginal effect of SES is -0.001530 (95% CI [-0.002322, -0.0007388]). For each one-unit increase in the socioeconomic index, the probability of being satisfied with mass transportation spending decreases by approximately 0.1530 percentage points, holding other variables constant (p = 0.0001510).\nThe marginal effect for being female compared to male is 0.06307 (95% CI [0.02456, 0.1016]). This indicates that females are, on average, about 6.3% percentage points more likely than males to be satisfied with mass transportation spending, holding other factors constant."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#model-comparison",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#model-comparison",
    "title": "Lab: Logistic Regression",
    "section": "Model comparison",
    "text": "Model comparison\n\nNow let‚Äôs see whether a person‚Äôs political views has a significant impact on their odds of being satisfied with spending on mass transportation, after accounting for the demographic factors.\n\n\nConduct a drop-in-deviance/likelihood ratio test to determine if polviews is a significant predictor of attitude towards spending on mass transportation. Name these two models fit2 and fit3, respectively. Compare the two models.\n\n\n\nCode\nfit2 &lt;- glm(\n  mass_trans_spend_right ~ 1 + age + sex + sei10,\n  family=binomial,\n  data=data\n)\n\nfit3 &lt;- glm(\n  mass_trans_spend_right ~ 1 + age + sex + sei10 + polviews,\n  family=binomial,\n  data=data\n)\n\ntest_likelihoodratio(fit2, fit3) %&gt;% kable()\n\n\n\n\n\n\nName\nModel\ndf\ndf_diff\nChi2\np\n\n\n\n\nfit2\nfit2\nglm\n4\nNA\nNA\nNA\n\n\nfit3\nfit3\nglm\n10\n6\n63.02844\n0\n\n\n\n\n\n\nIs the model with polviews better than the model without?\n\n\nYes."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#visualization",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#visualization",
    "title": "Lab: Logistic Regression",
    "section": "Visualization",
    "text": "Visualization\n\nLet‚Äôs plot the results\nWe next use the model to produce visualizations:\n\nGiven the code below, interpet what is being plotted:\n\npol_plot : The predicted probability of being satisfied with the spending of mass transportation increases when political views become more conversative, when controlling for age, sex and SES.\nsex_plot : The predicted probability of being satisfied with the spending of mass transportation is higher for women than for men, when controlling for sex, SES, and political views.\nses_plot: The predicted probability of being satisfied with the spending of mass transportation decreases when SES increases, when controlling for age, sex, and political views.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nadjust the various settings in your plot to make it look professional.\nYou can use ggeffects to get the predicted probabilities for these models.\n\n\n\n\n\n\nCode\nlibrary(ggeffects)\n\n\ncolors &lt;- c(\"Extremely liberal\" = \"black\",\n            \"Liberal\" = \"#0e2f44\",  # Dark blue\n            \"Slightly liberal\" = \"#1d5a6c\",  # Less dark blue\n            \"Moderate\" = \"#358ca3\",  # Medium blue\n            \"Slghtly conservative\" = \"#71b9d1\",  # Light blue\n            \"Conservative\" = \"#a6dcef\",  # Lighter blue\n            \"Extrmly conservative\" = \"#d0f0fd\")  # Very light blue\n\npp_pol &lt;- ggemmeans(fit3, terms = c(\"polviews\"))\npp_pol\n\n\n# Predicted probabilities of mass_trans_spend_right\n\npolviews             | Predicted |     95% CI\n---------------------------------------------\nExtremely liberal    |      0.34 | 0.27, 0.43\nLiberal              |      0.39 | 0.34, 0.45\nSlightly liberal     |      0.49 | 0.43, 0.54\nModerate             |      0.57 | 0.53, 0.60\nSlghtly conservative |      0.55 | 0.50, 0.60\nConservative         |      0.58 | 0.53, 0.63\nExtrmly conservative |      0.66 | 0.57, 0.75\n\nAdjusted for:\n*   age = 48.90\n* sei10 = 46.07\n\n\nCode\n# Adjusted plot with gradient colors\npol_plot &lt;- ggplot(pp_pol, aes(x = x, y = predicted, color = x)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n  scale_color_manual(values = colors) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) + \n  labs(title = \"Effect of Political Views on Satisfaction with Mass Transportation\",\n       x = \"Political Views\", y = \"Predicted Probability\",\n       color = \"Political Views\") +\n  theme_minimal()\npol_plot\n\n\n\n\n\n\n\n\n\nCode\npp_sex &lt;- ggemmeans(fit3, terms = c(\"sex\"))\npp_sex\n\n\n# Predicted probabilities of mass_trans_spend_right\n\nsex    | Predicted |     95% CI\n-------------------------------\nMale   |      0.48 | 0.44, 0.51\nFemale |      0.55 | 0.51, 0.58\n\nAdjusted for:\n*   age = 48.90\n* sei10 = 46.07\n\n\nCode\nsex_plot &lt;- ggplot(pp_sex, aes(x = x, y = predicted, color = x)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n  labs(title = \"Effect of Sex on Satisfaction with Mass Transportation\",\n       x = \"Sex\", y = \"Predicted Probability\",\n       color = \"Sex\") +\n  theme_minimal()\n\nsex_plot\n\n\n\n\n\n\n\n\n\nCode\npp_ses &lt;- ggemmeans(fit3, terms = \"sei10\")\npp_ses\n\n\n# Predicted probabilities of mass_trans_spend_right\n\nsei10 | Predicted |     95% CI\n------------------------------\n    0 |      0.57 | 0.52, 0.61\n   15 |      0.55 | 0.51, 0.58\n   25 |      0.54 | 0.51, 0.57\n   35 |      0.52 | 0.50, 0.55\n   50 |      0.51 | 0.48, 0.53\n   65 |      0.49 | 0.46, 0.52\n   75 |      0.48 | 0.44, 0.51\n  100 |      0.45 | 0.40, 0.50\n\nAdjusted for:\n* age = 48.90\n\n\nCode\nses_plot &lt;-  ggplot(pp_ses, aes(x = x, y = predicted)) +\n  geom_line(color = \"#2c7fb8\", size = 1) + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = \"#2c7fb8\", alpha = 0.2) +  # Add a confidence interval band\n  labs(title = \"Effect of SES on Satisfaction with Mass Transportation\",\n       x = \"Socioeconomic Status\", y = \"Predicted Probability\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")  \nses_plot"
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#model-assumptions",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#model-assumptions",
    "title": "Lab: Logistic Regression",
    "section": "Model Assumptions",
    "text": "Model Assumptions\n\nIs the logistic model a good choice for this data?\n\n\n\nCode\nbinned_residuals(fit2)\n\n\nWarning: About 86% of the residuals are inside the error bounds (~95% or higher would be good).\n\n\nCode\nbinned_residuals(fit2) %&gt;% plot(show_dots=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAnswer: It seems like the model does not fit the data very well. About 86% of the residuals are inside the error bounds, as opposed to the ideal &gt;= 95%."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#model-fit",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#model-fit",
    "title": "Lab: Logistic Regression",
    "section": "Model fit",
    "text": "Model fit\n\nCalculate the \\(R^2\\) for this model\n\n\n\nCode\nr2_mcfadden(fit2)\n\n\n# R2 for Generalized Linear Regression\n       R2: 0.010\n  adj. R2: 0.009\n\n\n\nR2 interpretation: The model explains around 1% of the variance in the dependent variable, which means it is not a good fit.\nNext, Take a look at the binned residual plots for each continuous predictor variable and look at linearity. Is there a predictor that sticks out? What can we do to improve model fit in this case?\n\n\n\nCode\nbinned_residuals(fit2, term=\"sei10\")\n\n\nWarning: About 88% of the residuals are inside the error bounds (~95% or higher would be good).\n\n\nCode\nbinned_residuals(fit2, term=\"age\")\n\n\nOk: About 98% of the residuals are inside the error bounds.\n\n\nCode\nbinned_residuals(fit2, term=\"sei10\") %&gt;% plot(show_dots=TRUE)\n\n\n\n\n\n\n\n\n\nCode\nbinned_residuals(fit2, term=\"age\") %&gt;% plot(show_dots=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere SES seems to stick out. For SES, only 88% of the residuals are inside the error bounds while for age, about 98% of the residuals are inside the error bounds. However, for the binned residual plot, it looks like there is no systematic trends, so I think it‚Äôs reasonable to assume linearity. If we want, we can transform SES or add interaction terms to improve model fit."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#testing-polviews",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#testing-polviews",
    "title": "Lab: Logistic Regression",
    "section": "Testing Polviews",
    "text": "Testing Polviews\n\n\nCode\nemmeans(fit3, \"polviews\") %&gt;% pairs() %&gt;% as.data.frame() %&gt;% filter(p.value &lt; .05)\n\n\n contrast                                   estimate        SE  df z.ratio\n Extremely liberal - Moderate             -0.9266262 0.1950664 Inf  -4.750\n Extremely liberal - Slghtly conservative -0.8487137 0.2127293 Inf  -3.990\n Extremely liberal - Conservative         -0.9935486 0.2108369 Inf  -4.712\n Extremely liberal - Extrmly conservative -1.3402621 0.2792876 Inf  -4.799\n Liberal - Moderate                       -0.7090022 0.1308520 Inf  -5.418\n Liberal - Slghtly conservative           -0.6310897 0.1555805 Inf  -4.056\n Liberal - Conservative                   -0.7759246 0.1532081 Inf  -5.065\n Liberal - Extrmly conservative           -1.1226380 0.2392048 Inf  -4.693\n Slightly liberal - Extrmly conservative  -0.7334002 0.2412625 Inf  -3.040\n p.value\n  &lt;.0001\n  0.0013\n  0.0001\n  &lt;.0001\n  &lt;.0001\n  0.0010\n  &lt;.0001\n  0.0001\n  0.0382\n\nResults are averaged over the levels of: sex \nResults are given on the log odds ratio (not the response) scale. \nP value adjustment: tukey method for comparing a family of 7 estimates \n\n\nCode\nemmeans(fit3, \"polviews\", type=\"response\") %&gt;% pairs() %&gt;% as.data.frame() %&gt;% filter(p.value &lt; .05)\n\n\n contrast                                 odds.ratio         SE  df null\n Extremely liberal / Moderate              0.3958871 0.07722426 Inf    1\n Extremely liberal / Slghtly conservative  0.4279651 0.09104070 Inf    1\n Extremely liberal / Conservative          0.3702605 0.07806458 Inf    1\n Extremely liberal / Extrmly conservative  0.2617771 0.07311109 Inf    1\n Liberal / Moderate                        0.4921350 0.06439684 Inf    1\n Liberal / Slghtly conservative            0.5320118 0.08277063 Inf    1\n Liberal / Conservative                    0.4602780 0.07051835 Inf    1\n Liberal / Extrmly conservative            0.3254202 0.07784206 Inf    1\n Slightly liberal / Extrmly conservative   0.4802732 0.11587191 Inf    1\n z.ratio p.value\n  -4.750  &lt;.0001\n  -3.990  0.0013\n  -4.712  0.0001\n  -4.799  &lt;.0001\n  -5.418  &lt;.0001\n  -4.056  0.0010\n  -5.065  &lt;.0001\n  -4.693  0.0001\n  -3.040  0.0382\n\nResults are averaged over the levels of: sex \nP value adjustment: tukey method for comparing a family of 7 estimates \nTests are performed on the log odds ratio scale \n\n\n\nConservatives are 2.7008 and 2.1726 times more likely to support mass transit spending compared to extremely liberal and liberal\nExtreme liberals are 0.3703, 0.3959, and 0.4280 times more likely to support spending compared to conservatives, moderates and slight conservatives\nExtrm conservatives are 3.8200 and 2.0821 times more likely to support mass spending than liberals and slight liberals\nLiberals are 0.4921 and 0.5320 times more likely to support spending than moderates and slight conservatives."
  },
  {
    "objectID": "posts/02-12 logistic/Lab-Logistic-Q.html#conclusion",
    "href": "posts/02-12 logistic/Lab-Logistic-Q.html#conclusion",
    "title": "Lab: Logistic Regression",
    "section": "Conclusion",
    "text": "Conclusion\nBased on the model summary below, and the three figures, we conclude that age, sex, SES, and political views are all significant variables in predicting satisfaction of mass transit spending. Specifically, people that are younger tend to be more satisfied with mass transit spending; females are more satisfied with mass transit spending than males in general; people of lower socioeconomic status are more satisfied with mass transit spending; and people with more conservative political views are more satisfied with mass transit spending.\n\n\n\n\nDf\nDeviance\nResid. Df\nResid. Dev\nPr(&gt;Chi)\n\n\n\n\nNULL\nNA\nNA\n2589\n3581.340\nNA\n\n\nage\n1\n9.268443\n2588\n3572.072\n0.0023314\n\n\nsex\n1\n12.156624\n2587\n3559.915\n0.0004891\n\n\nsei10\n1\n14.119078\n2586\n3545.796\n0.0001716\n\n\npolviews\n6\n63.028441\n2580\n3482.768\n0.0000000\n\n\n\nTable 1\n\n\n\n\n\nFigure 1: Effect of Sex on Satisfaction with Mass Transportation\n\n\n\n\n\n\n\n\n\nFigure 2: Effect of SES on Satisfaction with Mass Transportation\n\n\n\n\n\n\n\n\n\nFigure 3: Effect of Political Views on Satisfaction with Mass Transportation"
  },
  {
    "objectID": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html",
    "href": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html",
    "title": "Lab: Multinomial Regression",
    "section": "",
    "text": "Lab Goal: Predict voting frequency using demographic variables Data source: FiveThirtyEight ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù survey Method: Multinomial logistic regression"
  },
  {
    "objectID": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#data",
    "href": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#data",
    "title": "Lab: Multinomial Regression",
    "section": "Data",
    "text": "Data\nThe data for this assignment comes from an online Ipsos survey that was conducted for the FiveThirtyEight article ‚ÄúWhy Many Americans Don‚Äôt Vote‚Äù. You can read more about the survey design and respondents in the README of the GitHub repo for the data.\nRespondents were asked a variety of questions about their political beliefs, thoughts on multiple issues, and voting behavior. We will focus on using the demographic variables and someone‚Äôs party identification to understand whether a person is a probable voter.\nThe variables we‚Äôll focus on were (definitions from the codebook in data set GitHub repo):\n\nppage: Age of respondent\neduc: Highest educational attainment category.\n\nrace: Race of respondent, census categories. Note: all categories except Hispanic were non-Hispanic.\ngender: Gender of respondent\nincome_cat: Household income category of respondent\nQ30: Response to the question ‚ÄúGenerally speaking, do you think of yourself as a‚Ä¶‚Äù\n\n1: Republican\n2: Democrat\n3: Independent\n4: Another party, please specify\n5: No preference\n-1: No response\n\nvoter_category: past voting behavior:\n\nalways: respondent voted in all or all-but-one of the elections they were eligible in\nsporadic: respondent voted in at least two, but fewer than all-but-one of the elections they were eligible in\nrarely/never: respondent voted in 0 or 1 of the elections they were eligible in\n\n\nYou can read in the data directly from the GitHub repo:\n\n\nCode\nlibrary(nnet)\nlibrary(car)\nlibrary(tidyverse)\nlibrary(emmeans)\nlibrary(ggeffects)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(broom)\nlibrary(parameters)\nlibrary(easystats)\n\n\n\n\nCode\nvoter_data &lt;- read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/non-voters/nonvoters_data.csv\")"
  },
  {
    "objectID": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#lrt",
    "href": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#lrt",
    "title": "Lab: Multinomial Regression",
    "section": "LRT",
    "text": "LRT\n\nRun the full model and report overall significance of each of the terms\n\n\nCode\ncar::Anova(model2) %&gt;% \n  kable()\n\n\n\n\n\n\nLR Chisq\nDf\nPr(&gt;Chisq)\n\n\n\n\nppage\n638.297213\n2\n0.000000\n\n\nrace\n52.651508\n6\n0.000000\n\n\ngender\n6.027914\n2\n0.049097\n\n\nincome_cat\n67.721466\n6\n0.000000\n\n\neduc\n154.136763\n4\n0.000000\n\n\npol_ident_new\n153.843978\n6\n0.000000\n\n\n\n\n\n\nAll the terms: age, race, gender, income, education, and party identification are all significant in predicting voter category"
  },
  {
    "objectID": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#marginal-effects-political-group---emmeans",
    "href": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#marginal-effects-political-group---emmeans",
    "title": "Lab: Multinomial Regression",
    "section": "Marginal Effects Political Group - Emmeans",
    "text": "Marginal Effects Political Group - Emmeans\n\n\nCode\n#Get estimated marginal means from the model\n\n#using \nmultinomial_analysis &lt;- emmeans(model2, ~ pol_ident_new|voter_category)\n\ncoefs = contrast(regrid(multinomial_analysis, \"log\"),\"trt.vs.ctrl1\",  by=\"pol_ident_new\")\n# you can add a parameter to the above command, ref = newbaseline, if you want to change baseline\n\nupdate(coefs, by = \"contrast\") %&gt;%\n kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast\npol_ident_new\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nsporadic - (rarely/never)\nDem\n0.961\n0.070\n28\n13.722\n0.000\n\n\nalways - (rarely/never)\nDem\n0.480\n0.074\n28\n6.498\n0.000\n\n\nsporadic - (rarely/never)\nIndep\n0.591\n0.077\n28\n7.643\n0.000\n\n\nalways - (rarely/never)\nIndep\n-0.049\n0.084\n28\n-0.590\n0.900\n\n\nsporadic - (rarely/never)\nOther\n0.078\n0.087\n28\n0.902\n0.747\n\n\nalways - (rarely/never)\nOther\n-0.835\n0.110\n28\n-7.577\n0.000\n\n\nsporadic - (rarely/never)\nRep\n0.883\n0.084\n28\n10.469\n0.000\n\n\nalways - (rarely/never)\nRep\n0.327\n0.089\n28\n3.672\n0.004"
  },
  {
    "objectID": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#marginal-effects-of-education---emmeans",
    "href": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#marginal-effects-of-education---emmeans",
    "title": "Lab: Multinomial Regression",
    "section": "Marginal Effects of Education - Emmeans",
    "text": "Marginal Effects of Education - Emmeans\n\n\nCode\n#Get estimated marginal means from the model\n\n#using \nmultinomial_analysis &lt;- emmeans(model2, ~ educ|voter_category)\n\ncoefs = contrast(regrid(multinomial_analysis, \"log\"),\"trt.vs.ctrl1\",  by=\"educ\")\n# you can add a parameter to the above command, ref = newbaseline, if you want to change baseline\n\nupdate(coefs, by = \"contrast\") %&gt;%\n kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast\neduc\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nsporadic - (rarely/never)\nCollege\n0.986\n0.076\n28\n12.904\n0.000\n\n\nalways - (rarely/never)\nCollege\n0.477\n0.080\n28\n5.960\n0.000\n\n\nsporadic - (rarely/never)\nHigh school or less\n0.187\n0.069\n28\n2.705\n0.031\n\n\nalways - (rarely/never)\nHigh school or less\n-0.711\n0.080\n28\n-8.883\n0.000\n\n\nsporadic - (rarely/never)\nSome college\n0.707\n0.074\n28\n9.512\n0.000\n\n\nalways - (rarely/never)\nSome college\n0.167\n0.079\n28\n2.114\n0.112\n\n\n\n\n\n\nNext, plot the predicted probabilities of voter category as a function of Age and Party ID\n\n\n\nCode\n  ggemmeans(model2, terms = c(\"ppage\")) %&gt;% \n      ggplot(., aes(x = x, y = predicted, fill = response.level)) +\n      geom_area() + \n      geom_rug(sides = \"b\", position = \"jitter\", alpha = .5) + \n      labs(x = \"\\nAge\", y = \"Predicted Probablity\\n\", title = \"Predicted Probabilities of Voting Frequency by Age\") +\n      scale_fill_manual(\n        name = NULL,\n        values = c(\"always\" = \"#F6B533\", \"sporadic\" = \"#D07EA2\", \"rarely/never\" = \"#9854F7\"),\n        labels = c(\"RARELY OR NEVER VOTE    \", \"SOMETIMES VOTE    \", \"ALMOST ALWAYS VOTE    \"),\n        breaks = c(\"rarely/never\", \"sporadic\", \"always\")\n      ) +\n      theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\n ggemmeans(model2, terms=c(\"pol_ident_new\")) %&gt;%   ggplot(., aes(x = x, y = predicted, fill = response.level)) + \n  geom_bar(stat = \"identity\" ) +\n    geom_text(aes(label = round(predicted, 3)), color=\"white\", position = position_fill(vjust = 0.5),size=3)  + \n  labs(x=\"Education\", y=\"Predicted Probablity\") + \n  theme(text = element_text(size = 30)) +  \n  scale_fill_viridis(discrete = TRUE) + \n  theme_lucid(base_size=25)\n\n\n\n\n\n\n\n\n\nPlot predicted probabilities as a function of education and voting frequency.\n\n\nCode\n ggemmeans(model2, terms=c(\"educ\")) %&gt;% ggplot(., aes(x = x, y = predicted, fill = response.level)) + \n  geom_bar(stat = \"identity\" ) +\n    geom_text(aes(label = round(predicted, 3)), color=\"white\", position = position_fill(vjust = 0.5),size=3)  + \n  labs(x=\"Education\", y=\"Predicted Probablity\") + \n  theme(text = element_text(size = 30)) +  \n  scale_fill_viridis(discrete = TRUE) + \n  theme_lucid(base_size=25)"
  },
  {
    "objectID": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#write-up",
    "href": "posts/02-26 multinomial/Lab4_multinom_Questions-1.html#write-up",
    "title": "Lab: Multinomial Regression",
    "section": "Write-up",
    "text": "Write-up\n\nDifferences between political groups and voting behavior - Emmeans\n\n\nCode\nmultinomial_analysis &lt;- emmeans(model2, ~ pol_ident_new|voter_category)\n\ncoefs = contrast(regrid(multinomial_analysis, \"log\"),\"trt.vs.ctrl1\",  by=\"pol_ident_new\")\n# you can add a parameter to the above command, ref = newbaseline, if you want to change baseline\n\nupdate(coefs, by = \"contrast\") %&gt;%\n kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast\npol_ident_new\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nsporadic - (rarely/never)\nDem\n0.961\n0.070\n28\n13.722\n0.000\n\n\nalways - (rarely/never)\nDem\n0.480\n0.074\n28\n6.498\n0.000\n\n\nsporadic - (rarely/never)\nIndep\n0.591\n0.077\n28\n7.643\n0.000\n\n\nalways - (rarely/never)\nIndep\n-0.049\n0.084\n28\n-0.590\n0.900\n\n\nsporadic - (rarely/never)\nOther\n0.078\n0.087\n28\n0.902\n0.747\n\n\nalways - (rarely/never)\nOther\n-0.835\n0.110\n28\n-7.577\n0.000\n\n\nsporadic - (rarely/never)\nRep\n0.883\n0.084\n28\n10.469\n0.000\n\n\nalways - (rarely/never)\nRep\n0.327\n0.089\n28\n3.672\n0.004\n\n\n\n\n\nCode\n# get difference between yes-no and fair-excellent\ncontrast(coefs, \"revpairwise\", by = \"contrast\") %&gt;%\n  kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast1\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nIndep - Dem\nsporadic - (rarely/never)\n-0.370\n0.094\n28\n-3.933\n0.003\n\n\nOther - Dem\nsporadic - (rarely/never)\n-0.883\n0.103\n28\n-8.578\n0.000\n\n\nOther - Indep\nsporadic - (rarely/never)\n-0.513\n0.107\n28\n-4.807\n0.000\n\n\nRep - Dem\nsporadic - (rarely/never)\n-0.078\n0.099\n28\n-0.787\n0.860\n\n\nRep - Indep\nsporadic - (rarely/never)\n0.292\n0.099\n28\n2.965\n0.029\n\n\nRep - Other\nsporadic - (rarely/never)\n0.805\n0.109\n28\n7.404\n0.000\n\n\nIndep - Dem\nalways - (rarely/never)\n-0.529\n0.101\n28\n-5.255\n0.000\n\n\nOther - Dem\nalways - (rarely/never)\n-1.315\n0.125\n28\n-10.508\n0.000\n\n\nOther - Indep\nalways - (rarely/never)\n-0.786\n0.129\n28\n-6.072\n0.000\n\n\nRep - Dem\nalways - (rarely/never)\n-0.153\n0.104\n28\n-1.470\n0.468\n\n\nRep - Indep\nalways - (rarely/never)\n0.376\n0.104\n28\n3.605\n0.006\n\n\nRep - Other\nalways - (rarely/never)\n1.162\n0.130\n28\n8.969\n0.000\n\n\n\n\n\nEnter your interpretation here:\nVoters who are Democrats are 2.61 times more likely to vote sporadically than vote rarely/never.\nVoters who are Democrats are 1.62 times more likely to vote always than vote rarely/never.\nVoters who are Independents are 1.81 times more likely to vote sporadically than vote rarely/never.\nVoters who are Independents are 4.78% less likely to vote always than vote rarely/never.\nVoters who belong to other political parties are 1.08 times more likely to vote sporadically than vote rarely/never.\nVoters who belong to other political parties are 56.61% less likely to vote always than vote rarely/never.\nVoters who are Republicans are 2.42 times more likely to vote sporadically than vote rarely/never.\nVoters who are Republicans are 1.39 times more likely to vote always than vote rarely/never.\nVoters who are Independents are 30.93% less likely to vote sporadically than vote rarely/never compared to voters who are Democrats.\nVoters who belong to voters who belong to other political parties are 58.65% less likely to vote sporadically than vote rarely/never compared to voters who are Democrats.\nVoters who belong to other political parties are 40.13% less likely to vote sporadically than vote rarely/never compared to voters who are Republicans.\nVoters who are Republicans are 7.50% less likely to vote sporadically than vote rarely/never compared to voters who are Democrats.\nVoters who are Republicans are 1.34 times more likely to vote sporadically than vote rarely/never compared to voters who are Independents.\nVoters who are Republicans are 2.24 times more likely to vote sporadically than vote rarely/never compared to voters who belong to other political parties.\nVoters who are Independents are 41.08% less likely to vote always than vote rarely/never compared to voters who are Democrats.\nVoters who belong to other political parties are 73.15% less likely to vote always than vote rarely/never compared to voters who are Democrats.\nVoters who belong to other political parties are 54.43% less likely to vote always than vote rarely/never compared to voters who are Republicans.\nVoters who are Republicans are 14.19% less likely to vote always than vote rarely/never compared to voters who are Democrats.\nVoters who are Republicans are 1.46 times more likely to vote always than vote rarely/never compared to voters who are Independents.\nVoters who are Republicans are 3.20 times more likely to vote always than vote rarely/never compared to voters who belong to other political parties.\n\n\nDifferences between education level and voting behavior - Emmeans\nLast part of the assignment: Interpret the results from running the following code for your model\n\n\nCode\nmulti_an &lt;- emmeans(model, ~ educ|voter_category)\n\ncoefs = contrast(regrid(multi_an, \"log\"),\"trt.vs.ctrl1\",  by=\"educ\")\n\nupdate(coefs, by = \"contrast\") %&gt;% \n  kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast\neduc\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nsporadic - (rarely/never)\nCollege\n1.156\n0.075\n22\n15.483\n0.000\n\n\nalways - (rarely/never)\nCollege\n0.711\n0.079\n22\n9.041\n0.000\n\n\nsporadic - (rarely/never)\nHigh school or less\n0.259\n0.069\n22\n3.749\n0.003\n\n\nalways - (rarely/never)\nHigh school or less\n-0.602\n0.081\n22\n-7.476\n0.000\n\n\nsporadic - (rarely/never)\nSome college\n0.806\n0.075\n22\n10.818\n0.000\n\n\nalways - (rarely/never)\nSome college\n0.311\n0.080\n22\n3.895\n0.002\n\n\n\n\n\nCode\n# get difference between yes-no and fair-excellent\ncontrast(coefs, \"revpairwise\", by = \"contrast\") %&gt;%\n  kable(format = \"markdown\", digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontrast1\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nHigh school or less - College\nsporadic - (rarely/never)\n-0.897\n0.095\n22\n-9.409\n0.000\n\n\nSome college - College\nsporadic - (rarely/never)\n-0.349\n0.092\n22\n-3.779\n0.003\n\n\nSome college - High school or less\nsporadic - (rarely/never)\n0.547\n0.089\n22\n6.162\n0.000\n\n\nHigh school or less - College\nalways - (rarely/never)\n-1.313\n0.105\n22\n-12.463\n0.000\n\n\nSome college - College\nalways - (rarely/never)\n-0.401\n0.098\n22\n-4.091\n0.001\n\n\nSome college - High school or less\nalways - (rarely/never)\n0.913\n0.099\n22\n9.206\n0.000\n\n\n\n\n\nEnter your interpretation here:\nVoters with a highest degree of college are 3.18 times more likely to vote sporadically than vote rarely/never.\nVoters with a highest degree of college are 2.04 times more likely to vote always than vote rarely/never.\nVoters with a highest degree of high school or less are 1.30 times more likely to vote sporadically than vote rarely/never.\nVoters with a highest degree of high school or less are 45.23% less likely to vote always than vote rarely/never.\nVoters with a highest degree of some college are 2.24 times more likely to vote sporadically than vote rarely/never.\nVoters with a highest degree of some college are 1.36 times more likely to vote always than vote rarely/never.\nVoters with a highest degree of high school or less are 59.22% less likely to vote sporadically than vote rarely/never compared to voters with a highest degree of college.\nVoters with a highest degree of some college are 29.46% less likely to vote sporadically than vote rarely/never compared to voters with a highest degree of college.\nVoters with a highest degree of some college are 1.73 times more likely to vote sporadically than vote rarely/never compared to voters with a highest degree of high school or less.\nVoters with a highest degree of high school or less are 73.10% less likely to vote always than vote rarely/never compared to voters with a highest degree of college.\nVoters with a highest degree of some college are 33.03% less likely to vote always than vote rarely/never compared to voters with a highest degree of college.\nVoters with a highest degree of some college are 2.49 times more likely to vote always than vote rarely/never compared to voters with a highest degree of high school or less."
  },
  {
    "objectID": "posts/02-19 ordinal/ord_lab_q.html",
    "href": "posts/02-19 ordinal/ord_lab_q.html",
    "title": "Lab: Ordinal Regression",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don‚Äôt forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you‚Äôre done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "posts/02-19 ordinal/ord_lab_q.html#instructions",
    "href": "posts/02-19 ordinal/ord_lab_q.html#instructions",
    "title": "Lab: Ordinal Regression",
    "section": "",
    "text": "If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)\nIf you are creating a plot, use clear labels for all axes, titles, etc.\nIf you are using Github, don‚Äôt forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages. Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors.\nWhen you‚Äôre done, we should be able to knit the final version of the QMD in your GitHub as a HTML."
  },
  {
    "objectID": "posts/02-19 ordinal/ord_lab_q.html#load-packages",
    "href": "posts/02-19 ordinal/ord_lab_q.html#load-packages",
    "title": "Lab: Ordinal Regression",
    "section": "Load packages:",
    "text": "Load packages:\n\n\nCode\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(performance)\nlibrary(ordinal) #clm\nlibrary(car) # anova\nlibrary(ggeffects) #  viz\nlibrary(gofcat) # brant\nlibrary(brms)\nlibrary(emmeans) # contrasts\nlibrary(knitr)"
  },
  {
    "objectID": "posts/02-19 ordinal/ord_lab_q.html#load-data",
    "href": "posts/02-19 ordinal/ord_lab_q.html#load-data",
    "title": "Lab: Ordinal Regression",
    "section": "Load data",
    "text": "Load data\n\nMake sure only the top 3 ranks are being used. For some reason, there are missing ranks (my guess is they did not announce rank on TV)\n\n\n\nCode\ngbbo &lt;- read_csv(\"https://raw.githubusercontent.com/suyoghc/PSY-504_Spring-2025/refs/heads/main/Ordinal%20Regression/data/GBBO.csv\")\n\n# Enter code to filter. Think about the data type that would be relevant for Rank\ngb &lt;- gbbo %&gt;%\n  filter(`Technical Rank` &lt;= 3) %&gt;%\n  mutate(`Technical Rank` = factor(`Technical Rank`, levels=c(1,2,3), ordered=TRUE),\n         Gender = factor(Gender, levels=c(\"M\",\"F\"), ordered=TRUE))"
  },
  {
    "objectID": "posts/02-19 ordinal/ord_lab_q.html#explore",
    "href": "posts/02-19 ordinal/ord_lab_q.html#explore",
    "title": "Lab: Ordinal Regression",
    "section": "Explore",
    "text": "Explore\n\nPlot two figures showing the percentage of bakers in each rank‚Äî create one for Gender and Age\n\n\n\nCode\ngb_gender &lt;- gb %&gt;%\n  count(Gender, `Technical Rank`) %&gt;%\n  mutate(proportion = n / sum(n))\n\nggplot(gb_gender, aes(x = Gender, y = proportion, fill = `Technical Rank`)) +\n  geom_bar(stat='identity', position='fill') + \n  labs(x=\"Gender\", y=\"Proportion of Technical Rank\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ngb_age &lt;- gb %&gt;%\n  mutate(Age = cut_number(Age,8)) %&gt;%\n  count(Age, `Technical Rank`) %&gt;%\n  mutate(proportion = n / sum(n))\n\n\nggplot(gb_age, aes(x = Age, y = proportion, fill = `Technical Rank`)) +\n  geom_bar(stat='identity', position='fill') + \n  labs(x=\"Age (binned)\", y=\"Proportion of Technical Rank\")"
  },
  {
    "objectID": "posts/02-19 ordinal/ord_lab_q.html#ordinal-analysis",
    "href": "posts/02-19 ordinal/ord_lab_q.html#ordinal-analysis",
    "title": "Lab: Ordinal Regression",
    "section": "Ordinal Analysis",
    "text": "Ordinal Analysis\n\nIf you haven‚Äôt already, convert the outcome variable to an ordered factor. What does the order here represent?\nThe order here represent the technical rank: first, second, third.\nConvert input variables to categorical factors as appropriate.\n\n\nCode\nstr(gb)\n\n\ntibble [309 √ó 3] (S3: tbl_df/tbl/data.frame)\n $ Gender        : Ord.factor w/ 2 levels \"M\"&lt;\"F\": 2 1 1 2 1 2 1 2 2 1 ...\n $ Age           : num [1:309] 30 31 24 45 25 37 24 37 31 24 ...\n $ Technical Rank: Ord.factor w/ 3 levels \"1\"&lt;\"2\"&lt;\"3\": 2 3 1 2 1 3 1 3 2 3 ...\n\n\nCode\ngb = gb %&gt;%\n  mutate(Technical_Rank = `Technical Rank`)\n\n\nRun a ordinal logistic regression model against all relevant input variables. Interpret the effects for Gender, Age and Gender*Age (even if they are non-significant).\n\n\nCode\nmodel1 = clm(Technical_Rank~1 + Gender + Age, data=gb, link=\"logit\")\nmodel2 = clm(Technical_Rank~1 + Gender + Age + Gender * Age, data=gb, link=\"logit\")\n# summary(model2)\nmodel2 %&gt;% \n  tidy() %&gt;%\n  kable()\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\ncoef.type\n\n\n\n\n1|2\n-0.8419558\n0.3422080\n-2.460363\n0.0138797\nintercept\n\n\n2|3\n0.5796803\n0.3404226\n1.702826\n0.0886007\nintercept\n\n\nGender.L\n0.8127997\n0.4758129\n1.708234\n0.0875930\nlocation\n\n\nAge\n-0.0037139\n0.0092343\n-0.402186\n0.6875471\nlocation\n\n\nGender.L:Age\n-0.0274268\n0.0131038\n-2.093039\n0.0363456\nlocation\n\n\n\n\n\nCode\nprint(exp(0.8127997))\n\n\n[1] 2.25421\n\n\nCode\nprint(1-exp(-0.0037139))\n\n\n[1] 0.003707012\n\n\nCode\nprint(1-exp(-0.0274268))\n\n\n[1] 0.0270541\n\n\nGender: The odds of being in a higher Technical_Rank category are 2.25 times greater for Females compared to Males, controlling for Age and the interaction between Gender and Age.\nAge: For every one year increase in age, the odds of being in a higher Technical_Rank category decreases by approximately 0.37%, controlling for Gender and the interaction between Gender and Age.\nGender and Age: For each additional year increase in Age, the odds of being in a higher Technical_Rank category decreases by about 2.71% more for Females than for Males, controlling for Gender and Age.\nTest if the interaction is warranted\n\n#Hint: You need to create two models with clm(); one with interaction and one without. #Then you compare them using the anova test using anova()\n\n\nCode\n    anova_test &lt;- anova(model1, model2)\n    anova_test\n\n\nLikelihood ratio tests of cumulative link models:\n \n       formula:                                         link: threshold:\nmodel1 Technical_Rank ~ 1 + Gender + Age                logit flexible  \nmodel2 Technical_Rank ~ 1 + Gender + Age + Gender * Age logit flexible  \n\n       no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)  \nmodel1      4 685.72 -338.86                        \nmodel2      5 683.28 -336.64   4.437  1    0.03517 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nYes, the interaction is warranted.\n\nUse ggemmeans to create a figure showing the interaction between Gender and Age as a function of rank. Plot predicted probabilities from the model.\n\n\nCode\n# print(ggemmeans(model2, terms=c(\"Age\",\"Gender\")), n = Inf)\n\nplot(ggemmeans(model2, terms=c(\"Gender\",\"Age\"))) +\n  labs(title = \"Predicted Probabilities of Technical Rank\")\n\n\n\n\n\n\n\n\n\nCode\nplot(ggemmeans(model2, terms=c(\"Age [all]\",\"Gender\"))) +\n  labs(title = \"Predicted Probabilities of Technical Rank\")\n\n\n\n\n\n\n\n\n\n\n\nLatent Visualization\n\n\nCode\nols_clm = MASS::polr(Technical_Rank~Gender*Age, data=gb)\n\nggeffect(ols_clm, c(\"Age[all]\", \"Gender\"), latent=TRUE) %&gt;% plot()\n\n\n\n\n\n\n\n\n\n\nUse the Brant test to support or reject the hypothesis that the proportional odds assumption holds for your simplified model.\n\n\nCode\nbrant.test(ols_clm)\n\n\n\nBrant Test:\n                chi-sq   df   pr(&gt;chi)\nOmnibus          1.295    3       0.73\nGender.L         0.585    1       0.44\nAge              0.415    1       0.52\nGender.L:Age     0.924    1       0.34\n\nH0: Proportional odds assumption holds\n\n\nThe proportional odds assumption holds since all p-vlaues are &gt; 0.05.\nbrms\nBelow is a model implementation using the brms package. We will just use the default priors for this. The exercise is to run this code and note your observations. What are salient differences you observe in how the model fitting takes place. With respect to the results, how do you compare the results of the model you fit with clm and the one you fit with brms?\n\n\n\nCode\n  ols2_brm = brm(Technical_Rank ~  Gender*Age, data=gb, family = cumulative, cores = 4,chains = 4)\n\n\nThe `brm` package uses a bayesian approach, estimates parameters using Markov Chain Mote Carlo (MCMC), while the `clm` package uses a frequentist approach, estimates parameters via maximum likelihood estimation (MLE). `clm` is much faster and deterministic, while `brms` is slower and stochastic.\n\nThe results from `brms` provide posterior distributions with credible intervals, which tend to be wider than the standard errors in `clm`, reflecting greater uncertainty. While the point estimates from both models are similar, the bayesian approach allows for probabilistic statements about the parameters. The posterior distributions directly tell you the probability of a parameter being within a given range. Thus, I would say `brms` is more flexible and interpretable, while `clm` is computationally efficient and useful for quick estimation.\n\nThe conditional_effects function is used to plot predicted probabilities by Gender and Age across each rank.\n\n\nCode\nconditional_effects(ols2_brm, categorical = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis makes sense. Higher probabilities for higher Technical_Rank for females and younger ages.\ncheck_predictions from the easystats performance package is used for examining model fit (i.e., does the data fit the model being used?). Run the below code. What do you think?\n\n\n\nCode\ncheck_predictions(ols2_brm)\n\n\n\n\n\n\n\n\n\nI would say it fits the data pretty well. The observed data is within the model-predicted data intervals."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Labs & Assignments",
    "section": "",
    "text": "Bayes_Lab_2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBayes and Penguins\n\n\nPrinceton University\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nApr 2, 2025\n\n\nKW\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian GLM\n\n\n \n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 31, 2025\n\n\nKen Wang\n\n\n\n\n\n\n\n\n\n\n\n\nMLM2 - Answer Walkthrough\n\n\nPrinceton University\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 26, 2025\n\n\nKW\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to MLM Exercise/Walkthrough\n\n\nPrinceton University\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 19, 2025\n\n\nKW\n\n\n\n\n\n\n\n\n\n\n\n\nLab: Poisson Regression\n\n\nPrinceton University\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 5, 2025\n\n\nKW\n\n\n\n\n\n\n\n\n\n\n\n\nLab: Multinomial Regression\n\n\nPrinceton University\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 26, 2025\n\n\nKW\n\n\n\n\n\n\n\n\n\n\n\n\nLab: Ordinal Regression\n\n\nPrinceton University\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nKW\n\n\n\n\n\n\n\n\n\n\n\n\nLab: Logistic Regression\n\n\nPrinceton University\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 12, 2025\n\n\nKW\n\n\n\n\n\n\n\n\n\n\n\n\nMillie\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 6, 2025\n\n\nKW\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html",
    "title": "Lab: Poisson Regression",
    "section": "",
    "text": "To complete this lab:\nCode\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(emmeans)\nlibrary(ggeffects)\nlibrary(easystats)\nlibrary(performance)\nlibrary(knitr)\nCode\nlibrary(tidyverse)\n\ndata &lt;- read_delim(\"https://raw.githubusercontent.com/jgeller112/psy504-advanced-stats/main/slides/Poisson/data/2010.csv\")\nCode\nlibrary(naniar)\n\ndata_pos &lt;- data %&gt;%\n  dplyr::select(wwwhr, wordsum, age, sex, reliten, polviews, wrkhome) %&gt;%\nreplace_with_na(.,\n             replace = list(wwwhr = c(-1, 998, 999),\n                          wordsum = c(-1, 99),\n                          reliten = c(0, 8, 9), \n             polviews = c(0, 8, 9), \n             wrkhome = c(0,8,9), \n             age=c(0, 98, 99)))\nQ: Can you explain what might be going on in the above code?\nA: The code is using dplyr package to select 7 columns, then replace the values specified in the list with NAs. For instance, it replaces wwwhr values -1, 998, and 999 to NAs.\nQ: The next step in data cleaning would be to ensure that the data in your code are aligned with the description/ usage context of the variables\nCode\ndata_pos = data_pos %&gt;%\n  mutate(age_recode = age - mean(age, na.rm=TRUE),\n         sex_recode = as.factor(sex),\n         reliten_recode = as.factor(reliten),\n         polviews_recode = as.factor(polviews),\n         wrkhome_recode = as.factor(wrkhome))"
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#missingness",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#missingness",
    "title": "Lab: Poisson Regression",
    "section": "Missingness",
    "text": "Missingness\n\n\nCode\ndata_pos %&gt;%\n  dplyr::select(reliten, reliten_recode)\n\n\n# A tibble: 2,044 √ó 2\n   reliten reliten_recode\n     &lt;dbl&gt; &lt;fct&gt;         \n 1       1 1             \n 2       4 4             \n 3       1 1             \n 4       1 1             \n 5       1 1             \n 6       4 4             \n 7       3 3             \n 8       1 1             \n 9       1 1             \n10       1 1             \n# ‚Ñπ 2,034 more rows\n\n\nCode\nlibrary(skimr)\nskimr::skim(data_pos)\n\n\n\n\n\n\nName\ndata_pos\n\n\nNumber of rows\n2044\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nData summaryVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsex_recode\n0\n1.00\nFALSE\n2\n-1: 1153, 1: 891\n\n\nreliten_recode\n99\n0.95\nFALSE\n4\n2: 747, 1: 707, 4: 363, 3: 128\n\n\npolviews_recode\n71\n0.97\nFALSE\n7\n4: 746, 6: 315, 5: 265, 2: 259\n\n\nwrkhome_recode\n882\n0.57\nFALSE\n6\n1: 674, 5: 147, 2: 101, 4: 92\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nwwwhr\n996\n0.51\n9.79\n13.41\n0.00\n2.00\n5.00\n14.00\n168.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nwordsum\n657\n0.68\n6.03\n2.07\n0.00\n5.00\n6.00\n7.00\n10.00\n‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñÇ\n\n\nage\n3\n1.00\n47.97\n17.68\n18.00\n33.00\n47.00\n61.00\n89.00\n‚ñá‚ñá‚ñá‚ñÖ‚ñÉ\n\n\nsex\n0\n1.00\n-0.13\n0.99\n-1.00\n-1.00\n-1.00\n1.00\n1.00\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÜ\n\n\nreliten\n99\n0.95\n2.08\n1.08\n1.00\n1.00\n2.00\n3.00\n4.00\n‚ñá‚ñá‚ñÅ‚ñÇ‚ñÉ\n\n\npolviews\n71\n0.97\n4.08\n1.46\n1.00\n3.00\n4.00\n5.00\n7.00\n‚ñÉ‚ñÇ‚ñá‚ñÉ‚ñÖ\n\n\nwrkhome\n882\n0.57\n2.26\n1.72\n1.00\n1.00\n1.00\n4.00\n6.00\n‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñÅ\n\n\nage_recode\n3\n1.00\n0.00\n17.68\n-29.97\n-14.97\n-0.97\n13.03\n41.03\n‚ñá‚ñá‚ñá‚ñÖ‚ñÉ"
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#fit-a-poisson-model-to-the-data.",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#fit-a-poisson-model-to-the-data.",
    "title": "Lab: Poisson Regression",
    "section": "Fit a Poisson model to the data.",
    "text": "Fit a Poisson model to the data.\n\n\nCode\nlibrary(lme4)\nmodel1 = glm(wwwhr~age_recode+wordsum+sex_recode+reliten_recode+polviews_recode+wrkhome_recode, \n              data=data_pos,\n              family=poisson(link = \"log\"))"
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#carry-out-model-checking",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#carry-out-model-checking",
    "title": "Lab: Poisson Regression",
    "section": "Carry out model checking",
    "text": "Carry out model checking\nHint: performance package has the function you‚Äôre looking for\n\n\nCode\nlibrary(performance)\nperformance::check_model(model1, check = c(\"pp_check\", \"outliers\", \"vif\", \"overdispersion\"))"
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#find-any-outliers",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#find-any-outliers",
    "title": "Lab: Poisson Regression",
    "section": "Find any outliers",
    "text": "Find any outliers\n\n\nCode\noutlier_idx = check_outliers(model1)\noutlier_idx\n\n\n3 outliers detected: cases 72, 156, 363.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)."
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#refit-the-model-after-excluding-outliers",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#refit-the-model-after-excluding-outliers",
    "title": "Lab: Poisson Regression",
    "section": "Refit the model after excluding outliers",
    "text": "Refit the model after excluding outliers\n\n\nCode\ndata_pos2 = data_pos %&gt;%\n  filter(! row_number() %in% which(outlier_idx))\n\nmodel2 = glm(wwwhr~age+wordsum+sex_recode+reliten_recode+polviews_recode+wrkhome_recode, \n              data=data_pos2,\n              family=poisson(link=\"log\"))\n\n\n\n\nCode\nmodel_parameters(model2) %&gt;%\n  print_html()\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nz\np\n\n\n\n\n(Intercept)\n1.89\n0.09\n(1.71, 2.07)\n20.52\n&lt; .001\n\n\nage\n-0.02\n1.10e-03\n(-0.02, -0.01)\n-15.29\n&lt; .001\n\n\nwordsum\n0.10\n7.86e-03\n(0.08, 0.11)\n12.38\n&lt; .001\n\n\nsex recode (1)\n0.22\n0.03\n(0.17, 0.27)\n8.13\n&lt; .001\n\n\nreliten recode (2)\n0.34\n0.04\n(0.26, 0.41)\n8.88\n&lt; .001\n\n\nreliten recode (3)\n0.43\n0.06\n(0.30, 0.55)\n6.68\n&lt; .001\n\n\nreliten recode (4)\n0.65\n0.04\n(0.57, 0.72)\n16.23\n&lt; .001\n\n\npolviews recode (2)\n-0.10\n0.07\n(-0.23, 0.03)\n-1.49\n0.136\n\n\npolviews recode (3)\n-0.18\n0.07\n(-0.31, -0.04)\n-2.51\n0.012\n\n\npolviews recode (4)\n-0.21\n0.06\n(-0.33, -0.08)\n-3.23\n0.001\n\n\npolviews recode (5)\n-0.06\n0.07\n(-0.19, 0.07)\n-0.92\n0.359\n\n\npolviews recode (6)\n-0.25\n0.07\n(-0.39, -0.11)\n-3.46\n&lt; .001\n\n\npolviews recode (7)\n-0.31\n0.10\n(-0.51, -0.11)\n-3.02\n0.003\n\n\nwrkhome recode (2)\n0.21\n0.04\n(0.12, 0.29)\n4.57\n&lt; .001\n\n\nwrkhome recode (3)\n0.35\n0.05\n(0.26, 0.44)\n7.50\n&lt; .001\n\n\nwrkhome recode (4)\n0.44\n0.04\n(0.35, 0.52)\n9.76\n&lt; .001\n\n\nwrkhome recode (5)\n0.24\n0.04\n(0.15, 0.32)\n5.64\n&lt; .001\n\n\nwrkhome recode (6)\n0.40\n0.06\n(0.29, 0.51)\n7.20\n&lt; .001\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck for Overdispersion\nHint: performance package has the function you‚Äôre looking for\n\n\nCode\nperformance::check_overdispersion(model2)\n\n\n# Overdispersion test\n\n       dispersion ratio =   15.102\n  Pearson's Chi-Squared = 8804.224\n                p-value =  &lt; 0.001\n\n\nWhat do you notice? And what‚Äôs a good next step forward? Can there be another model class that can fit the data? If so, fit this model to the data.\n\nThere is overdispersion, which means there is more variation in the response than what‚Äôs implied by a Poisson model. We can try to fit a negative-binomial regression model.\n\n\n\nCode\nmodel3 = glm.nb(wwwhr~age+wordsum+sex_recode+reliten_recode+polviews_recode+wrkhome_recode, \n              data=data_pos2)\n\nmodel4 = MASS::glm.nb(wwwhr~age+wordsum+sex_recode+reliten_recode+polviews_recode+wrkhome_recode, \n              data=data_pos2)"
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#which-one-is-better--your-earlier-model-or-later-model",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#which-one-is-better--your-earlier-model-or-later-model",
    "title": "Lab: Poisson Regression",
    "section": "Which one is better- your earlier model, or later model?",
    "text": "Which one is better- your earlier model, or later model?\n\n\nCode\ntest_likelihoodratio(model2, model3) %&gt;%\n  kable()\n\n\n\n\n\n\nName\nModel\ndf\ndf_diff\nChi2\np\n\n\n\n\nmodel2\nmodel2\nglm\n18\nNA\nNA\nNA\n\n\nmodel3\nmodel3\nnegbin\n19\n1\n4510.038\n0\n\n\n\n\n\nCode\ntest_likelihoodratio(model2, model4) %&gt;%\n  kable()\n\n\n\n\n\n\nName\nModel\ndf\ndf_diff\nChi2\np\n\n\n\n\nmodel2\nmodel2\nglm\n18\nNA\nNA\nNA\n\n\nmodel4\nmodel4\nnegbin\n19\n1\n4510.038\n0\n\n\n\n\n\nThe later model is better here, which means the previous poisson model was not a good fit to the data."
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#what-is-zero-inflation-is-there-zero-inflation-in-your-chosen-model",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#what-is-zero-inflation-is-there-zero-inflation-in-your-chosen-model",
    "title": "Lab: Poisson Regression",
    "section": "What is zero inflation? Is there zero-inflation in your chosen model?",
    "text": "What is zero inflation? Is there zero-inflation in your chosen model?\n\n\nCode\nperformance::check_zeroinflation(model3)\n\n\n# Check for zero-inflation\n\n   Observed zeros: 40\n  Predicted zeros: 67\n            Ratio: 1.68\n\n\nThere is no zero-inflation here since # of observed zeros &lt; # of predicted zeros.\n\nLog LambdaMean Count\n\n\n\n\nCode\nprint(coef(model4))\n\n\n     (Intercept)              age          wordsum      sex_recode1 \n      1.72933133      -0.01630350       0.10573220       0.14429163 \n reliten_recode2  reliten_recode3  reliten_recode4 polviews_recode2 \n      0.28114285       0.38546776       0.62578244       0.17573144 \npolviews_recode3 polviews_recode4 polviews_recode5 polviews_recode6 \n      0.09431515      -0.04193018       0.13914802      -0.04427420 \npolviews_recode7  wrkhome_recode2  wrkhome_recode3  wrkhome_recode4 \n     -0.15510946       0.11140958       0.31377893       0.30530537 \n wrkhome_recode5  wrkhome_recode6 \n      0.15257360       0.25947760 \n\n\nCode\nprint(exp(coef(model4)))\n\n\n     (Intercept)              age          wordsum      sex_recode1 \n       5.6368834        0.9838287        1.1115242        1.1552210 \n reliten_recode2  reliten_recode3  reliten_recode4 polviews_recode2 \n       1.3246428        1.4703019        1.8697083        1.1921179 \npolviews_recode3 polviews_recode4 polviews_recode5 polviews_recode6 \n       1.0989060        0.9589367        1.1492942        0.9566916 \npolviews_recode7  wrkhome_recode2  wrkhome_recode3  wrkhome_recode4 \n       0.8563214        1.1178527        1.3685871        1.3570393 \n wrkhome_recode5  wrkhome_recode6 \n       1.1648282        1.2962527 \n\n\nCode\nmean(exp(predict(model4, type = \"link\")))\n\n\n[1] 9.879506\n\n\n\n\n\n\nCode\nprint(mean(data_pos2$wwwhr, na.rm = TRUE))\n\n\n[1] 9.792543\n\n\nCode\ndata_pos_base = data_pos2 %&gt;%\n  filter(sex_recode==-1, reliten_recode==1, polviews_recode==1, wrkhome_recode==1)\nmean(data_pos_base$wwwhr, na.rm = TRUE)\n\n\n[1] 5.4"
  },
  {
    "objectID": "posts/03-05 poisson/poisson_lab_questions-1.html#report-your-conclusions",
    "href": "posts/03-05 poisson/poisson_lab_questions-1.html#report-your-conclusions",
    "title": "Lab: Poisson Regression",
    "section": "Report your conclusions",
    "text": "Report your conclusions\nThe coefficients of the model is roughly similar to the log value of the mean of the dependent variable. The exponential of the intercept of the model is 5.637, while the mean number of hours per week that a person spends on the internet (wwwhr) for the baseline group (sex=-1, religosity=1, political_orientation=1, work_from_home=1) is 5.4.\nBecause of the numerous number of levels for different categorical variables, here we don‚Äôt look at each level. We can use our full model to predict the dependent variable, and then take the mean of the exponential, which is 9.880, while the mean wwwhr for the whole dataset is 9.793.\nOverall, a negative-binomial regression model is a good fit to the data due to dispersion. We don‚Äôt need to use a zero-inflated model since there is no zero-inflation."
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-glm",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-glm",
    "title": "Bayesian GLM",
    "section": "Bayesian GLM",
    "text": "Bayesian GLM\n\nBayesian Inference\nGeneralized Linear Models (GLMs)"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#likelihood",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#likelihood",
    "title": "Bayesian GLM",
    "section": "Likelihood",
    "text": "Likelihood\nHey\n\n\n\nPSY 504"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayes",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayes",
    "title": "Bayesian GLM",
    "section": "Bayes",
    "text": "Bayes\n\nHey\n\n\n\nPSY 504"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-inference",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-inference",
    "title": "Bayesian GLM",
    "section": "Bayesian Inference",
    "text": "Bayesian Inference\n\n\n\n\n\n\n\n\n\n\\(p(\\theta|y)\\propto p(y|\\theta)p(\\theta)\\)\n\n\n\\(p(\\theta)\\): prior distributions of the parameters\n\n\n\n\nprior beliefs or the prior knowledge on the parameter distributions, based on the existing knowledge or the results of previous studies\n\n\n\n\n\\(p(y|\\theta)\\): probability distribution of the data given the parameters\n\n\n\n\nThe likelihood function\n\n\n\n\n\\(p(\\theta|y)\\): posterior distributions of the parameters\n\n\n\n\nProportional to the prior distributions of the parameter times the likelihood function"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#hey",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#hey",
    "title": "Bayesian GLM",
    "section": "Hey",
    "text": "Hey\n\n\n\nPSY 504"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayes-rule",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayes-rule",
    "title": "Bayesian GLM",
    "section": "Bayes Rule",
    "text": "Bayes Rule\n\n\n\n\n\n\n\n\n\n\\(p(\\theta|y)\\propto p(y|\\theta)p(\\theta)\\)\n\n\n\\(p(\\theta)\\): prior distributions of the parameters\n\n\n\n\nPrior beliefs or the prior knowledge on the parameter distributions, based on the existing knowledge or the results of previous studies\n\n\n\n\n\\(p(y|\\theta)\\): probability distribution of the data given the parameters\n\n\n\n\nThe likelihood function\n\n\n\n\n\\(p(\\theta|y)\\): posterior distributions of the parameters\n\n\n\n\nProportional to the prior distributions of the parameter times the likelihood function"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-vs-freqeuntist-inference",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-vs-freqeuntist-inference",
    "title": "Bayesian GLM",
    "section": "Bayesian vs Freqeuntist Inference",
    "text": "Bayesian vs Freqeuntist Inference\n\n\nFrequentist\n\n\nObjective probability:\n\nThe limit of the relative frequency of an event occuring in a large number of trials\nProbabilities are inherent properties of the phenomena under consideration.\n\nParameter Estimation:\n\n\\(\\theta\\) is unknown and fixed\nUse sample data to estimate \\(\\theta\\) with a certain level of confidence\n\nHypothesis Testing:\n\nFormulating null and alternative hypotheses\nCollecting sample data\nMaking decisions based on the probability of observing the data under the assumption that the null hypothesis is true\n\n\n\n\nBayesian\n\n\nSetup: \\(\\theta\\) is a random variable with a distribution\nSubjective probability:\n\n\n\n\n\n\n\nPSY 504"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-vs-frequentist-inference",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-vs-frequentist-inference",
    "title": "Bayesian GLM",
    "section": "Bayesian vs Frequentist Inference",
    "text": "Bayesian vs Frequentist Inference\n\n\nFrequentist\n\n\nObjective probability:\n\n\n\n\nThe limit of the relative frequency of an event occuring in a large number of trials\nProbabilities are inherent properties of the phenomena under consideration.\n\n\n\nBayesian\n\n\nSubjective probability:\n\n\n\n\nReflects an individual‚Äôs degree of belief in the occurrence of an event\nUpdated as new evidence becomes available"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-vs-frequentist-inference-1",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-vs-frequentist-inference-1",
    "title": "Bayesian GLM",
    "section": "Bayesian vs Frequentist Inference",
    "text": "Bayesian vs Frequentist Inference\n\n\nFrequentist\n\n\nParameter Estimation:\n\n\n\n\n\\(\\theta\\) is unknown and fixed\nUse sample data to estimate \\(\\theta\\) with a certain level of confidence\n\n\n\nBayesian\n\n\nParameter Estimation:\n\n\n\n\nA probability distribution for the parameter of interest rather than a point estimate\nIncorporates information from both the prior distribution and the likelihood function derived from the observed data\n\n\n\n\n\n\n\nPSY 504"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference",
    "title": "Bayesian GLM",
    "section": "Frequentist vs Bayesian Inference",
    "text": "Frequentist vs Bayesian Inference\n\n\nFrequentist\n\n\nObjective probability:\n\n\n\n\nThe limit of the relative frequency of an event occuring in a large number of trials\nProbabilities are inherent properties of the phenomena under consideration.\n\n\n\nBayesian\n\n\nSubjective probability:\n\n\n\n\nReflects an individual‚Äôs degree of belief in the occurrence of an event\nUpdated as new evidence becomes available"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-1",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-1",
    "title": "Bayesian GLM",
    "section": "Frequentist vs Bayesian Inference",
    "text": "Frequentist vs Bayesian Inference\n\n\nFrequentist\n\n\nParameter Estimation:\n\n\n\n\nParameters are unknown and fixed\nDistinguish parameters from random variables\nUse sample data to estimate parameters with a certain level of confidence\n\n\n\nBayesian\n\n\nParameter Estimation:\n\n\n\n\nParameters are also random variables with probability distributions\nA fixed set of parameters implies a distribution over the data, \\(p(y|\\theta)\\)\nA fixed set of data implies a distribution over the parameters, \\(p(\\theta|y)\\)\nIncorporates information from both the prior distribution and the likelihood function"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-2",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-2",
    "title": "Bayesian GLM",
    "section": "Frequentist vs Bayesian Inference",
    "text": "Frequentist vs Bayesian Inference\n\n\nFrequentist\n\n\nHypothesis Testing:\n\n\n\n\nFormulating null and alternative hypotheses\nCollecting sample data\nMaking decisions based on the probability of observing the data under the assumption that the null hypothesis is true\np-values: probability of obtaining the observed data or more extreme data if the null is true\n\n\n\nBayesian\n\n\nBayesian Inference:\n\n\n\n\nDefine a prior distribution based on existing knowledge\nCollect sample data\nDevelop a likelihood function that describes the probability of observing the collected data given different values of the parameter\nUse Bayes‚Äô Theorem to update the prior distribution and obtain the posterior distribution\nMake inference about the parameter based on the posterior distribution"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-3",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-3",
    "title": "Bayesian GLM",
    "section": "Frequentist vs Bayesian Inference",
    "text": "Frequentist vs Bayesian Inference\n\n\nFrequentist\n\n\np-values:\n\n\n\n\nthe probability of obtaining the observed data or more extreme data under the assumption that the null hypothesis is true\n\n\n\n\nConfidence intervals:\n\n\n\n\ncontain the true parameter value with a certain frequency in repeated sampling\n\n\n\nBayesian\n\n\nposterior probabilities:\n\n\n\n\nthe probability of hypotheses given the data\n\n\n\n\nCredible intervals:\n\n\n\n\ncontain the true parameter value with a certain level of credibility based on the posterior distribution"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-4",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#frequentist-vs-bayesian-inference-4",
    "title": "Bayesian GLM",
    "section": "Frequentist vs Bayesian Inference",
    "text": "Frequentist vs Bayesian Inference\n\n\nFrequentist\n\n\nLimitations:\n\n\n\n\nSubjectivity in the null hypothesis choice\nConfidence intervals can be misinterpreted\nFixed Parameter Assumption\n\n\n\nBayesian\n\n\nAdvantages:\n\n\n\n\nIncorporating prior information\nUncertainty quantification\n\n\n\n\n\n\n\nPSY 504"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#why-bayesian",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#why-bayesian",
    "title": "Bayesian GLM",
    "section": "Why Bayesian?",
    "text": "Why Bayesian?\n\n\nFrequentist\n\n\nLimitations:\n\n\n\n\nSubjectivity in the null hypothesis choice\nConfidence intervals can be misinterpreted\nFixed Parameter Assumption\n\n\n\nBayesian\n\n\nAdvantages:\n\n\n\n\nIncorporating prior information\nUncertainty quantification"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#markov-chain-monte-carlo-mcmc",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#markov-chain-monte-carlo-mcmc",
    "title": "Bayesian GLM",
    "section": "Markov Chain Monte Carlo (MCMC)",
    "text": "Markov Chain Monte Carlo (MCMC)\n\n\nDeveloped in the 1940s by physicists at Los Alamos\nAn algorithm used to draw samples from a probability distribution\nMonte Carlo: Use random samples over a distribution to estimate solutions or perform simulations\nMarkov Chain: A sequence of random variables where the next state depends only on the current state\nGeneral procedure:\n\n\n\n\nStarts with an initial guess (or ‚Äúseed‚Äù) and iteratively propose new values based on the current value and the target distribution\nThese proposed values are accepted or rejected based on a probability that depends on the target distribution\nOver many iterations, the sequence of samples forms a distribution that approximates the target posterior distribution"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-glm-1",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-glm-1",
    "title": "Bayesian GLM",
    "section": "Bayesian GLM",
    "text": "Bayesian GLM\n\nBayesian Inference\nGeneralized Linear Models (GLMs)"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#generalized-linear-models-glms",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#generalized-linear-models-glms",
    "title": "Bayesian GLM",
    "section": "Generalized Linear Models (GLMs)",
    "text": "Generalized Linear Models (GLMs)\n\n\nExtends ordinary linear regression models\nA link function that connects the linear predictor and the expected value or mean of \\(y\\).\nExamples\n\n\n\n\nLogistic regression\nOrdinal regression\nMultinomial regression\nPoisson regression\nNegative binomial regression"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-logistic-regression",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#bayesian-logistic-regression",
    "title": "Bayesian GLM",
    "section": "Bayesian Logistic Regression",
    "text": "Bayesian Logistic Regression\n\n# load data\ndata &lt;- read.csv(\"logistic.csv\")\nhead(data) %&gt;% kable()\n\n\n\n\nage\nsex\nsei10\npolviews\nmass_trans_spend_right\n\n\n\n\n47\nMale\n87.9\nModerate\n0\n\n\n61\nMale\n38.3\nLiberal\n0\n\n\n43\nFemale\n21.8\nModerate\n0\n\n\n55\nFemale\n39.7\nSlightly liberal\n0\n\n\n53\nFemale\n44.6\nSlightly liberal\n1\n\n\n50\nMale\n80.7\nSlightly liberal\n0"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#fitting-logistic",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#fitting-logistic",
    "title": "Bayesian GLM",
    "section": "Fitting Logistic",
    "text": "Fitting Logistic\nFrequentist Logistic Regression\n\nlog_model_freq = glm(\n  mass_trans_spend_right ~ 1 + age + sex + sei10,\n  family=binomial,\n  data=data\n)\n\nBayesian Logistic Regression\n\ninvisible({capture.output({\n\nlog_model_bay = brm(\n  mass_trans_spend_right ~ 1 + age + sex + sei10,\n  family=bernoulli(link=\"logit\"),\n  data=data,\n  warmup=500,\n  iter=2000,\n  cores=2,\n  chains=2,\n  seed=123\n)\n\n})})"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#evaluating-logistic",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#evaluating-logistic",
    "title": "Bayesian GLM",
    "section": "Evaluating Logistic",
    "text": "Evaluating Logistic\n\n\n\ntab_model(log_model_freq)\n\n\n\n\n¬†\nmass_trans_spend_right\n\n\nPredictors\nOdds Ratios\nCI\np\n\n\n(Intercept)\n2.28\n1.74¬†‚Äì¬†3.00\n&lt;0.001\n\n\nage\n0.99\n0.99¬†‚Äì¬†1.00\n0.007\n\n\nsex [Male]\n0.77\n0.66¬†‚Äì¬†0.91\n0.001\n\n\nsei10\n0.99\n0.99¬†‚Äì¬†1.00\n&lt;0.001\n\n\nObservations\n2590\n\n\nR2 Tjur\n0.014\n\n\n\n\n\n\n\n\n\ntab_model(log_model_bay)\n\n\n\n\n¬†\nmass_trans_spend_right\n\n\nPredictors\nOdds Ratios\nCI (95%)\n\n\nIntercept\n2.28\n1.74¬†‚Äì¬†2.98\n\n\nage\n0.99\n0.99¬†‚Äì¬†1.00\n\n\nsex: Male\n0.77\n0.66¬†‚Äì¬†0.91\n\n\nsei10\n0.99\n0.99¬†‚Äì¬†1.00\n\n\nObservations\n2590\n\n\nR2 Bayes\n0.015"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#marginal-effects",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#marginal-effects",
    "title": "Bayesian GLM",
    "section": "Marginal Effects",
    "text": "Marginal Effects\n\n\n\n# predicted probability\npp_sex &lt;- ggemmeans(log_model_freq, terms = c(\"sex\"))\nggplot(pp_sex, aes(x = x, y = predicted, color = x)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +\n  labs(title = \"Effect of Sex on Satisfaction with Mass Transportation\",\n       x = \"Sex\", y = \"Predicted Probability\",\n       color = \"Sex\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n# marginal effects\nce = conditional_effects(log_model_bay, effects=\"sex\")\nplot(ce, ask = FALSE)"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#marginal-effects-1",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#marginal-effects-1",
    "title": "Bayesian GLM",
    "section": "Marginal Effects",
    "text": "Marginal Effects\n\n\n\n# predicted probability\npp_ses &lt;- ggemmeans(log_model_freq, terms = \"sei10 [all]\")\nggplot(pp_ses, aes(x = x, y = predicted)) +\n  geom_line(color = \"#2c7fb8\", size = 1) + \n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = \"#2c7fb8\", alpha = 0.2) +  # Add a confidence interval band\n  labs(title = \"Effect of SES on Satisfaction with Mass Transportation\",\n       x = \"Socioeconomic Status\", y = \"Predicted Probability\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")  \n\n\n\n\n\n\n\n\n\n\n# marginal effects\nce = conditional_effects(log_model_bay, effects=\"sei10\")\nplot(ce, ask = FALSE)"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#plotting-parameters",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#plotting-parameters",
    "title": "Bayesian GLM",
    "section": "Plotting Parameters",
    "text": "Plotting Parameters\nParameter distribution\n\n\n\nmcmc_plot(log_model_bay, type=\"intervals\")\n\n\n\n\n\n\n\n\n\n\nmcmc_plot(log_model_bay, type=\"hist\", bins=30)\n\n\n\n\n\n\n\n# mcmc_plot(log_model_bay, type=\"dens\")"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#plotting-parameters-1",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#plotting-parameters-1",
    "title": "Bayesian GLM",
    "section": "Plotting Parameters",
    "text": "Plotting Parameters\n\n\nTrace\n\nmcmc_plot(log_model_bay, type=\"trace\")"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#plotting-parameters-2",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#plotting-parameters-2",
    "title": "Bayesian GLM",
    "section": "Plotting Parameters",
    "text": "Plotting Parameters\n\n\nTwo parameters\n\nmcmc_plot(log_model_bay, variable=c(\"b_Intercept\", \"b_age\"), type=\"scatter\")"
  },
  {
    "objectID": "posts/03-31 bayesian GLM/bayesian glm.html#other-glms",
    "href": "posts/03-31 bayesian GLM/bayesian glm.html#other-glms",
    "title": "Bayesian GLM",
    "section": "Other GLMs",
    "text": "Other GLMs\nLots of Bayesian GLMs, all in one package!\n\nmodel = brm(\n  y ~ 1 + x1 + x2 + x3 + (1+x4|x3), # multilevel\n  family=bernoulli(link=\"logit\"), # logistic\n  family=cumulative(link=\"logit\"), # ordinal\n  family=categorical(link=\"logit\"), # multinomial\n  family=poisson(link=\"log\"), # poisson\n  family=negbinomial(link=\"log\") # negative binomial\n  family=zero_inflated_poisson(link=\"log\") # zero-inflated poisson\n  family=zero_inflated_negbinomial(link=\"log\") # zero-inflated negbinom\n  data=data,\n  warmup=500,\n  iter=2000,\n  cores=2,\n  chains=2,\n  seed=123\n)\n\n\n\n\nPSY 504"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html",
    "title": "MLM2 - Answer Walkthrough",
    "section": "",
    "text": "Today‚Äôs lab uses data from a study conducted by Coyne et al.¬†(2019), which examined the impact of a high-quality, evidence-based vocabulary instruction intervention in kindergarten. The data consists of 1,428 students who were nested in 233 clusters or classrooms (clu_id).\nIn the sample of at-risk youth in the classroom (N = 6), half were allocated to treatment and the other half to control. The treatment group received supplemental small-group vocabulary instruction in addition to the whole-group instruction, while the control group received only whole-group vocabulary instruction. Since the observations were not independent (due to students being nested within classrooms), the researchers needed to account for this in their analysis.\nThe main question that the researchers aimed to answer was whether the supplemental small-group kindergarten vocabulary instruction intervention increased students‚Äô knowledge of the vocabulary words taught in the intervention. To measure vocabulary knowledge, the researchers used an ETW (ETW_SpringK) assessment, which evaluated students‚Äô ability to explain the meaning of a given word. The assessment was administered after the intervention concluded, in the spring of kindergarten. In the sample, ETW scores ranged from 0 to 52 (the maximum score), with a mean of 13.65 and a standard deviation of 11.10. To answer the research question, the researchers used two fixed effects and their interaction: TRT (1 = treatment and 0 = control) and PPVT (Peabody Picture Vocabulary Test, which measures students‚Äô vocabulary before the intervention; PPVT_FallK).\nCoyne, M. D., McCoach, D. B., Ware, S., Austin, C. R., Loftus-Rattan, S. M., & Baker, D. L. (2019). Racing Against the Vocabulary Gap: Matthew Effects in Early Vocabulary Instruction and Intervention. Exceptional Children, 85(2), 163‚Äì179. https://doi.org/10.1177/0014402918789162\n\n\n\n\nCode\n# fill in packages you need as you go here\nlibrary(tidyverse) # data wrangling\nlibrary(knitr) # nice tables\nlibrary(patchwork) # combine figures\nlibrary(lme4) # fit mixed models\nlibrary(lmerTest) # mixed models\nlibrary(broom.mixed) # tidy output of mixed models\nlibrary(afex) # fit mixed models for lrt test\nlibrary(emmeans) # marginal means\nlibrary(ggeffects) # marginal means\nlibrary(ggrain) # rain plots\nlibrary(easystats) # nice ecosystem of packages\nlibrary(interactions)\n\n\n\n\n\n\n\nCode\n# read in data file\ndata &lt;- read.csv(\"Ch3_MLM_R.csv\")"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#load-packages",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#load-packages",
    "title": "MLM2 - Answer Walkthrough",
    "section": "",
    "text": "Code\n# fill in packages you need as you go here\nlibrary(tidyverse) # data wrangling\nlibrary(knitr) # nice tables\nlibrary(patchwork) # combine figures\nlibrary(lme4) # fit mixed models\nlibrary(lmerTest) # mixed models\nlibrary(broom.mixed) # tidy output of mixed models\nlibrary(afex) # fit mixed models for lrt test\nlibrary(emmeans) # marginal means\nlibrary(ggeffects) # marginal means\nlibrary(ggrain) # rain plots\nlibrary(easystats) # nice ecosystem of packages\nlibrary(interactions)"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#load-data",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#load-data",
    "title": "MLM2 - Answer Walkthrough",
    "section": "",
    "text": "Code\n# read in data file\ndata &lt;- read.csv(\"Ch3_MLM_R.csv\")"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#data-structure",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#data-structure",
    "title": "MLM2 - Answer Walkthrough",
    "section": "Data structure",
    "text": "Data structure\nQ1. What are the Level 1 and Level 2 variables in this study? How many units are in Level 1? Level 2? Are the fixed effects at Level 1 or Level 2?\nQ2. What are the Level 1 and Level 2 variables in this study? How many units are in Level 1? Level 2? Are the fixed effects at Level 1 or Level 2?\nAnswers:\n\nLevel 1 variables: ETW_SpringK, TRT, and PPVT_FallK.\nThere are 1,427 units in Level 1. There are 222 units in Level 2.\nThe fixed effects are at Level 1 because they pertain to the individual student-level variables and their interactions.\n\n\n\nCode\n# Computing Dataset Statistics:\n\n# assuming 'data' is the dataframe and 'clu_id' identifies the clusters/classrooms\nsummary_stats &lt;- data %&gt;%\n  group_by(clu_id) %&gt;%\n  summarise(N_students = n()) %&gt;%\n  ungroup() %&gt;%\n  summarise(\n    N_clusters = n(),\n    Total_students = sum(N_students),\n    Average_students_per_classroom = mean(N_students),\n    SD_students_per_classroom = sd(N_students),\n    Min_students_in_classroom = min(N_students),\n    Max_students_in_classroom = max(N_students)\n  )\n\n# Extracting the values to variables for easier printing\nn_clusters &lt;- summary_stats$N_clusters\ntotal_students &lt;- summary_stats$Total_students\naverage_students &lt;- summary_stats$Average_students_per_classroom\nsd_students &lt;- summary_stats$SD_students_per_classroom\nmin_students &lt;- summary_stats$Min_students_in_classroom\nmax_students &lt;- summary_stats$Max_students_in_classroom\n\n\n\n\nCode\ncat(\"Number of clusters (classrooms):\", n_clusters, \"\\n\")\n\n\nNumber of clusters (classrooms): 222 \n\n\n\n\nCode\ncat(\"Total number of students:\", total_students, \"\\n\")\n\n\nTotal number of students: 1427 \n\n\n\n\nCode\ncat(\"Average number of students per classroom:\", round(average_students, 1), \"\\n\")\n\n\nAverage number of students per classroom: 6.4 \n\n\n\n\nCode\ncat(\"Standard deviation of students per classroom:\", round(sd_students, 1), \"\\n\")\n\n\nStandard deviation of students per classroom: 2.2 \n\n\n\n\nCode\ncat(\"Minimum number of students in a classroom:\", min_students, \"\\n\")\n\n\nMinimum number of students in a classroom: 2 \n\n\n\n\nCode\ncat(\"Maximum number of students in a classroom:\", max_students, \"\\n\")\n\n\nMaximum number of students in a classroom: 18"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#deviation-code-0.5--0.5-aka-effect-code-for-the-treatment-variable",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#deviation-code-0.5--0.5-aka-effect-code-for-the-treatment-variable",
    "title": "MLM2 - Answer Walkthrough",
    "section": "2. Deviation code (0.5, -0.5), aka effect code for the treatment variable",
    "text": "2. Deviation code (0.5, -0.5), aka effect code for the treatment variable\n\n\n\n\n\n\nNote\n\n\n\nNOTE: Deviation/Effect coding is one way to recode categorical variables for regression analysis. They transform the treatment variable (TRT) from: treatment ‚Üí 0.5 control ‚Üí -0.5\nRemember that different ways of coding categorical variables do not actually influence the results/ predictions. But they can influence how we interpret coefficients.\nNow, with deviation coding (-0.5,0.5), here: Intercept = grand mean across all groups Treatment coefficient = difference between groups (divided by 2)\nWith dummy coding (0/1), it‚Äôd be: Intercept = mean of reference group Treatment coefficient = difference from reference group\nThe key advantage? When interpreting interactions, deviation coding makes results more intuitive since coefficients show deviations from overall means (or overall main effect) rather than from a reference group (which may not always be clear or relevant, making interpretation harder) .\n\n\n\n\nCode\n#deviation code the TRT var\ndata &lt;- data %&gt;%\n  mutate(TRT = ifelse(TRT == 1, 0.5, -0.5))\n\n# Note, one can also use contr.sum to instantiate such codings. \n# Contr.sum defaults to -1/1 coding (not 0,1).\ndata$TRT &lt;- factor(data$TRT)\ncontrasts(data$TRT) &lt;- contr.sum(2)/2"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#group-mean-center-ppvt_fallk",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#group-mean-center-ppvt_fallk",
    "title": "MLM2 - Answer Walkthrough",
    "section": "3. Group mean center PPVT_Fallk",
    "text": "3. Group mean center PPVT_Fallk\nQ3. Insert code below to center the variable PPVT_Fallk within the clusters/classrooms\nAnswer:\n\n\nCode\n#within-clustering centering\ndata$clu_id &lt;- as.factor(data$clu_id)\n\ndata &lt;- data %&gt;%\n  group_by(clu_id) %&gt;%\n  mutate(PPVT_FallK_centered = PPVT_FallK - mean(PPVT_FallK, na.rm = TRUE)) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#visualizations",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#visualizations",
    "title": "MLM2 - Answer Walkthrough",
    "section": "Visualizations",
    "text": "Visualizations\nQ4. Create two nicely looking visualizations: One for the relationship between PPTV and EWR and one for the relationship between TRT and EWR. Make sure you plot the between-cluster (class) variability when you graph these (given how many clusters there are, randomly sample 20 of them to plot).\nAnswerS:\n\n\nCode\n# fig 1\n# Randomly sample 20 clusters to plot\nset.seed(500) # for reproducibility\nclusters_sample &lt;- data %&gt;%\n  distinct(clu_id) %&gt;%\n  mutate(clu_id = as.character(clu_id)) %&gt;%\n  sample_n(20) %&gt;%\n  pull(clu_id)\n\ndata_sample &lt;- data %&gt;%\n  filter(clu_id %in% clusters_sample)\n\nggplot(data_sample, aes(x = PPVT_FallK, y = ETW_SpringK, group = clu_id)) +\n  geom_point(aes(color = as.factor(clu_id))) +\n  geom_smooth(method = \"lm\", se = FALSE, aes(group = clu_id, color = as.factor(clu_id))) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"PPTV scores vs EWR scores by classroom\", x = \"PPTV scores\", y = \"EWR scores\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\n# fig 2\n# bubble plots\n# PPVT_FallK and ETW_SpringK\np1_df &lt;- data %&gt;%\n  group_by(clu_id) %&gt;%\n  summarise(\n    mean_PPVT_FallK = mean(PPVT_FallK, na.rm = TRUE),\n    mean_ETW_SpringK = mean(ETW_SpringK, na.rm = TRUE),\n    n_students = n())\n\np1 = ggplot(p1_df, aes(x = mean_PPVT_FallK, y = mean_ETW_SpringK, size = n_students)) +\n  geom_point(alpha = .5, color = \"#6096ba\") +\n  scale_size_continuous(range = c(1, 12), guide = \"none\") +\n  labs(title = \"Peabody Picture Vocabulary Test (PPVT) Scores by\\nExpressive Target Word Measure (ETW)\",\n       x = \"Mean PPVT\",\n       y = \"Mean ETW\") +\n  theme_classic() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12)\n  )\n\n# ETW_SpringK and TVT\np2_df = data %&gt;%\n  group_by(clu_id, TRT) %&gt;%\n  summarise(mean_ETW_SpringK = mean(ETW_SpringK, na.rm = TRUE),\n            n_students = n())\n\n\n`summarise()` has grouped output by 'clu_id'. You can override using the\n`.groups` argument.\n\n\nCode\np2 = ggplot(p2_df, aes(x = factor(TRT), y = mean_ETW_SpringK)) +\n  ggdist::stat_halfeye(\n    adjust = .5,\n    width = .4,\n    .width = 0,\n    justification = -.9,\n    point_colour = NA,\n    fill = \"#6096ba\"\n  ) +\n  geom_point(aes(group = factor(clu_id), size = n_students), position = position_jitter(width = 0.05)) +\n  guides(size = \"none\") +\n  labs(title = \"Expressive Target Word Measure (ETW) Scores\\nby Condition\",\n       x = \"Condition\",\n       y = \"\") +\n  scale_x_discrete(labels = c(\"Control\", \"Treatment\")) +\n  theme_classic() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12)\n  )\n\ncombined_plot = p1 | p2\n\ncaption_text = \"Figure 1.\\nA: Mean classroom scores on the PPVT and ETW. Each 'bubble' represents a cluster or classroom.\\nB: ETW scores by experimental condition. Each bubble represents the average ETW score for a classroom.\\nLarger bubbles represent pairs containing more students.\"\n\nannotated_plot = combined_plot &\n  plot_annotation(\n    tag_levels = \"A\",\n    caption = caption_text,\n    theme = theme(\n      plot.caption = element_text(size = 12, hjust = 0)\n    )\n  )\n\nannotated_plot"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#model-comparisons",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#model-comparisons",
    "title": "MLM2 - Answer Walkthrough",
    "section": "Model comparisons",
    "text": "Model comparisons\nQ5. Fit an unconditional means (null model), and print its summary\n\n\n\n\n\n\nTip\n\n\n\nmake sure you have loaded lmerTest to get p-values\nWhen you load lmerTest, it modifies how summary() works on lmer models. This happens automatically, and there isn‚Äôt a specific new function you need to call.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe ‚Äúmodel‚Äù with linear regression sets the intercept to be mean The unconditional means ‚Äúnull model‚Äù ends up setting the group intercepts to group means. Neither of these models have slopes.\nNull model in lm() ‚Äî lm(Y ~ 1) Null model in lmer() ‚Äî lm(Y ~ 1 + (1|grouping_factor))\nREML (Restricted Maximum Likelihood) is better for variance estimation - and that‚Äôs exactly what null models are trying to do for the data without considering any fixed effect predictor. So, choose REML in your lmer call.\n\n\n::: Answer. ::: cell\n\n\nCode\nmodel1 &lt;- lmer(ETW_SpringK ~ 1 + (1|clu_id),\n               data = data)\nsummary(model1)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ETW_SpringK ~ 1 + (1 | clu_id)\n   Data: data\n\nREML criterion at convergence: 10855.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.8972 -0.6979 -0.2156  0.5325  3.5095 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n clu_id   (Intercept)  19.91    4.462  \n Residual             104.43   10.219  \nNumber of obs: 1427, groups:  clu_id, 222\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)  13.7248     0.4094 201.4834   33.52   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n:::\nQ6. The intraclass correlation coefficient (ICC) measures proportion of total variance due to group membership Calculate it manually for the fitted model from the output, and print it out. Is multilevel modeling warranted here?\n\n\n\n\n\n\nTip\n\n\n\nA common heuristic: ICC &lt; 0.05 = Probably not needed ICC &gt; 0.05-0.1 = Multilevel warranted ICC &gt; 0.1 = Strong indication for multilevel models.\n\n\n\n\nCode\n#TYPE YOUR CODE BELOW\n# a. Extract the variance components from the model output\n# b. Calculate ICC\n\n\nNow use the icc function in easystats / performance package to calculate the icc\nAnswers:\n\n\nCode\n# Extract the variance components from the model output\ncluster_variance &lt;- 19.91\nresidual_variance &lt;- 104.43\n\n# Calculate ICC\nicc &lt;- cluster_variance / (cluster_variance + residual_variance)\nround(icc, 4)\n\n\n[1] 0.1601\n\n\nNow use the icc function in easystats / performance package to calculate the icc\n\n\nCode\n#easystats\nperformance::icc(model1)\n\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.160\n  Unadjusted ICC: 0.160\n\n\nIs multilevel modeling warranted here? Yep! What does the ICC mean? It tells us how much variability there is between clusters. It also tells how how correlated our level 1 units are to one another. In this case, we have observe an ICC of 0.160, which indicates that 16% of the total variance in our outcome variable (students‚Äô vocabulary knowledge scores ETW_SpringK) is attributable to differences between classroom (Level 2 variance).\nQ7. Build up from the last model. Fit a model that includes all level 1 variables (no interaction)\n\n\nCode\n#Type your code here\n\n\n\n\n\n\n\n\nTip\n\n\n\nTip: You‚Äôre building from the last model. So you‚Äôre building on the clustering structure. So, you‚Äôd make sure to keep the random intercept intact.\n\n\n\n\n\n\n\n\nTip\n\n\n\nMaximum likelihood (as opposed Restricted maximum likelihood is best once you begin to have fixed effects), so set your REML flag appropriately. By default it‚Äôs True.\n\n\nAnswer:\n\n\nCode\nlevel_1_model &lt;- lmer(ETW_SpringK ~ TRT + PPVT_FallK + (1|clu_id), data = data)\nsummary(level_1_model)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ETW_SpringK ~ TRT + PPVT_FallK + (1 | clu_id)\n   Data: data\n\nREML criterion at convergence: 10349.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4814 -0.6259 -0.1126  0.5149  3.9787 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n clu_id   (Intercept) 21.60    4.647   \n Residual             69.93    8.362   \nNumber of obs: 1427, groups:  clu_id, 222\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(&gt;|t|)    \n(Intercept)  -25.36477    3.95423 1398.06472  -6.415 1.93e-10 ***\nTRT1         -10.44860    0.45197 1250.92146 -23.118  &lt; 2e-16 ***\nPPVT_FallK     0.46073    0.04665 1386.53443   9.876  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) TRT1  \nTRT1        0.022       \nPPVT_FallK -0.995 -0.020\n\n\nQ8. Fit a model that includes the fixed interaction between the level-1 variables\n\n\n\n\n\n\nNote\n\n\n\nNote, in case you‚Äôre ever counfused about this in R formulas format Y ~ A + B + A:B (main effects + interaction term) is the same as Y ~ A*B\n\n\nAnswer:\n\n\nCode\ninteraction_model &lt;- lmer(ETW_SpringK ~ TRT * PPVT_FallK + (1|clu_id), data = data)\nsummary(interaction_model)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ETW_SpringK ~ TRT * PPVT_FallK + (1 | clu_id)\n   Data: data\n\nREML criterion at convergence: 10339.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6149 -0.6202 -0.1202  0.5219  4.1549 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n clu_id   (Intercept) 21.66    4.655   \n Residual             69.25    8.322   \nNumber of obs: 1427, groups:  clu_id, 222\n\nFixed effects:\n                  Estimate Std. Error         df t value Pr(&gt;|t|)    \n(Intercept)      -25.30463    3.93672 1396.23691  -6.428 1.77e-10 ***\nTRT1              16.10042    7.33721 1244.64811   2.194   0.0284 *  \nPPVT_FallK         0.46021    0.04644 1384.47854   9.909  &lt; 2e-16 ***\nTRT1:PPVT_FallK   -0.31512    0.08693 1245.16526  -3.625   0.0003 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) TRT1   PPVT_F\nTRT1         0.005              \nPPVT_FallK  -0.995 -0.004       \nTRT1:PPVT_F -0.004 -0.998  0.002\n\n\nQ9. Compare the main effects and interaction models. Which model is the best? Try the likelihood ratio test, AIC and BIC, and jot down your thoughts.\nAnswer:\n\n\nCode\ntest_likelihoodratio(level_1_model, interaction_model, REML=FALSE)\n\n\nWarning: model3 are not supported models and have been dropped.\n\n\n# Likelihood-Ratio-Test (LRT) for Model Comparison (ML-estimator)\n\nName   |           Model | df | df_diff |  Chi2 |      p\n--------------------------------------------------------\nmodel1 | lmerModLmerTest |  5 |         |       |       \nmodel2 | lmerModLmerTest |  6 |       1 | 13.11 | &lt; .001\n\n\n\n\n\n\n\n\nTip\n\n\n\nAIC and BIC can be used with the models you‚Äôve already fitted.\nHowever, for likelihood ratio tests of nested models, Maximum likelihood (as opposed Restricted maximum likelihood) is best for model comparison. So such a likelihood ratio test will require models to be re-fit with REML=TRUE, just to give better model comparison results. )\n\n\nAnswer: - The interaction model is statistically superior to the main effects model, as indicated by lower AIC and BIC scores. This is further confirmed by a statistically significant likelihood ratio test (\\(\\chi^2 = 8.39, p = .0038\\)). This suggests that including the interaction between TRT and PPVT_FallK provides a better fit to the data.\nQ10. Use the best model from above and fit a model that adds random slopes for TRT\nAnswer:\n\n\nCode\nbest_model &lt;- lmer(ETW_SpringK ~ TRT * PPVT_FallK + (1+ TRT|clu_id), data = data)\n\n\nNext, let‚Äôs create a model with a random slope for treatment and PPVT scores. This will be our maximal model.\n\n\n\n\n\n\nWarning\n\n\n\nWe could include a random slope for the interaction between the two, but we only have 6 students per classroom and makes our model too complex.\n\n\n\n\nCode\ncomplex_model &lt;- lmer(ETW_SpringK ~ TRT * PPVT_FallK + (1 + TRT + PPVT_FallK|clu_id), data = data)\n\n\nboundary (singular) fit: see help('isSingular')\n\n\n\nisSingular(complex_model)\n\n[1] TRUE\n\n\nTake a look at the maximal model output. What is the warning message? We observe that the more complex model has a singular fit, which likely results from overfitting the data. In particular, the more complex model contains random slopes for both TRT and PPVT_FallK within clusters (clu_id). We can infer that there is not enough variation in TRT or PPVT_FallK within clusters, so the model may not be able to estimate random effects reliably. To get rid of this warning, we could reduce complexity in the model by removing some of the random slopes."
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#model-interpretation",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#model-interpretation",
    "title": "MLM2 - Answer Walkthrough",
    "section": "Model interpretation",
    "text": "Model interpretation\nThrough model comparisons like before, we can tell that the model with random slopes for TRT and random intercepts for classroom is the best. Now let‚Äôs use this best model and examine the fixed effects.\nQ 11. Please interpret these effects/coefs in a sentence or two.\n\n\nCode\n# fit the best model and output a nice summary table of results.\nlibrary(afex) # load afex in\n\nm &lt;- mixed(ETW_SpringK ~ TRT * PPVT_FallK + (1+ TRT|clu_id), data=data)\n\n\nContrasts set to contr.sum for the following variables: TRT, clu_id\n\n\nNumerical variables NOT centered on 0: PPVT_FallK\nIf in interactions, interpretation of lower order (e.g., main) effects difficult.\n\n\nCode\nnice(m) %&gt;%\n  kable()\n\n\n\n\n\nEffect\ndf\nF\np.value\n\n\n\n\nTRT\n1, 1248.94\n3.15 +\n.076\n\n\nPPVT_FallK\n1, 1247.01\n112.04 ***\n&lt;.001\n\n\nTRT:PPVT_FallK\n1, 1244.19\n10.76 **\n.001\n\n\n\n\n\n\n\nCode\nemtrends(best_model, ~TRT, var=\"PPVT_FallK\") %&gt;%\n  test() %&gt;%\n  kable()\n\n\n\n\n\nTRT\nPPVT_FallK.trend\nSE\ndf\nt.ratio\np.value\n\n\n\n\n-0.5\n0.3120067\n0.0565135\n1180.010\n5.520926\n0\n\n\n0.5\n0.5827390\n0.0617509\n1167.729\n9.436926\n0\n\n\n\n\n\nLet‚Äôs evaluate the variance components of the model.\n\n\nCode\nmodel_parameters(best_model, effects=\"random\") %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nEffects\nGroup\n\n\n\n\nSD (Intercept)\n4.7798625\nNA\n0.95\nNA\nNA\nrandom\nclu_id\n\n\nSD (TRT1)\n6.6910483\nNA\n0.95\nNA\nNA\nrandom\nclu_id\n\n\nCor (Intercept~TRT1)\n-0.8922365\nNA\n0.95\nNA\nNA\nrandom\nclu_id\n\n\nSD (Observations)\n7.5474782\nNA\n0.95\nNA\nNA\nrandom\nResidual\n\n\n\n\n\nQ12. How do you interpet the modeling results, in terms of varaince in intercept, treatment effect, and residuals?\nAnswers: - The variance is 25.01 for the intercepts across the different classrooms (clu_id). This suggests there is substantial variability in the baseline ETW_SpringK scores that can be attributed to differences between classrooms before considering TRT or PPVT_FallK scores.\n\nThe variance associated with the treatment effect (TRT) across classrooms is 45.51. This suggests significant variability in how the treatment effect on ETW_SpringK scores differs from one classroom to another.\nThe variance of residuals is 57.02. This indicates the remaining within-classroom variance in student scores that cannot be explained by the model‚Äôs fixed effects or the classroom-level random effects.\nOverall, our variance components are significant for both the random intercept and slope for TRT. This suggests that multilevel modeling is, indeed, appropriate and necessary to account for the clustering of student scores within classrooms and the variability in treatment effects across classrooms."
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#model-fit",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#model-fit",
    "title": "MLM2 - Answer Walkthrough",
    "section": "Model fit",
    "text": "Model fit\nWe can then calculate the conditional and marginal pseudo-\\(R^2\\) of the model\n\n\nCode\nr2(best_model)\n\n\n# R2 for Mixed Models\n\n  Conditional R2: 0.543\n     Marginal R2: 0.262\n\n\nThe semi-\\(R^2\\) for the PPVT variable is calculated using the partR2 function from partR2 package\n\n\nCode\nlibrary(partR2)\npartR2(best_model, data = data, partvars = c(\"PPVT_FallK\"), R2_type = \"marginal\")\n\n\n\n\nR2 (marginal) and 95% CI for the full model: \n R2     CI_lower CI_upper nboot ndf\n 0.2619 NA       NA       1     4  \n\n----------\n\nPart (semi-partial) R2:\n Predictor(s) R2     CI_lower CI_upper nboot ndf\n Model        0.2619 NA       NA       1     4  \n PPVT_FallK   0.0000 NA       NA       1     4  \n\n\nWe can visualize the random intercepts and slopes in your model\n\n\nCode\nrandom &lt;- estimate_grouplevel(best_model)\nplot(random) + theme_lucid()"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#assumptions",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#assumptions",
    "title": "MLM2 - Answer Walkthrough",
    "section": "Assumptions",
    "text": "Assumptions\nQ12. Check model assumptions with check_model. Do any of the assumptions appear to be violated?\n\n\nCode\ncheck_model(best_model)\n\n\n\n\n\n\n\n\n\nAnswer:\nWe can also visualize the interaction between TRT and PPVT score on ETW (I would check out the interactions or ggeffects packages. They have some nice features for plotting interactions.)\n\n\nCode\ninteract_plot(best_model, pred = \"PPVT_FallK\", modx = \"TRT\", data = data)"
  },
  {
    "objectID": "posts/03-26 mlm 2/MLM2_Ans.html#reporting-results",
    "href": "posts/03-26 mlm 2/MLM2_Ans.html#reporting-results",
    "title": "MLM2 - Answer Walkthrough",
    "section": "Reporting Results",
    "text": "Reporting Results\nQ14. Briefly highlight what you think needs to be present in the results. I will share what a complete report would like in the solution.\nWrite-up the results of your MLM model incorporating the above information. This write-up should resemble what you would find in a published paper. You can use the textbook for guidance and the report function from easystats\nThe present study investigated the impact of a vocabulary instruction intervention on students‚Äô knowledge, using a nested data structure with two levels: students (Level 1) nested within classrooms (Level 2). The analysis included 1,427 students distributed across 222 classrooms. Classrooms varied in size, with an average of approximately 6.4 students per classroom (\\(SD = 2.2, range = [2, 18]\\)).\nThe relationship between the intervention and vocabulary knowledge was modeled using a multilevel linear model, represented by the following equation:\n\n\nCode\nequatiomatic::extract_eq(best_model)\n\n\n\\[\n\\begin{aligned}\n  \\operatorname{ETW\\_SpringK}_{i}  &\\sim N \\left(\\mu, \\sigma^2 \\right) \\\\\n    \\mu &=\\alpha_{j[i]} + \\beta_{1j[i]}(\\operatorname{TRT}_{\\operatorname{1}}) + \\beta_{2}(\\operatorname{PPVT\\_FallK}) + \\beta_{3}(\\operatorname{PPVT\\_FallK} \\times \\operatorname{TRT}_{\\operatorname{1}}) \\\\    \n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{1j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\mu_{\\alpha_{j}} \\\\\n      &\\mu_{\\beta_{1j}}\n    \\end{aligned}\n  \\end{array}\n\\right)\n,\n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{1j}} \\\\\n     \\rho_{\\beta_{1j}\\alpha_{j}} & \\sigma^2_{\\beta_{1j}}\n  \\end{array}\n\\right)\n\\right)\n    \\text{, for clu\\_id j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]\n\n\nwhere \\(ETW\\_SpringK\\) is the student‚Äôs score on the vocabulary knowledge assessment, \\(TRT\\) is the treatment condition, \\(PPVT\\_FallK\\) is the Peabody Picture Vocabulary Test score, and \\((1 + TRT|clu\\_id)\\) represents the random intercepts and slopes for treatment across classrooms. Note that \\(ETW\\_SpringK\\), \\(TRT\\), and \\(PPVT\\_FallK\\) are all Level 1 variables, and \\(clu\\_id\\) is at Level 2. For the above analysis, we mean centered \\(PPVT\\_FallK\\) within each cluster and deviation coded \\(TRT\\).\nBefore settling on the above model, we estimated an unconditional means (null) model and maximal model, which included a random slope for both treatment and PPVT scores. We compared the above model (\\(df = 8\\)) to the maximal model (\\(df = 11\\)) using a likelihood ratio test from the easystats package (version 0.6.0). We found that the more complex model did not significantly improve model fit (\\(\\chi^2 = 4.85, p = 0.185\\)). We therefore proceeded to use the simpler model for our analyses, as there was not sufficient evidence to justify additional complexity in our model.\nWe checked our model assumptions (linearity, normality of residuals, homoscedasticity, collinearity) visually, using diagnostic plots from the performance package (version 0.10.5). Based on this visual assessment, we found that all our model assumptions were satisfied. The Intraclass Correlation Coefficient (ICC) for the outcome variable was calculated as 0.16, suggesting that 16% of the variance in vocabulary knowledge scores could be attributed to differences between classrooms. The models were estimated using Restricted Maximum Likelihood (REML) to account for the nested data structure. The lme4 package (version 1.1.34) was used for fitting the model, with the interactions package (version 1.1.5) for estimating and plotting interactions.\nThe fixed effects analysis revealed a significant intercept (\\(b = 13.47, SE = 0.40, t(209) = 34.03, p &lt; .001\\)), indicating a high baseline level of vocabulary knowledge. The treatment effect was also significant (\\(b = 10.47, SE = 0.62, t(213) = 17.02, p &lt; .001\\)), suggesting that the treatment had a substantial positive impact on vocabulary knowledge. Additionally, PPVT scores were positively associated with ETW scores (\\(b = 0.43, SE = 0.04, t(1091) = 9.67, p &lt; .001\\)), indicating that higher initial vocabulary levels were associated with higher post-intervention vocabulary knowledge. The interaction between treatment and PPVT scores was also significant (\\(b = 0.28, SE = 0.09, t(1074) = 3.06, p = .002\\)), suggesting that the treatment effect varied as a function of initial vocabulary levels.\nRegarding random effects, we observe a variance of 25.01 (\\(SD = 5.00\\)) for the intercepts across the different classrooms. This suggests there is substantial variability in the baseline ETW scores that can be attributed to differences between classrooms before considering treatment or PPVT scores. The variance associated with the treatment effect (\\(SD = 6.75\\)). This suggests significant variability in how the treatment effect on ETW scores differs from across clasrooms. Finally, the variance of residuals was 57.02 (\\(SD = 7.55\\)), indicating within-classroom variance in student scores that cannot be explained by the model‚Äôs fixed effects or the classroom-level random effects. Overall, our variance components are significant for both the random intercept and slope for treatment. This suggests that multilevel modeling is, indeed, appropriate and necessary to account for the clustering of student scores within classrooms and the variability in treatment effects across classrooms.\nthe model estimated the standard deviation of the random intercepts for classrooms (\\(SD = 5.00\\)), indicating variability in baseline ETW scores across classrooms. The correlation between the random intercepts and slopes for treatment within classrooms was estimated to be 0.89, suggesting a strong positive relationship between the classroom baseline scores and the treatment effect. The standard deviation of the random slopes for treatment (\\(SD = 6.75\\)) indicated substantial variability in the treatment effect across classrooms. The residual standard deviation (\\(SD = 7.55\\)) reflected the within-classroom variability in ETW scores that was not explained by the model‚Äôs fixed and random effects.\nTaken together, these results suggest that both the treatment and initial PPVT scores are significant predictors of students‚Äô vocabulary knowledge. There was a notable interaction effect, suggesting that the benefit of the treatment varies depending on students‚Äô initial vocabulary levels. The significant random effects for treatment across classrooms underscore the intervention‚Äôs differential effectiveness depending on classroom context. These findings highlight the importance of considering both the individual and contextual factors in educational interventions. ```"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html",
    "title": "Bayes and Penguins",
    "section": "",
    "text": "Here is a worksheet and assignment that combines Bayes (brms) with tidyverse tools. The focus is on the essentials when it comes to simple linear regression with brms.\nPlease read and run through this worksheet and answer the conceptual questions that are interleaved within them. At the end of each part, is a coding exercise based on the material you‚Äôve read until then."
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#packages-and-data",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#packages-and-data",
    "title": "Bayes and Penguins",
    "section": "Packages and data",
    "text": "Packages and data\nLoad the primary packages.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.1     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.0.4     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggside)\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\nlibrary(brms)\n\nLoading required package: Rcpp\nLoading 'brms' package (version 2.22.0). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\nAttaching package: 'brms'\n\nThe following object is masked from 'package:stats':\n\n    ar\n\nlibrary(broom)\nlibrary(broom.mixed)\n\nWe‚Äôll use the penguins data set from the palmerpenguins package.\n\ndata(penguins, package = \"palmerpenguins\")\n\n# Any type of looking at data is a part of EDA \nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nYou might divide the data set by the three levels of species.\n\npenguins %&gt;% \n  count(species)\n\n# A tibble: 3 √ó 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nTo start, we‚Äôll make a subset of the data called chinstrap.\n\nchinstrap &lt;- penguins %&gt;% \n  filter(species == \"Chinstrap\")\n\nglimpse(chinstrap)\n\nRows: 68\nColumns: 8\n$ species           &lt;fct&gt; Chinstrap, Chinstrap, Chinstrap, Chinstrap, Chinstra‚Ä¶\n$ island            &lt;fct&gt; Dream, Dream, Dream, Dream, Dream, Dream, Dream, Dre‚Ä¶\n$ bill_length_mm    &lt;dbl&gt; 46.5, 50.0, 51.3, 45.4, 52.7, 45.2, 46.1, 51.3, 46.0‚Ä¶\n$ bill_depth_mm     &lt;dbl&gt; 17.9, 19.5, 19.2, 18.7, 19.8, 17.8, 18.2, 18.2, 18.9‚Ä¶\n$ flipper_length_mm &lt;int&gt; 192, 196, 193, 188, 197, 198, 178, 197, 195, 198, 19‚Ä¶\n$ body_mass_g       &lt;int&gt; 3500, 3900, 3650, 3525, 3725, 3950, 3250, 3750, 4150‚Ä¶\n$ sex               &lt;fct&gt; female, male, male, female, male, female, female, ma‚Ä¶\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nWe‚Äôve done from a full data set with \\(N = 344\\) rows, to a subset with \\(n = 68\\) rows. (‚Äú$‚Äù signs hold LaTex snippets)"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#more-exploratory-data-analysis-eda",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#more-exploratory-data-analysis-eda",
    "title": "Bayes and Penguins",
    "section": "More Exploratory data analysis (EDA)",
    "text": "More Exploratory data analysis (EDA)\nOur focal variables will be body_mass_g and bill_length_mm. Here they are in a scatter plot.\n\nchinstrap %&gt;% \n  ggplot(aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", formula = 'y ~ x', se = FALSE)\n\n\n\n\n\n\n\n\nWe can augment the plot with some nice functions from the ggside package.\n\nchinstrap %&gt;% \n  ggplot(aes(x = body_mass_g, y = bill_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", formula = 'y ~ x', se = FALSE) +\n  # from ggside\n  geom_xsidehistogram(bins = 30) +\n  geom_ysidehistogram(bins = 30) +\n  scale_xsidey_continuous(breaks = NULL) +\n  scale_ysidex_continuous(breaks = NULL) +\n  theme(ggside.panel.scale = 0.25)\n\n\n\n\n\n\n\n\nIt‚Äôs a good idea to get a sense of the sample statistics. Here are the means and SD‚Äôs for the two variables.\n\nchinstrap %&gt;% \n  summarise(body_mass_g_mean = mean(body_mass_g),\n            body_mass_g_sd = sd(body_mass_g),\n            bill_length_mm_mean = mean(bill_length_mm),\n            bill_length_mm_sd = sd(bill_length_mm)) \n\n# A tibble: 1 √ó 4\n  body_mass_g_mean body_mass_g_sd bill_length_mm_mean bill_length_mm_sd\n             &lt;dbl&gt;          &lt;dbl&gt;               &lt;dbl&gt;             &lt;dbl&gt;\n1            3733.           384.                48.8              3.34\n\n\nAnd you know that more efficient way to compute sample statistics for multiple variables is to first convert the data into the long format with pivot_longer(). Then you use a group_by() line before the main event in summarise().\n\nchinstrap %&gt;% \n  pivot_longer(cols = c(body_mass_g, bill_length_mm)) %&gt;% \n  group_by(name) %&gt;% \n  summarise(mean = mean(value),\n            sd = sd(value),\n            # count the missing data (if any)\n            n_missing = sum(is.na(value))) \n\n# A tibble: 2 √ó 4\n  name             mean     sd n_missing\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;     &lt;int&gt;\n1 bill_length_mm   48.8   3.34         0\n2 body_mass_g    3733.  384.           0\n\n\n\nQuestion 1.1: What do the marginal histograms added by ggside tell you about the distribution of body_mass_g and bill_length_mm individually?\nThe distribution of body_mass_g and bill_length_mm are probably not gaussian. They both look kinda bimodal."
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#ols",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#ols",
    "title": "Bayes and Penguins",
    "section": "OLS",
    "text": "OLS\nWe‚Äôll fit the model\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & = \\beta_0 + \\beta_1 \\text{body_mass_g}_i + \\epsilon_i \\\\\n\\epsilon_i & \\sim \\operatorname{Normal}(0, \\sigma_\\epsilon)\n\\end{align}\n\\]\nwhere bill_length_mm is the dependent variable or a response variable. The sole predictor is body_mass_g. Both variables have \\(i\\) subscripts, which indicate they vary across the \\(i\\) rows in the data set. For now, you might think if \\(i\\) as standing for ‚Äúindex.‚Äù The last term in the first line, \\(\\epsilon\\), is often called the error, or noise term. In the second line, we see we‚Äôre making the conventional assumption the ‚Äúerrors‚Äù are normally distributed around the regression line.\nAn alternative and equivalent way to write that equation is\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{body_mass_g}_i,\n\\end{align}\n\\]\nwhich is meant to convey we are modeling bill_length_mm as normally distributed, with a conditional mean. You don‚Äôt tend to see equations written this way in the OLS paradigm. However, this style of notation will serve us better when we start modeling our data with other distributions.\nThis notation grows on you\nFitting the model with the base R lm() function, which uses the OLS algorithm.\n\n# fit\nfit1.ols &lt;- lm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n\n# summarize the results\nsummary(fit1.ols)\n\n\nCall:\nlm(formula = bill_length_mm ~ 1 + body_mass_g, data = chinstrap)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8399 -2.2370  0.3247  1.8385  9.3138 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3.217e+01  3.443e+00   9.344 1.07e-13 ***\nbody_mass_g 4.463e-03  9.176e-04   4.863 7.48e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.887 on 66 degrees of freedom\nMultiple R-squared:  0.2638,    Adjusted R-squared:  0.2527 \nF-statistic: 23.65 on 1 and 66 DF,  p-value: 7.48e-06\n\n\nThe point estimates are in scientific notation. We can pull them with the coef() function.\n\ncoef(fit1.ols)\n\n (Intercept)  body_mass_g \n32.174192865  0.004462694 \n\n\nWe can compute fitted values, or predictions, with the predict() function. Here‚Äôs the default behavior.\n\npredict(fit1.ols)\n\n       1        2        3        4        5        6        7        8 \n47.79362 49.57870 48.46303 47.90519 48.79773 49.80183 46.67795 48.90930 \n       9       10       11       12       13       14       15       16 \n50.69437 48.68616 49.13243 49.02086 48.68616 50.24810 48.12832 50.24810 \n      17       18       19       20       21       22       23       24 \n46.90108 48.68616 47.57049 51.81005 48.23989 47.34735 45.11601 49.13243 \n      25       26       27       28       29       30       31       32 \n46.90108 50.69437 47.34735 49.13243 48.68616 52.47945 46.45481 51.36378 \n      33       34       35       36       37       38       39       40 \n47.12422 50.47124 48.23989 49.57870 49.35556 53.59512 44.22347 52.25632 \n      41       42       43       44       45       46       47       48 \n49.80183 48.46303 48.01676 47.79362 48.57459 52.03318 47.34735 51.36378 \n      49       50       51       52       53       54       55       56 \n46.67795 48.57459 47.01265 49.80183 48.23989 50.24810 47.12422 47.57049 \n      57       58       59       60       61       62       63       64 \n46.67795 50.24810 49.13243 47.90519 49.80183 48.46303 48.46303 50.02497 \n      65       66       67       68 \n47.34735 49.02086 50.47124 49.02086 \n\n\nWe get one prediction, one fitted value, for each case in the data set. We can express the uncertainty around those predictions with confidence intervals.\n\npredict(fit1.ols,\n        interval = \"confidence\") %&gt;% \n  # just the top 6\n  head()\n\n       fit      lwr      upr\n1 47.79362 46.97456 48.61268\n2 49.57870 48.81580 50.34160\n3 48.46303 47.74771 49.17834\n4 47.90519 47.10905 48.70133\n5 48.79773 48.09864 49.49682\n6 49.80183 48.99783 50.60584\n\n\nWe might also ask for a standard error for each prediction.\n\npredict(fit1.ols,\n        se.fit = TRUE) %&gt;% \n  data.frame()\n\n        fit    se.fit df residual.scale\n1  47.79362 0.4102359 66       2.886728\n2  49.57870 0.3821060 66       2.886728\n3  48.46303 0.3582736 66       2.886728\n4  47.90519 0.3987564 66       2.886728\n5  48.79773 0.3501459 66       2.886728\n6  49.80183 0.4026961 66       2.886728\n7  46.67795 0.5648454 66       2.886728\n8  48.90930 0.3504110 66       2.886728\n9  50.69437 0.5185569 66       2.886728\n10 48.68616 0.3513814 66       2.886728\n11 49.13243 0.3554108 66       2.886728\n12 49.02086 0.3521734 66       2.886728\n13 48.68616 0.3513814 66       2.886728\n14 50.24810 0.4550963 66       2.886728\n15 48.12832 0.3789333 66       2.886728\n16 50.24810 0.4550963 66       2.886728\n17 46.90108 0.5296025 66       2.886728\n18 48.68616 0.3513814 66       2.886728\n19 47.57049 0.4359183 66       2.886728\n20 51.81005 0.7050167 66       2.886728\n21 48.23989 0.3707575 66       2.886728\n22 47.34735 0.4647215 66       2.886728\n23 45.11601 0.8407923 66       2.886728\n24 49.13243 0.3554108 66       2.886728\n25 46.90108 0.5296025 66       2.886728\n26 50.69437 0.5185569 66       2.886728\n27 47.34735 0.4647215 66       2.886728\n28 49.13243 0.3554108 66       2.886728\n29 48.68616 0.3513814 66       2.886728\n30 52.47945 0.8273195 66       2.886728\n31 46.45481 0.6015246 66       2.886728\n32 51.36378 0.6270243 66       2.886728\n33 47.12422 0.4961023 66       2.886728\n34 50.47124 0.4856973 66       2.886728\n35 48.23989 0.3707575 66       2.886728\n36 49.57870 0.3821060 66       2.886728\n37 49.35556 0.3661365 66       2.886728\n38 53.59512 1.0397147 66       2.886728\n39 44.22347 1.0105441 66       2.886728\n40 52.25632 0.7859885 66       2.886728\n41 49.80183 0.4026961 66       2.886728\n42 48.46303 0.3582736 66       2.886728\n43 48.01676 0.3882941 66       2.886728\n44 47.79362 0.4102359 66       2.886728\n45 48.57459 0.3541019 66       2.886728\n46 52.03318 0.7451900 66       2.886728\n47 47.34735 0.4647215 66       2.886728\n48 51.36378 0.6270243 66       2.886728\n49 46.67795 0.5648454 66       2.886728\n50 48.57459 0.3541019 66       2.886728\n51 47.01265 0.5126128 66       2.886728\n52 49.80183 0.4026961 66       2.886728\n53 48.23989 0.3707575 66       2.886728\n54 50.24810 0.4550963 66       2.886728\n55 47.12422 0.4961023 66       2.886728\n56 47.57049 0.4359183 66       2.886728\n57 46.67795 0.5648454 66       2.886728\n58 50.24810 0.4550963 66       2.886728\n59 49.13243 0.3554108 66       2.886728\n60 47.90519 0.3987564 66       2.886728\n61 49.80183 0.4026961 66       2.886728\n62 48.46303 0.3582736 66       2.886728\n63 48.46303 0.3582736 66       2.886728\n64 50.02497 0.4272392 66       2.886728\n65 47.34735 0.4647215 66       2.886728\n66 49.02086 0.3521734 66       2.886728\n67 50.47124 0.4856973 66       2.886728\n68 49.02086 0.3521734 66       2.886728\n\n\nInstead of relying on predictions from the values in the data, we might instead define a sequence of values from the predictor variable. We‚Äôll call those nd.\n\nnd &lt;- tibble(body_mass_g = seq(from = min(chinstrap$body_mass_g),\n                               to = max(chinstrap$body_mass_g),\n                               length.out = 50))\n\nglimpse(nd)\n\nRows: 50\nColumns: 1\n$ body_mass_g &lt;dbl&gt; 2700.000, 2742.857, 2785.714, 2828.571, 2871.429, 2914.286‚Ä¶\n\n\nWe can insert our nd data into the newdata argument.\n\npredict(fit1.ols,\n        interval = \"confidence\",\n        newdata = nd) %&gt;% \n  # just the top 6\n  head()\n\n       fit      lwr      upr\n1 44.22347 42.20585 46.24108\n2 44.41473 42.47057 46.35888\n3 44.60598 42.73489 46.47708\n4 44.79724 42.99874 46.59574\n5 44.98850 43.26207 46.71493\n6 45.17976 43.52482 46.83469\n\n\nNow we wrangle those predictions a bit and pump the results right into ggplot().\n\npredict(fit1.ols,\n        interval = \"confidence\",\n        newdata = nd) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd) %&gt;% \n  \n  ggplot(aes(x = body_mass_g)) +\n  # 95% confidence interval ribbon\n  geom_ribbon(aes(ymin = lwr, ymax = upr),\n              alpha = 1/3) +\n  # point estimate line\n  geom_line(aes(y = fit)) +\n  geom_point(data = chinstrap,\n             aes(y = bill_length_mm))\n\n\n\n\n\n\n\n\nIf we wanted to, we could look at the residuals with help from the residuals() function.\n\nresiduals(fit1.ols)\n\n         1          2          3          4          5          6          7 \n-1.2936220  0.4213003  2.8369738 -2.5051894  3.9022718 -4.6018344 -0.5779485 \n         8          9         10         11         12         13         14 \n 2.3907044 -4.6943732  2.6138391 -2.5324303  2.6791371 -1.6861609  1.7518962 \n        15         16         17         18         19         20         21 \n-2.2283241  0.2518962  3.3989168  9.3138391 -1.1704873 -2.6100467 -5.8398915 \n        22         23         24         25         26         27         28 \n 1.1526474 -1.9160056  1.4675697 -0.2010832  1.3056268  3.1526474  0.3675697 \n        29         30         31         32         33         34         35 \n-2.2861609  0.3205492 -5.5548138  2.8362227 -4.6242179  0.5287615  1.4601085 \n        36         37         38         39         40         41         42 \n-2.0786997 -1.7555650 -1.5951243  2.6765332  1.2436839 -0.8018344 -2.2630262 \n        43         44         45         46         47         48         49 \n 2.8832432 -2.2936220  2.3254065 -1.2331814  2.7526474 -2.3637773  4.8220515 \n        50         51         52         53         54         55         56 \n 1.2254065  1.0873494  1.5981656 -2.5398915  0.4518962 -4.6242179  4.6295127 \n        57         58         59         60         61         62         63 \n-1.4779485 -0.9481038  1.0675697 -2.3051894  2.0981656 -1.6630262 -2.7630262 \n        64         65         66         67         68 \n 5.7750309 -3.8473526  0.5791371  0.3287615  1.1791371 \n\n\nHere we might put them in a tibble and display them in a plot.\n\n# put them in a tibble\ntibble(r = residuals(fit1.ols)) %&gt;% \n  # plot!\n  ggplot(aes(x = r)) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\n\n\nQuestion 1.2: Can you predict what the mean value, and standard deviations will be? Why? Calculate it. Compare this against outputs in summary(fit1.ols) and explain. Map the values you find to the latex equations before.\n\n# Slope\nslope = cov(chinstrap$body_mass_g, chinstrap$bill_length_mm) / var(chinstrap$body_mass_g)\nslope\n\n[1] 0.004462694\n\nres = residuals(fit1.ols)\nvar_res = sum(res^2) / (length(chinstrap) - 2)\nvar_res / sum((chinstrap$body_mass_g - mean(chinstrap$body_mass_g))^2)\n\n[1] 9.262102e-06\n\n# Intercept\nmean(chinstrap$bill_length_mm) - slope * mean(chinstrap$body_mass_g)\n\n[1] 32.17419\n\nsd(chinstrap$bill_length_mm)\n\n[1] 3.339256\n\n\nThe estimate for the intercept is 32.17 with a standard deviation of 3.40. The standard deviation is not computed from the residuals but the simple SD of the y is a good enough estimate here. Both are pretty close to the estimated value from the model.\n\nThe mean value for the slope is 0.0045 and the standard deviation is 9.26e-06. These are quite similar to the values from our ols model.\n\\[\n\\begin{align}\n\\text{bill_length_mm}_i & = 32.17 + 0.0045 * \\text{body_mass_g}_i\\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#bayes-with-default-settings",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#bayes-with-default-settings",
    "title": "Bayes and Penguins",
    "section": "Bayes with default settings",
    "text": "Bayes with default settings\nWe‚Äôll be fitting our Bayesian models with the brms package. The primary function is brm().\nbrm() can work a lot like the OLS-based lm() function. For example, here‚Äôs how to fit a Bayesian version of our OLS model fit1.ols.\n\nfit1.b &lt;- brm(\n  data = chinstrap,\n  bill_length_mm ~ 1 + body_mass_g\n)\n\nCompiling Stan program...\n\n\nTrying to compile a simple C file\n\n\nStart sampling\n\n\nNotice what‚Äôs happening in the console, below. We‚Äôll get into the details of what just happened later. For now, appreciate we just fit our first Bayesian model, and it wasn‚Äôt all that hard.\nSummarize the model.\n\nsummary(fit1.b)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: chinstrap (Number of observations: 68) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      32.22      3.46    25.60    39.01 1.00     4571     3022\nbody_mass_g     0.00      0.00     0.00     0.01 1.00     4649     3040\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.93      0.26     2.47     3.50 1.00     1666     1567\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nQuestion 1.3: Contrast the language of in the brm() output from the in the lm() output. Ignore ‚ÄòRhat,‚Äô ‚ÄòBulk_ESS,‚Äô and ‚ÄòTail_ESS‚Äô for now.\nThe estimated values are pretty similar in both models. \n\nThe frequentist model shows t and p value for all parameters.\n\nThe bayesian model shows the 95% confidence interval for all parameters.\nWe can get a quick and dirty plot of the fitted line with the conditional_effects() function.\n\nconditional_effects(fit1.b)\n\n\n\n\n\n\n\n# %&gt;% \n#   plot(points = TRUE)"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#coefficients-and-coefficient-plots",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#coefficients-and-coefficient-plots",
    "title": "Bayes and Penguins",
    "section": "Coefficients and coefficient plots",
    "text": "Coefficients and coefficient plots\nWe might want to compare the coefficient summaries from the OLS model to those from the Bayesian model. Here‚Äôs the frequentist summary:\n\ncbind(coef(fit1.ols),              # point estimates\n      sqrt(diag(vcov(fit1.ols))),  # standard errors\n      confint(fit1.ols))           # 95% CIs\n\n                                             2.5 %       97.5 %\n(Intercept) 32.174192865 3.4433622902 25.299298235 39.049087495\nbody_mass_g  0.004462694 0.0009176106  0.002630625  0.006294763\n\n\nWe can compute a focused summary of the Bayesian model with the fixef() function.\n\nfixef(fit1.b)\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.224719295 3.4644118924 25.601940878 39.014504958\nbody_mass_g  0.004452718 0.0009225075  0.002648983  0.006221399\n\n\nIn this case, the results are very similar.\nWe can also pull this information from our OLS model with the broom::tidy() function.\n\ntidy(fit1.ols, conf.int = TRUE)\n\n# A tibble: 2 √ó 7\n  term        estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept) 32.2      3.44          9.34 1.07e-13 25.3      39.0    \n2 body_mass_g  0.00446  0.000918      4.86 7.48e- 6  0.00263   0.00629\n\n\nIf you would like to use the tidy() function with your brms models, it will have to be the version of tidy() from the broom.mixed package.\n\ntidy(fit1.b)\n\nWarning in tidy.brmsfit(fit1.b): some parameter names contain underscores: term\nnaming may be unreliable!\n\n\n# A tibble: 3 √ó 8\n  effect   component group    term         estimate std.error conf.low conf.high\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 fixed    cond      &lt;NA&gt;     (Intercept)  32.2      3.46     25.6      39.0    \n2 fixed    cond      &lt;NA&gt;     body_mass_g   0.00445  0.000923  0.00265   0.00622\n3 ran_pars cond      Residual sd__Observa‚Ä¶  2.93     0.258     2.47      3.50   \n\n\nHere‚Äôs how to wrangle and combine these two results into a single data frame. Then we‚Äôll make a coefficient plot.\n\nbind_rows(\n  tidy(fit1.ols, conf.int = TRUE) %&gt;% select(term, estimate, contains(\"conf\")),\n  tidy(fit1.b) %&gt;% select(term, estimate, contains(\"conf\")) %&gt;% filter(term != \"sd__Observation\")\n) %&gt;% \n  mutate(method = rep(c(\"lm()\", \"brm()\"), each = 2)) %&gt;% \n  \n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = method)) +\n  geom_pointrange() +\n  scale_x_continuous(\"parameter space\", expand = expansion(mult = 0.2)) +\n  scale_y_discrete(expand = expansion(mult = 5)) +\n  facet_wrap(~ term, scales = \"free_x\")\n\n\n\n\n\n\n\n\nAt a superficial level for simple conventional regression type models, the results from a Bayesian brm() model will be very similar to those from an OLS lm() model. This will not always be case, and even in this example there are many differences once we look below the surface."
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#more-questionsexercise",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#more-questionsexercise",
    "title": "Bayes and Penguins",
    "section": "More Questions/Exercise",
    "text": "More Questions/Exercise\nGo back to the full penguins data set. This time, make a subset of the data called gentoo, which is only the cases for which species == \"Gentoo\".\n\ngentoo &lt;- penguins %&gt;% \n  filter(species == \"Gentoo\")\n\nCan you fit the same OLS model to these data?\n\nfit2.ols &lt;- lm(\n  data = gentoo,\n  bill_length_mm ~ 1 + body_mass_g\n)\n\nHow about plotting the results with predict()?\n\ngentoo_filtered = gentoo %&gt;% filter(!is.na(body_mass_g))\nod2 &lt;- tibble(body_mass_g = gentoo_filtered$body_mass_g)\npredict(fit2.ols,\n        interval = \"confidence\") %&gt;% \n  data.frame() %&gt;% \n  bind_cols(od2) %&gt;% \n  ggplot(aes(x = body_mass_g)) +\n  # 95% confidence interval ribbon\n  geom_ribbon(aes(ymin = lwr, ymax = upr),\n              alpha = 1/3) +\n  # point estimate line\n  geom_line(aes(y = fit)) +\n  geom_point(data = gentoo_filtered,\n             aes(y = bill_length_mm))\n\n\n\n\n\n\n\nnd2 &lt;- tibble(body_mass_g = seq(from = min(gentoo$body_mass_g, na.rm=TRUE),\n                               to = max(gentoo$body_mass_g, na.rm=TRUE),\n                               length.out = 50))\n\npredict(fit2.ols,\n        interval = \"confidence\",\n        newdata = nd2) %&gt;% \n  data.frame() %&gt;% \n  bind_cols(nd2) %&gt;% \n  ggplot(aes(x = body_mass_g)) +\n  # 95% confidence interval ribbon\n  geom_ribbon(aes(ymin = lwr, ymax = upr),\n              alpha = 1/3) +\n  # point estimate line\n  geom_line(aes(y = fit)) +\n  geom_point(data = gentoo,\n             aes(y = bill_length_mm))\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nCan you fit the same default Bayesian brm() model to these data?\n\nfit2.b &lt;- brm(\n  data = gentoo,\n  bill_length_mm ~ 1 + body_mass_g\n)\n\nWarning: Rows containing NAs were excluded from the model.\n\n\nCompiling Stan program...\n\n\nTrying to compile a simple C file\n\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nusing C compiler: ‚ÄòApple clang version 16.0.0 (clang-1600.0.26.6)‚Äô\nusing SDK: ‚ÄòMacOSX15.4.sdk‚Äô\nclang -arch x86_64 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/Rcpp/1.0.14/e7bdd9ee90e96921ca8a0f1972d66682/Rcpp/include/\"  -I\"/Users/kw1166/Downloads/Grad/2024S PSY 504/02-05-Quarto/renv/library/macos/R-4.4/x86_64-apple-darwin20/RcppEigen/include/\"  -I\"/Users/kw1166/Downloads/Grad/2024S PSY 504/02-05-Quarto/renv/library/macos/R-4.4/x86_64-apple-darwin20/RcppEigen/include/unsupported\"  -I\"/Users/kw1166/Downloads/Grad/2024S PSY 504/02-05-Quarto/renv/library/macos/R-4.4/x86_64-apple-darwin20/BH/include\" -I\"/Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/StanHeaders/2.32.10/c35dc5b81d7ffb1018aa090dff364ecb/StanHeaders/include/src/\"  -I\"/Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/StanHeaders/2.32.10/c35dc5b81d7ffb1018aa090dff364ecb/StanHeaders/include/\"  -I\"/Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/RcppParallel/5.1.10/34ee3ba92c1b2df651980325523ed22a/RcppParallel/include/\"  -I\"/Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/rstan/2.32.6/8a5b5978f888a3477c116e0395d006f8/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/StanHeaders/2.32.10/c35dc5b81d7ffb1018aa090dff364ecb/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/x86_64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from &lt;built-in&gt;:1:\nIn file included from /Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/StanHeaders/2.32.10/c35dc5b81d7ffb1018aa090dff364ecb/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Users/kw1166/Downloads/Grad/2024S PSY 504/02-05-Quarto/renv/library/macos/R-4.4/x86_64-apple-darwin20/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Users/kw1166/Downloads/Grad/2024S PSY 504/02-05-Quarto/renv/library/macos/R-4.4/x86_64-apple-darwin20/RcppEigen/include/Eigen/Core:19:\n/Users/kw1166/Downloads/Grad/2024S PSY 504/02-05-Quarto/renv/library/macos/R-4.4/x86_64-apple-darwin20/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: 'cmath' file not found\n  679 | #include &lt;cmath&gt;\n      |          ^~~~~~~\n1 error generated.\nmake: *** [foo.o] Error 1\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.2e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.118 seconds (Warm-up)\nChain 1:                0.086 seconds (Sampling)\nChain 1:                0.204 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 6e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.125 seconds (Warm-up)\nChain 2:                0.085 seconds (Sampling)\nChain 2:                0.21 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.125 seconds (Warm-up)\nChain 3:                0.081 seconds (Sampling)\nChain 3:                0.206 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.143 seconds (Warm-up)\nChain 4:                0.092 seconds (Sampling)\nChain 4:                0.235 seconds (Total)\nChain 4: \n\n\nHow about plotting the results with conditional_effects()?\n\nconditional_effects(fit2.b)\n\n\n\n\n\n\n\n# %&gt;% \n#   plot(points = TRUE)\n\nCan you make a coefficient plot comparing the new OLS and Bayesian beta coefficients?\n\nbind_rows(\n  tidy(fit2.ols, conf.int = TRUE) %&gt;% select(term, estimate, contains(\"conf\")),\n  tidy(fit2.b) %&gt;% select(term, estimate, contains(\"conf\")) %&gt;% filter(term != \"sd__Observation\")\n) %&gt;% \n  mutate(method = rep(c(\"lm()\", \"brm()\"), each = 2)) %&gt;% \n  \n  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = method)) +\n  geom_pointrange() +\n  scale_x_continuous(\"parameter space\", expand = expansion(mult = 0.2)) +\n  scale_y_discrete(expand = expansion(mult = 5)) +\n  facet_wrap(~ term, scales = \"free_x\")"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#exploring-model-results",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#exploring-model-results",
    "title": "Bayes and Penguins",
    "section": "Exploring model results",
    "text": "Exploring model results\nWe can extract the posterior draws from our Bayesian models with the as_draws_df() function.\n\nas_draws_df(fit1.b)\n\n# A draws_df: 1000 iterations, 4 chains, and 6 variables\n   b_Intercept b_body_mass_g sigma Intercept lprior lp__\n1           38        0.0028   2.8        48   -4.3 -174\n2           36        0.0034   2.8        48   -4.3 -173\n3           33        0.0045   3.3        49   -4.4 -173\n4           43        0.0016   3.3        49   -4.4 -176\n5           31        0.0048   3.2        49   -4.3 -172\n6           31        0.0048   2.7        49   -4.2 -171\n7           33        0.0043   2.8        49   -4.2 -171\n8           37        0.0032   2.9        49   -4.3 -172\n9           30        0.0051   2.8        49   -4.3 -171\n10          33        0.0041   3.0        48   -4.3 -172\n# ... with 3990 more draws\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nNote the meta data. We can get a sense of the full posterior distributions of the \\(\\beta\\) parameters with plots.\n\n# wrangle\nas_draws_df(fit1.b) %&gt;% \n  pivot_longer(starts_with(\"b_\")) %&gt;% \n  \n  # plot!\n  ggplot(aes(x = value)) + \n  # geom_density(fill = \"grey20\") +\n  geom_histogram(bins = 40) +\n  facet_wrap(~ name, scales = \"free\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\n\n\n\n\n\n\nWe might summarize those posterior distributions with basic descriptive statistics, like their means, SD‚Äôs, and inner 95-percentile range.\n\nas_draws_df(fit1.b) %&gt;% \n  pivot_longer(starts_with(\"b_\")) %&gt;% \n  group_by(name) %&gt;% \n  summarise(mean = mean(value),\n            sd = sd(value),\n            ll = quantile(value, probs = 0.025),\n            ul = quantile(value, probs = 0.975))\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n# A tibble: 2 √ó 5\n  name              mean       sd       ll       ul\n  &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 b_Intercept   32.2     3.46     25.6     39.0    \n2 b_body_mass_g  0.00445 0.000923  0.00265  0.00622\n\n\nNotice how these values match up exactly with those from fixef().\n\nfixef(fit1.b)\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.224719295 3.4644118924 25.601940878 39.014504958\nbody_mass_g  0.004452718 0.0009225075  0.002648983  0.006221399\n\n\nThus,\n\nThe Bayesian posterior mean is analogous to the frequentist point estimate.\nThe Bayesian posterior SD is analogous to the frequentist standard error.\nThe Bayesian posterior percentile-based 95% (credible) interval is analogous to the frequentist 95% confidence interval.\n\nThese are not exactly the same, mind you. But they serve similar functions.\nWe can also get a sense of these distributions with the plot() function.\n\nplot(fit1.b)\n\n\n\n\n\n\n\n\nIgnore the trace plots on the right for a moment. And let‚Äôs consider the pairs() plot.\n\npairs(fit1.b)\n\n\n\n\n\n\n\n# we can adjust some of the settings with the off_diag_args argument\npairs(fit1.b, off_diag_args = list(size = 1/4, alpha = 1/4))\n\n\n\n\n\n\n\n\n\nQuestion 2.1 : In the parlance of Probability, do you know what is the term by which the distributions in the diagonal of the above plot are known as? And the distributions in the off-diagonal?\nThe diagonal ones are the marginal distributions of individual parameters.\n\nThe off-diagnoal ones are the bivariate marginal distributions, or the joint distributions of the paired two parameters, marginalized over the remaining parameters.\nNotice how the two \\(\\beta\\) parameters seem to have a strong negative correlation. We can quantify that correlation with the vcov() function.\n\nvcov(fit1.b)                      # variance/covariance metric\n\n               Intercept   body_mass_g\nIntercept   12.002149760 -3.179187e-03\nbody_mass_g -0.003179187  8.510201e-07\n\nvcov(fit1.b, correlation = TRUE)  # correlation metric\n\n             Intercept body_mass_g\nIntercept    1.0000000  -0.9947562\nbody_mass_g -0.9947562   1.0000000\n\n\nThis correlation/covariance among the parameters is not unique to Bayesian models. Here‚Äôs the vcov() output for the OLS model.\n\nvcov(fit1.ols)  # variance/covariance metric\n\n             (Intercept)   body_mass_g\n(Intercept) 11.856743861 -3.143295e-03\nbody_mass_g -0.003143295  8.420092e-07\n\n\nI‚Äôm not aware of an easy way to get that output in a correlation metric for our OLS model. Here‚Äôs how to compute the correlation by hand.\n\ncov_xy &lt;- vcov(fit1.ols)[2, 1]  # covariance between the intercept and slope\nvar_x  &lt;- vcov(fit1.ols)[1, 1]  # variance for the intercept\nvar_y  &lt;- vcov(fit1.ols)[2, 2]  # variance for the slope\n\n# convert the covariance into a correlation\ncov_xy / (sqrt(var_x) * sqrt(var_y))\n\n[1] -0.9948188\n\n\nThat code follows the definition of a covariance, which can be expressed as\n\\[\n\\text{Cov}(x, y) = \\rho \\sigma_x \\sigma_y,\n\\]\nwhere \\(\\sigma_x\\) is the standard deviation for x, \\(\\sigma_y\\) is the standard deviation for y, and \\(\\rho\\) is their correlation. And thus, you can convert a covariance into a correlation with the formula\n\\[\n\\rho = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y},\n\\]\nwhere \\(\\sigma_{xy}\\) is the covariance of x and y."
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#draws",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#draws",
    "title": "Bayes and Penguins",
    "section": "Draws",
    "text": "Draws\nLet‚Äôs save the as_draws_df() output for our model as an object called draws.\n\ndraws &lt;- as_draws_df(fit1.b)\nglimpse(draws)\n\nRows: 4,000\nColumns: 9\n$ b_Intercept   &lt;dbl&gt; 37.64801, 35.73979, 32.51482, 43.27222, 31.26464, 30.925‚Ä¶\n$ b_body_mass_g &lt;dbl&gt; 0.002841119, 0.003352717, 0.004489759, 0.001603265, 0.00‚Ä¶\n$ sigma         &lt;dbl&gt; 2.846181, 2.800578, 3.269793, 3.264512, 3.172250, 2.6514‚Ä¶\n$ Intercept     &lt;dbl&gt; 48.25416, 48.25578, 49.27548, 49.25735, 49.17160, 48.876‚Ä¶\n$ lprior        &lt;dbl&gt; -4.327303, -4.316111, -4.358964, -4.358006, -4.336398, -‚Ä¶\n$ lp__          &lt;dbl&gt; -173.8591, -173.0895, -172.5650, -176.2871, -171.9391, -‚Ä¶\n$ .chain        &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶\n$ .iteration    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1‚Ä¶\n$ .draw         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1‚Ä¶\n\n\nFor each parameter in the model, we have 4,000 draws from the posterior.\n\nQuestion 2.2: How does this concept relate to representing uncertainty? Can you anticipate how predictions are made based upon these 4000 draws and the linear regression formula?\nSince we hae 4000 posterior samples, the spread can tell us how uncertain we are about each parameter. We can also get the mean and the 95% confidence interval from the distribution.\n\nFor each value of x, the predictions are made by averaging the predicted values across the 4000 samples of the parameters.\n\\[\\widehat{\\text{bill_length_mm}}_i = \\beta_0 + \\beta_1 \\text{body_mass_g}_i.\\]\nLet‚Äôs break the 4000 draws down with our draws object.\n\n# adjust the parameter names \ndraws &lt;- draws %&gt;% \n  mutate(beta0 = b_Intercept,\n         beta1 = b_body_mass_g)\n\n# Note: go through this one line at a time\ndraws %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = y_hat)) +\n  geom_histogram(bins = 40) +\n  labs(title = \"Bayesians have posterior distributions\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51))\n\n\n\n\n\n\n\n\nHere‚Äôs what that is for the OLS model.\n\npredict(fit1.ols,\n        newdata = tibble(body_mass_g = mean(chinstrap$body_mass_g)),\n        interval = \"confidence\") %&gt;% \n  data.frame() %&gt;% \n  \n  ggplot(aes(x = fit, xmin = lwr, xmax = upr, y = 0)) +\n  geom_pointrange() +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Frequentists have point estmates and 95% CI's\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51))\n\n\n\n\n\n\n\n\nAnother handy way to present a Bayesian posterior is as a density with a point-interval summary below.\n\nlibrary(ggdist) #for stat_half_eye and mean_qi\n\n\nAttaching package: 'ggdist'\n\n\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\ndraws %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = y_hat)) +\n  stat_halfeye(point_interval = mean_qi, .width = .95) +\n  # scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Bayesians have posterior distributions\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51))\n\n\n\n\n\n\n\n\nThe dot at the base of the plot is the posterior mean, and the horizontal line marks the 95% percentile-based interval. If you‚Äôd like to mark the median instead, set point_interval = median_qi. If you‚Äôre like a different kind of horizontal interval, adjust the .width argument.\n\ndraws %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = y_hat)) +\n  # note the changes to this line\n  stat_halfeye(point_interval = median_qi, .width = c(.5, .99)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Bayesians have posterior distributions\",\n       subtitle = \"The dot marks the median.\\nThe thicker line marks the 50% interval, and\\nthe thinner line marks the 99% interval.\",\n       x = expression(hat(italic(y))*'|'*italic(x)==3733.1)) +\n  coord_cartesian(xlim = c(47, 51))"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#about-those-means-sds-and-intervals.",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#about-those-means-sds-and-intervals.",
    "title": "Bayes and Penguins",
    "section": "About those means, SD‚Äôs, and intervals.",
    "text": "About those means, SD‚Äôs, and intervals.\nYou can describe a Bayesian posterior in a lot of different ways. Earlier we said the posterior mean is the Bayesian point estimate. This isn‚Äôt strictly true. Means are very popular, but you can summarize a posterior by its mean, median, or mode.\nLet‚Äôs see what this looks like in practice. First, we compute and save our statistics for each of our model parameters.\n\npoints &lt;- draws %&gt;% \n  rename(`beta[0]` = beta0,\n         `beta[1]` = beta1) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  group_by(parameter) %&gt;% \n  summarise(mean = mean(value),\n            median = median(value),\n            mode = Mode(value)) %&gt;% \n  pivot_longer(starts_with(\"m\"), names_to = \"statistic\")\n\n# what?\npoints\n\n# A tibble: 9 √ó 3\n  parameter statistic    value\n  &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n1 beta[0]   mean      32.2    \n2 beta[0]   median    32.2    \n3 beta[0]   mode      32.0    \n4 beta[1]   mean       0.00445\n5 beta[1]   median     0.00447\n6 beta[1]   mode       0.00454\n7 sigma     mean       2.93   \n8 sigma     median     2.91   \n9 sigma     mode       2.85   \n\n\nNow plot.\n\ndraws %&gt;% \n  rename(`beta[0]` = beta0,\n         `beta[1]` = beta1) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(data = points,\n             aes(xintercept = value, color = statistic),\n             size = 3/4) +\n  scale_color_viridis_d(option = \"A\", end = .8) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"parameter space\") +\n  facet_wrap(~ parameter, labeller = label_parsed, scales = \"free\", ncol = 1) +\n  theme(strip.text = element_text(size = 14))\n\n\n\n\n\n\n\n\n\nQuestion 2.3: Discuss the skew in \\(\\sigma\\).Why it might arise, etc.?\n$\\sigma$ might be skewed becasue a few reasons.\n\nFirst, it can't be negative, so it is bounded below 0.\n\nSecond, we might have a weak prior for $\\sigma$, which will result in posterior uncertainty that includes the possibility of high residual variability, resulting in a longer right tail in the posterior.\n\nThird, there could be some outliers that inflates $\\sigma$, making its posterior distribution more right-skewed.\n\n\nThe mean is the brms default summary, and McElreath (2015, 2020) defaulted to the mean in his texts.\nThe median is also available for many brms functions, and it‚Äôs what Gelman et al (2020) recommend.\nThe mode can be attractive for very skewed distributions, and it‚Äôs what Kruschke (2015) used in his text.\n\nWith many brms functions, you can request the median by setting robust = TRUE. For example:\n\nfixef(fit1.b)                 # means\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.224719295 3.4644118924 25.601940878 39.014504958\nbody_mass_g  0.004452718 0.0009225075  0.002648983  0.006221399\n\nfixef(fit1.b, robust = TRUE)  # medians\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.177198496 3.4527727281 25.601940878 39.014504958\nbody_mass_g  0.004469983 0.0009169407  0.002648983  0.006221399\n\n\n\n\nQuestion 2.4: Given the skew in sigma and what you know about summary statistics, what might be the implication of using just the mean, median, or mode of posteriors to make a prediction?\nThe mean is pulled toward the tail, so using the mean of sigma will lead to wider predicted intervals (more conservative), but we might overestimate uncertainty in new predictions if the skew is strong.\n\nThe median is robust to the skew, so using the median provides a balanced summary that is not too influenced by tail values.\n\nThe mode is often below the mean when the distribution is right skewed, so using the mode of sigma could underestimate uncertainty and produce overconfident predictions.\n\nOverall, it is better to use the entire posterior, which full captures the uncertainty, including the skew, instead of using only a single value of the distribution.\n\nSD‚Äôs and MAD SD‚Äôs.\nEarlier we said the posterior SD is the Bayesian standard error. This isn‚Äôt strictly true. You can also use the median absolute deviation (MAD SD). If we let \\(M\\) stand for the median of some variable \\(y\\), which varies across \\(i\\) cases, we can define the MAD SD as\n\\[\\textit{MAD SD} = 1.4826 \\times \\operatorname{median}_{i = 1}^n |y_i - M|,\\]\nwhere \\(1.4826\\) is a constant that scales the MAD SD into a standard-deviation metric. Here‚Äôs what this looks like in practice.\n\n# go through this line by line\ndraws %&gt;% \n  select(beta0) %&gt;% \n  mutate(mdn = median(beta0)) %&gt;% \n  mutate(`|yi - mdn|` = abs(beta0 - mdn)) %&gt;% \n  summarise(MAD_SD = 1.4826 * median(`|yi - mdn|`))\n\n# A tibble: 1 √ó 1\n  MAD_SD\n   &lt;dbl&gt;\n1   3.45\n\n\nBase R also has a mad() function.\n\n?mad\n\nHelp on topic 'mad' was found in the following packages:\n\n  Package               Library\n  posterior             /Users/kw1166/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/x86_64-apple-darwin20/posterior/1.6.0/fc1213566f2ed9f0b15bef656ed1000b\n  stats                 /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/library\n\n\nUsing the first match ...\n\ndraws %&gt;% \n  summarise(MAD_SD = mad(beta0))\n\n# A tibble: 1 √ó 1\n  MAD_SD\n   &lt;dbl&gt;\n1   3.45\n\n\nYou can request the MAD SD from many brms functions by setting robust = TRUE.\n\nfixef(fit1.b)                 # SD\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.224719295 3.4644118924 25.601940878 39.014504958\nbody_mass_g  0.004452718 0.0009225075  0.002648983  0.006221399\n\nfixef(fit1.b, robust = TRUE)  # MAD SD\n\n                Estimate    Est.Error         Q2.5        Q97.5\nIntercept   32.177198496 3.4527727281 25.601940878 39.014504958\nbody_mass_g  0.004469983 0.0009169407  0.002648983  0.006221399\n\n\n\nTo my eye, many authors (e.g., Kruschke, McElreath) just use the SD.\nGelman et al (see Section 5.3) recommend the MAD SD.\n\n\n\nBayesian intervals.\nBayesians describe the widths of their posteriors with intervals. I‚Äôve seen these variously described as confidence intervals, credible intervals, probability intervals, and even uncertainty intervals. My recommendation is just pick a term, and clearly tell your audience what you mean (e.g., at the end of a Method section in a journal article).\nTo my eye, the most popular interval is a 95% percentile-based interval. 95% is conventional, perhaps due to the popularity of the 95% frequentist confidence interval, which is related to the 0.05 alpha level used for the conventional \\(p\\)-value cutoff. However, you can use other percentiles. Some common alternatives are 99%, 89%, 80%, and 50%.\nAlso, Bayesian intervals aren‚Äôt always percentile based. An alternative is the highest posterior density interval (HPDI), which has mathematical properties some find desirable.\nbrms only supports percentile-based intervals, but it does allow for a variety of different ranges via the prob argument. For example, here‚Äôs how to request 80% intervals in summary().\n\nsummary(fit1.b, prob = .80)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bill_length_mm ~ 1 + body_mass_g \n   Data: chinstrap (Number of observations: 68) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS\nIntercept      32.22      3.46    27.82    36.68 1.00     4571     3022\nbody_mass_g     0.00      0.00     0.00     0.01 1.00     4649     3040\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS\nsigma     2.93      0.26     2.62     3.26 1.00     1666     1567\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nRegarding interval widths:\n\n95% Intervals are widely used.\nMcElreat likes 89% intervals, and uses them as a default in his rethinking package.\nSome of the bayesplot, ggdist, and tidybayes functions return 80% intervals.\nSome of the ggdist, and tidybayes functions return 66% or 50% intervals.\nI‚Äôve heard Gelman report his fondness for 50% intervals on his blog (https://statmodeling.stat.columbia.edu/2016/11/05/why-i-prefer-50-to-95-intervals/).\n\nRegarding interval types:\n\nPercentile-based intervals are widely used in the Stan ecosystem, and are supported in texts like Gelman et al.\nKruschke has consistently advocates for HPDI‚Äôs in his articles, and in his text.\n\n\n\n\nPosterior summaries with tidybayes.\nMatthew Kay‚Äôs tidybayes package (https://mjskay.github.io/tidybayes/) offers an array of convenience functions for summarizing posterior distributions with points and intervals. See the Point summaries and intervals section of Kay‚Äôs Extracting and visualizing tidy draws from brms models vignette (https://mjskay.github.io/tidybayes/articles/tidy-brms.html#point-summaries-and-intervals) for a detailed breakdown. In short, the family of functions use the naming scheme [median|mean|mode]_[qi|hdi]. Here are a few examples.\n\ndraws %&gt;% mean_qi(beta0)                        # mean and 95% percentile interval\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\nWarning: Dropping 'draws_df' class as required metadata was removed.\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n# A tibble: 1 √ó 6\n  beta0 .lower .upper .width .point .interval\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1  32.2   25.6   39.0   0.95 mean   qi       \n\ndraws %&gt;% median_qi(beta0, .width = .80)        # median and 80% percentile interval\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\nWarning: Dropping 'draws_df' class as required metadata was removed.\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n# A tibble: 1 √ó 6\n  beta0 .lower .upper .width .point .interval\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1  32.2   27.8   36.7    0.8 median qi       \n\ndraws %&gt;% mode_hdi(beta0, .width = c(.5, .95))  # mode, with 95 and 50% HPDI's\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\nWarning: Dropping 'draws_df' class as required metadata was removed.\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n# A tibble: 2 √ó 6\n  beta0 .lower .upper .width .point .interval\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    \n1  32.0   29.9   34.5   0.5  mode   hdi      \n2  32.0   25.6   38.9   0.95 mode   hdi      \n\n\nAs an aside, the Mode() function we used a while back was also from tidybayes.\n\n\nSpaghetti plots.\nRemember how we said the draw was something like 4,000 separate equations for our Bayesian model? Let‚Äôs see that again.\n\ndraws %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  mutate(body_mass_g = mean(chinstrap$body_mass_g)) %&gt;% \n  # here's the equation\n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  # subset the top 6\n  head()\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n# A tibble: 6 √ó 5\n  .draw beta0   beta1 body_mass_g y_hat\n  &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1     1  37.6 0.00284       3733.  48.3\n2     2  35.7 0.00335       3733.  48.3\n3     3  32.5 0.00449       3733.  49.3\n4     4  43.3 0.00160       3733.  49.3\n5     5  31.3 0.00480       3733.  49.2\n6     6  30.9 0.00481       3733.  48.9\n\n\nOne way we might emphasize the 4,000 equations is with a spaghetti plot. When we display the fitted line for bill_length_mm over the range of body_mass_g values, we can display a single line for each posterior draw. Here‚Äôs what that can look like.\n\nrange(chinstrap$body_mass_g)\n\n[1] 2700 4800\n\n# Note: go through this one line at a time\ndraws %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  expand_grid(body_mass_g = range(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  # plot!\n  ggplot(aes(x = body_mass_g, y = y_hat, group = .draw)) +\n  geom_line(linewidth = 1/10, alpha = 1/10)\n\n\n\n\n\n\n\n\nIt might be easier to see what‚Äôs going on with a random subset of, say, 10 of the posterior draws.\n\nset.seed(10)\n\ndraws %&gt;% \n  # take a random sample of 10 rows\n  slice_sample(n = 10) %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  expand_grid(body_mass_g = range(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = body_mass_g, y = y_hat, group = .draw)) +\n  geom_line(linewidth = 1/2, alpha = 1/2)\n\n\n\n\n\n\n\n\nWhile we‚Äôre at it, let‚Äôs take 20 draws and do a little color coding.\n\nset.seed(20)\n\ndraws %&gt;% \n  # take a random sample of 20 rows\n  slice_sample(n = 20) %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  expand_grid(body_mass_g = range(chinstrap$body_mass_g)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  \n  ggplot(aes(x = body_mass_g, y = y_hat, group = .draw, color = beta0)) +\n  geom_line() +\n  scale_color_viridis_c(expression(beta[0]~(the~intercept)), end = .9)\n\n\n\n\n\n\n\n\nDo you remember how we said \\(\\beta_0\\) and \\(\\beta_1\\) had a strong negative correlation? Notice how the lines computed by lower \\(\\beta_0\\) values also tend to have higher slopes. This will happen all the time with conventional regression models.\n\n\nQuestion 2.5: We have done all this without yet specifying a prior. What do you think is going on?\nThe brms package assigns default priors (weakly informative priors) to all the parameters, even though we didn't specify any."
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#questionexercise",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#questionexercise",
    "title": "Bayes and Penguins",
    "section": "Question/Exercise:",
    "text": "Question/Exercise:\nIn the last part, we made a subset of the penguins data called gentoo, which was only the cases for which species == \"Gentoo\". Do that again and refit the Bayesian model to those data. Can you then remake some of the figures in this file with the new version of the model?\n\n# wrangle\nas_draws_df(fit2.b) %&gt;% \n  pivot_longer(starts_with(\"b_\")) %&gt;% \n  \n  # plot!\n  ggplot(aes(x = value)) + \n  # geom_density(fill = \"grey20\") +\n  geom_histogram(bins = 40) +\n  facet_wrap(~ name, scales = \"free\")\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\n\n\n\n\n\npairs(fit2.b)\n\n\n\n\n\n\n\n\n\ndraws2 &lt;- as_draws_df(fit2.b)\n\n# adjust the parameter names \ndraws2 &lt;- draws2 %&gt;% \n  mutate(beta0 = b_Intercept,\n         beta1 = b_body_mass_g)\n\ndraws2 %&gt;% \n  mutate(body_mass_g = mean(gentoo$body_mass_g, na.rm=TRUE)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  ggplot(aes(x = y_hat)) +\n  # note the changes to this line\n  stat_halfeye(point_interval = median_qi, .width = c(.5, .99)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(title = \"Bayesians have posterior distributions\",\n       subtitle = \"The dot marks the median.\\nThe thicker line marks the 50% interval, and\\nth thinner line marks the 99% interval.\")\n\n\n\n\n\n\n\npoints &lt;- draws2 %&gt;% \n  rename(`beta[0]` = beta0,\n         `beta[1]` = beta1) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  group_by(parameter) %&gt;% \n  summarise(mean = mean(value),\n            median = median(value),\n            mode = Mode(value)) %&gt;% \n  pivot_longer(starts_with(\"m\"), names_to = \"statistic\")\n\n\ndraws2 %&gt;% \n  rename(`beta[0]` = beta0,\n         `beta[1]` = beta1) %&gt;% \n  pivot_longer(cols = c(`beta[0]`, `beta[1]`, sigma), \n               names_to = \"parameter\") %&gt;% \n  ggplot(aes(x = value)) +\n  geom_density() +\n  geom_vline(data = points,\n             aes(xintercept = value, color = statistic),\n             size = 3/4) +\n  scale_color_viridis_d(option = \"A\", end = .8) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  xlab(\"parameter space\") +\n  facet_wrap(~ parameter, labeller = label_parsed, scales = \"free\", ncol = 1) +\n  theme(strip.text = element_text(size = 14))\n\n\n\n\n\n\n\nset.seed(20)\n\ndraws2 %&gt;% \n  # take a random sample of 20 rows\n  slice_sample(n = 20) %&gt;% \n  select(.draw, beta0, beta1) %&gt;% \n  expand_grid(body_mass_g = range(gentoo$body_mass_g, na.rm=TRUE)) %&gt;% \n  mutate(y_hat = beta0 + beta1 * body_mass_g) %&gt;% \n  ggplot(aes(x = body_mass_g, y = y_hat, group = .draw, color = beta0)) +\n  geom_line() +\n  scale_color_viridis_c(expression(beta[0]~(the~intercept)), end = .9)"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#references",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#references",
    "title": "Bayes and Penguins",
    "section": "References",
    "text": "References\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press. https://doi.org/10.1017/9781139161879\nKruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/\nMcElreath, R. (2015). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. https://xcelab.net/rm/statistical-rethinking/"
  },
  {
    "objectID": "posts/04-02 Bayes 1/Bayes_Lab_1.html#session-information",
    "href": "posts/04-02 Bayes 1/Bayes_Lab_1.html#session-information",
    "title": "Bayes and Penguins",
    "section": "Session information",
    "text": "Session information\n\nsessionInfo()\n\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] ggdist_3.3.2        broom.mixed_0.2.9.6 broom_1.0.7        \n [4] brms_2.22.0         Rcpp_1.0.14         ggside_0.3.1       \n [7] lubridate_1.9.4     forcats_1.0.0       stringr_1.5.1      \n[10] dplyr_1.1.4         purrr_1.0.4         readr_2.1.5        \n[13] tidyr_1.3.1         tibble_3.2.1        ggplot2_3.5.1      \n[16] tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.1     viridisLite_0.4.2    farver_2.1.2        \n [4] loo_2.8.0            fastmap_1.2.0        tensorA_0.36.2.1    \n [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n[10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.5      \n[13] magrittr_2.0.3       posterior_1.6.0      compiler_4.4.1      \n[16] rlang_1.1.4          tools_4.4.1          utf8_1.2.4          \n[19] yaml_2.3.10          knitr_1.49           labeling_0.4.3      \n[22] bridgesampling_1.1-2 htmlwidgets_1.6.4    curl_6.2.0          \n[25] pkgbuild_1.4.6       plyr_1.8.9           abind_1.4-8         \n[28] withr_3.0.2          grid_4.4.1           stats4_4.4.1        \n[31] xtable_1.8-4         colorspace_2.1-1     future_1.34.0       \n[34] inline_0.3.21        emmeans_1.10.7       globals_0.16.3      \n[37] scales_1.3.0         cli_3.6.3            mvtnorm_1.3-3       \n[40] rmarkdown_2.28       generics_0.1.3       RcppParallel_5.1.10 \n[43] rstudioapi_0.17.1    reshape2_1.4.4       tzdb_0.4.0          \n[46] rstan_2.32.6         splines_4.4.1        bayesplot_1.11.1    \n[49] parallel_4.4.1       matrixStats_1.5.0    vctrs_0.6.5         \n[52] V8_6.0.3             Matrix_1.7-0         jsonlite_1.8.8      \n[55] callr_3.7.6          hms_1.1.3            listenv_0.9.1       \n[58] glue_1.8.0           parallelly_1.42.0    ps_1.9.0            \n[61] codetools_0.2-20     distributional_0.5.0 stringi_1.8.4       \n[64] gtable_0.3.6         QuickJSR_1.5.2       palmerpenguins_0.1.1\n[67] munsell_0.5.1        pillar_1.10.1        furrr_0.3.1         \n[70] htmltools_0.5.8.1    Brobdingnag_1.2-9    R6_2.5.1            \n[73] evaluate_1.0.3       lattice_0.22-6       backports_1.5.0     \n[76] renv_1.0.7           rstantools_2.4.0     gridExtra_2.3       \n[79] coda_0.19-4.1        nlme_3.1-164         checkmate_2.3.2     \n[82] mgcv_1.9-1           xfun_0.51            pkgconfig_2.0.3"
  }
]