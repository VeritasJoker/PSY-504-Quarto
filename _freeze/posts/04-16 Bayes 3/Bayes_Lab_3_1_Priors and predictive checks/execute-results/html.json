{
  "hash": "b56987d0169a30f60d43833801655e23",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"PSY 504: Bayes Lab 3, Priors and Predictive Checks April 16th, 2025\"\nsubtitle: \"Princeton University\"\ndate: \"2025-04-16\"\nauthor: \"KW\"\ncategories: [code, analysis]\nformat:\n  html:\n    self-contained: false\n    anchor-sections: true\n    code-tools: true\n    code-fold: true\n    fig-width: 8\n    fig-height: 4\n    code-block-bg: \"#f1f3f5\"\n    code-block-border-left: \"#31BAE9\"\n    mainfont: Source Sans Pro\n    theme: journal\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    captions: true\n    cap-location: margin\n    table-captions: true\n    tbl-cap-location: margin\n    reference-location: margin\n  pdf:\n    pdf-engine: lualatex\n    toc: false\n    number-sections: true\n    number-depth: 2\n    top-level-division: section\n    reference-location: document\n    listings: false\n    header-includes:\n      \\usepackage{marginnote, here, relsize, needspace, setspace}\n      \\def\\it{\\emph}\nexecute:\n  freeze: auto\n  echo: true\n  message: false\n  warning: false\n  fig-align: center\n  fig-width: 12\n  fig-height: 8\n  editor_options: \n  chunk_output_type: inline\n  code-overflow: wrap\n  html:\n    code-fold: true\n    code-tools: true\neditor: visual\n---\n\n\n\\\nDuring the first Bayes Lab you considered exploratory data analysis, compared default brms with lm(), and extracted posteriors after fitting models. You summarized posterior distributions and also generated a distribution of predictions using these posterior draws.\\\n\\\nDuring the second Bayes lab, you looked at the different types of distributions that are relevant for Bayesian analysis, including priors.\n\nDuring today's lab, you will go into prior predictive checks and some HMC diagnostics. While we look at the simple linear modeling case, this workflow is relevant for all Bayesian models.\n\n## Setup: Packages and data\n\nLoad the primary packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n# library(truncnorm)  # if needed\n```\n:::\n\n\nThis time we'll be taking data from the **moderndive** package. We want the `evals` data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(evals, package = \"moderndive\")\n```\n:::\n\n\nThe `evals` data were originally in the paper by Hamermesh and Parker (2005; <https://doi.org/10.1016/j.econedurev.2004.07.013).> You can learn more about the data like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n?moderndive::evals\n```\n:::\n\n\nYou can learn even more information about the data from <https://www.openintro.org/data/index.php?data=evals.>\n\nAnyway, we need to subset the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevals94 <- evals %>% \n  group_by(prof_ID) %>% \n  slice(1) %>% \n  ungroup()\n\nglimpse(evals94)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 94\nColumns: 14\n$ ID           <int> 1, 5, 8, 10, 18, 24, 31, 36, 43, 50, 60, 63, 68, 75, 79, …\n$ prof_ID      <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ score        <dbl> 4.7, 4.6, 4.1, 4.5, 4.8, 4.4, 4.4, 3.4, 4.8, 4.0, 3.6, 4.…\n$ age          <int> 36, 59, 51, 40, 31, 62, 33, 51, 33, 47, 35, 37, 42, 49, 3…\n$ bty_avg      <dbl> 5.000, 3.000, 3.333, 3.167, 7.333, 5.500, 4.167, 4.000, 4…\n$ gender       <fct> female, male, male, female, female, male, female, female,…\n$ ethnicity    <fct> minority, not minority, not minority, not minority, not m…\n$ language     <fct> english, english, english, english, english, english, eng…\n$ rank         <fct> tenure track, tenured, tenured, tenured, tenure track, te…\n$ pic_outfit   <fct> not formal, not formal, not formal, not formal, not forma…\n$ pic_color    <fct> color, color, color, color, color, color, color, color, c…\n$ cls_did_eval <int> 24, 17, 55, 40, 42, 182, 33, 25, 48, 16, 18, 30, 28, 30, …\n$ cls_students <int> 43, 20, 55, 46, 48, 282, 41, 41, 60, 19, 25, 34, 40, 36, …\n$ cls_level    <fct> upper, upper, upper, upper, upper, upper, upper, upper, u…\n```\n\n\n:::\n:::\n\n\n## Intercept-only model\n\nLet's start by fitting an intercept-only model\n\n$$\n\\begin{align}\n\\text{bty\\_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 \\\\\n\\beta_0 & \\sim \\text{???} \\\\\n\\sigma & \\sim \\text{???},\n\\end{align} \n$$\n\nwhere $\\beta_0$ is the same as the unconditional population mean, and the population standard deviation is $\\sigma$. Our next task will be choosing our priors.\n\n#### Question 1: Why have we left some of the specification above unfilled / with questions marks at this point?\n\nBecause here $\\beta_0$ and $\\sigma$ are disributions, and we don't have a chosen prior distribution for them just yet.\n\n### Visualize possible prior distributions.\n\nIn this exercise, we'll choose the priors together. Let's start with prior on $\\beta_0$. Below are a few candidate distributions visualized with **ggdist** and friends.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(\n  prior(normal(5.5, 1)),\n  prior(normal(8, 2)),\n  prior(normal(5.5, 2))\n) %>% \n  parse_dist() %>% \n\n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye(point_interval = mean_qi, .width = c(.5, .95)) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  labs(subtitle = \"The red lines mark the lower and upper boundaries.\",\n       x = expression(italic(p)(beta[0])),\n      y = NULL)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-5-1.png){width=768}\n:::\n:::\n\n\nThe red lines in the figures (shown at x=1 and x=10) represent the lower and upper boundaries for the beauty ratings scale used in the study. With the simple intercept model, setting a prior on the intercept parameter is the same as setting a prior on the expected mean in observation space.\n\nNow let's visualize a few potential priors for $\\sigma$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(\n  prior(exponential(1)), \n  prior(normal(0, 1), lb = 0), \n  prior(normal(2, 0.3), lb = 0)\n) %>% \n  parse_dist() %>% \n  \n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye(point_interval = mean_qi, .width = c(.5, .95)) +\n  xlab(expression(italic(p)(sigma))) +\n  ylab(NULL)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-6-1.png){width=768}\n:::\n:::\n\n\n#### Question 2: Given that $\\sigma$ refers to the standard deviation, are these three priors theoretically possible? If yes, give an example of a theoretically impossible prior for $\\sigma$.\n\nYes, they should all be theoretically possible, since we only need $\\sigma$ to be bigger than 0, and all three priors satisfy that.\n\nA theoretically impossible prior would be a normal distribution with mean 0 and standard deviation 1, but not having a left bound and cutoff at 0.\n\n\n### Prior-predictive checks (by hand).\n\nNote: It's possible we'll need the `truncnorm::rtruncnorm()` function in this section. Once we have candidate priors for both $\\beta_0$ and $\\sigma$, we can simulate values from those priors and plot the implied distributions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# how many distributions do you want?\nn <- 50\n\n# do you want to make the simulation reproducible?\n# set.seed(1)\n\n# simulate values from the priors\ntibble(iter = 1:n,\n       # choose the hyperparameter values with the class\n       beta0 = rnorm(n = n, mean = 5.5, sd = 1),\n       sigma = rexp(n = n, rate = 1 / 1)) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  mutate(density = dnorm(x = bty_avg, mean = beta0, sd = sigma)) %>% \n  \n  # plot!\n  ggplot(aes(x = bty_avg, y = density, group = iter)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~and~italic(p)(sigma)))\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-7-1.png){width=768}\n:::\n:::\n\n\nThe simulated values constitute predictions that are made using our prior beliefs (a prior is set for beta0 and another for sigma) When you check if these predictions (prior predictive) make sense or not, it is called the prior predictive check. The point of the prior predictive check is to iterate on specifying the priors until the prior predictive is sensible/satisfactory.\n\n(Again, the red boundaries denote that the only possible bty_avg values are between 1 and 10.)\n\n#### Question 3: Can Explain what the section of the previous command, before ggplot is doing?\n\nThe code first sets the number of draws to 50. Then creates a tibble with 50 rows, where each row is a simulated $\\beta$ and $\\sigma$. Then we attach a column `bty_avg` that ranges from –2 to 13 with step 0.025 for every draw, making the tibble 30,050 rows. Then for each `bty_avg` value, we calculate the density of the normal distribution given each $\\beta$ and $\\sigma$. Then we plot the 50 density plots for the 50 distributions.\n\n\n#### Question 4: The prior predictive above is for one combination of our candidate priors. Why don't you also try the $\\beta_0$ prior centered at 8, along with the $\\sigma$ prior centered at 2? What do you observe? Among these two , which would you pick? And why? (Optional: try others too if you'd like)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# how many distributions do you want?\nn <- 50\n\n# do you want to make the simulation reproducible?\n# set.seed(1)\n\n# simulate values from the priors\ntibble(iter = 1:n,\n       # choose the hyperparameter values with the class\n       beta0 = rnorm(n = n, mean = 8, sd = 2),\n       sigma = rnorm(n = n, mean = 2, sd = 0.3)) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  mutate(density = dnorm(x = bty_avg, mean = beta0, sd = sigma)) %>% \n  \n  # plot!\n  ggplot(aes(x = bty_avg, y = density, group = iter)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~and~italic(p)(sigma)))\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-8-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(truncnorm)\n# how many distributions do you want?\nn <- 50\n\n# do you want to make the simulation reproducible?\n# set.seed(1)\n\n# simulate values from the priors\ntibble(iter = 1:n,\n       # choose the hyperparameter values with the class\n       beta0 = rnorm(n = n, mean = 5.5, sd = 2),\n       sigma = rtruncnorm(n = n, a = 0, mean = 0, sd = 1))  %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  mutate(density = dnorm(x = bty_avg, mean = beta0, sd = sigma)) %>% \n  \n  # plot!\n  ggplot(aes(x = bty_avg, y = density, group = iter)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~and~italic(p)(sigma)))\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-9-1.png){width=768}\n:::\n:::\n\n\nThe $\\beta_0$ prior centered at 8 with the $\\sigma$ prior centered at 2 has a much wider density plot. I don't like how it's centered around 8 though. I also tried a third one, where the $\\beta_0$ prior is centered at 5.5 with an sd of 2, and the $\\sigma$ prior is a truncated normal distribution of mean 0 and sd 1. I think I would prefer the first one, since all the density plots are within the lower and upper boundaries.\n\n\n### Fit the model that you prefer\n\nWe should practice writing out our model equation with our priors of choice:\n\n$$\n\\begin{align}\n\\text{bty\\_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 \\\\\n\\beta_0 & \\sim \\text{Normal}(5.5,\\,1) \\\\\n\\sigma & \\sim \\text{Exponential}(1).\n\\end{align}\n$$\n\nLet's fit a model with our priors of choice.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit9.b = brm(\n  data = evals94,\n  family = gaussian,\n  bty_avg ~ 1,\n  # make sure we're settled on our priors \n  # we don't need to use these; they're placeholders\n  prior = prior(normal(5.5, 1), class = Intercept) +\n    prior(exponential(1), class = sigma)\n)\n```\n:::\n\n\nCheck the model summary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit9.b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 1 \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     4.62      0.17     4.30     4.95 1.00     3636     2922\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.60      0.12     1.39     1.84 1.00     3769     2947\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nNow we might do a posterior predictive check to see how well our model describes the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit9.b, ndraws = 100) +\n  ggtitle(\"posterior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-11-1.png){width=768}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit9.b, ndraws = 8,\n         type = \"hist\", binwidth = 0.5) +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\")  +\n  ggtitle(\"posterior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-11-2.png){width=768}\n:::\n:::\n\n\nOur simple Gaussian model doesn't do a great job respecting the lower and upper boundaries, but this is about as good as it gets when you're in Gaussian land. On the whole, the model did a pretty okay reproducing the gross features of the distribution of the sample data.\n\n#### Question 5: To ensure you've understood things well, can you write below about the difference between the prior predictive check and the posterior predictive check? How do they differ in their objectives?\n\nThe prior predictive check draws from the prior distributions. It is used to evaluate prior plausibility and can help detect unrealistic priors or unreasonable model behavior early in the modeling process.\n\nThe posterior predictive checks draws from the posterior distributions. It is used to check for model fit, as it takes into account both the data and the prior.\n\n\n## Prior-predictive checks (by `sample_prior = \"only\"`)\n\nWe can also sample from the prior predictive distribution from `brm()` itself. To do so, we use the `sample_prior` argument, which has the following options:\n\n-   `\"no\"`, which is the default, and does not sample from the prior;\n-   `\"yes\",`, which will sample from both the prior and the posterior; and\n-   `\"only\"`, which will only sample from the prior.\n\nLet's set `sample_prior = \"only\"`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check to see if we want to use other priors\n\nfit10.b = brm(\n  data = evals94,\n  family = gaussian,\n  bty_avg ~ 1,\n  prior = prior(normal(5.5, 1), class = Intercept) +\n    prior(exponential(1), class = sigma),\n  # here's the magic\n  sample_prior = \"only\",\n  # we can set our seed, too!\n  seed = 1\n)\n```\n:::\n\n\nDid you notice how we used the `seed` argument? This makes the results reproducible.\n\nNow the `summary()` function only returns summaries for the priors, NOT the posterior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit10.b)  # this summarizes the prior\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 1 \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     5.49      1.00     3.49     7.45 1.00     2076     2255\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.98      0.97     0.03     3.50 1.00     2029     1418\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nThe `as_draws_df()` function also returns draws from the prior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas_draws_df(fit10.b) %>% \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A draws_df: 6 iterations, 1 chains, and 5 variables\n  b_Intercept sigma Intercept lprior lp__\n1         4.2  1.08       4.2   -2.8 -2.7\n2         6.1  0.99       6.1   -2.1 -2.1\n3         5.8  0.99       5.8   -2.0 -2.0\n4         6.2  0.46       6.2   -1.6 -2.4\n5         6.2  0.49       6.2   -1.7 -2.4\n6         6.0  0.23       6.0   -1.3 -2.8\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n\n\n:::\n:::\n\n\nHere's how we might use that `as_draws_df()` output to make a similar plot to the one we made before.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# how many distributions do you want?\nn <- 50\n\n# do you want to make the results reproducible?\n# set.seed(1)\n\nas_draws_df(fit10.b) %>% \n  \n  # subset\n  slice_sample(n = n) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  # notice we're defining the mean by b_Intercept\n  mutate(density = dnorm(x = bty_avg, mean = b_Intercept, sd = sigma)) %>% \n  \n  ggplot(aes(x = bty_avg, y = density, \n             # notice we're grouping by .draw\n             group = .draw)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~and~italic(p)(sigma)))\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-14-1.png){width=768}\n:::\n:::\n\n\nWe can also use functions like `pp_check()` to compare the prior to the sample data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit10.b, ndraws = 100) +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit10.b, ndraws = 8,\n         type = \"hist\", binwidth = 0.5) +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-15-2.png){width=768}\n:::\n:::\n\n\n## Univariable predictor model\n\nNow we'll add `gender` as the sole predictor in the model,\n\n$$\n\\begin{align}\n\\text{bty_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{gender}_i \\\\\n\\beta_0 & \\sim \\text{???} \\\\\n\\beta_1 & \\sim \\text{???} \\\\\n\\sigma & \\sim \\text{???}.\n\\end{align}\n$$\n\nLet's try these same set of $\\beta_0$ priors\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# change as needed\n\nc(\n  prior(normal(5.5, 1)),\n  prior(normal(7, 0.5)),\n  prior(normal(5.5, 2))\n) %>% \n  parse_dist() %>% \n  \n  ggplot(aes(xdist = .dist_obj, y = prior)) + \n  stat_halfeye(point_interval = mean_qi, .width = c(.5, .95)) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  labs(subtitle = \"The red lines mark the lower and upper bondaries.\",\n       x = expression(italic(p)(beta[0])),\n      y = NULL)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n\nNow we update our by-hand prior predictive simulation to accomodate $\\beta_0$ and $\\beta_1$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 50\n\nset.seed(1)\n\ntibble(iter = 1:n,\n       beta0 = rnorm(n = n, mean = 5.5, sd = 1),\n       # notice our new line\n       beta1 = rnorm(n = n, mean = 0, sd = 1),\n       sigma = rexp(n = n, rate = 1 / 1)) %>% \n  # we have a new expand_grid() line\n  # make sure everyone understands this coding scheme\n  expand_grid(gendermale = 0:1) %>% \n  expand_grid(bty_avg = seq(from = -2, to = 13, by = 0.025)) %>% \n  # notice the updated mean formula\n  mutate(density = dnorm(x = bty_avg, \n                         mean = beta0 + beta1 * gendermale, \n                         sd = sigma)) %>% \n  \n  # plot!\n  ggplot(aes(x = bty_avg, y = density, group = iter)) +\n  geom_line(linewidth = 1/3, alpha = 1/2) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  labs(subtitle = expression(\"Prior predictive distributions based on \"*italic(p)(beta[0])~ and~italic(p)(beta[1])~and~italic(p)(sigma))) +\n  facet_wrap(~ gendermale, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-17-1.png){width=768}\n:::\n:::\n\n\nBefore we fit the model, let's practice the `sample_prior = \"only\"` approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check to see if we want to use other priors\n\nfit11.b = brm(\n  data = evals94,\n  family = gaussian,\n  # notice the 0 + Intercept syntax\n  bty_avg ~ 0 + Intercept + gender,\n  prior = prior(normal(5.5, 1), class = b, coef = Intercept) +\n    prior(normal(0, 1), class = b, coef = gendermale) +\n    prior(exponential(1), class = sigma),\n  # here's the magic\n  sample_prior = \"only\",\n  seed = 2\n)\n```\n:::\n\n\nCheck the prior summary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit11.b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 0 + Intercept + gender \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      5.49      0.98     3.58     7.40 1.00     3315     2688\ngendermale    -0.02      1.00    -1.93     1.90 1.00     3354     2634\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.00      1.00     0.03     3.55 1.00     2186     1435\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nCompare the prior with the data with `pp_check()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit11.b, \n         type = \"dens_overlay_grouped\",\n         group = \"gender\",\n         ndraws = 100) +\n  coord_cartesian(xlim = c(-1, 12),\n                  ylim = c(0, 3)) +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-19-1.png){width=768}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit11.b, ndraws = 5,\n         type = \"freqpoly_grouped\", group = \"gender\") +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-19-2.png){width=768}\n:::\n:::\n\n\nThere isn't a great grouped histogram option for `pp_check()`, so we experimented with `type = \"freqpoly_grouped\"` instead.\n\nIf we wanted, we could also use the `predict()` function to simulate `bty_avg` values from the priors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# walk through this slowly\n\nset.seed(1)\n\npredict(fit11.b,\n        summary = FALSE,\n        ndraws = 5) %>% \n  str()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n num [1:5, 1:94] 4.1 7.4 2.61 6.32 6.22 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : NULL\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# customize the predictor grid, as desired\nnd <- tibble(gender = rep(c(\"female\", \"male\"), each = 50)) %>% \n  # this will make it easier to connect the nd data to the predict() output\n  mutate(row = 1:n())\n\nset.seed(1)\n\npredict(fit11.b,\n        newdata = nd,\n        summary = FALSE,\n        ndraws = 5) %>% \n  data.frame() %>% \n  mutate(draw = 1:n()) %>% \n  pivot_longer(-draw) %>% \n  mutate(row = str_remove(name, \"X\") %>% as.double()) %>% \n  left_join(nd, by = \"row\") %>% \n  \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = 0.5, boundary = 1) +\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  facet_grid(draw ~ gender, labeller = label_both)\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-21-1.png){width=768}\n:::\n:::\n\n\nOnce we've settled on our priors, we should once again practice writing out the full model equation:\n\n$$\n\\begin{align}\n\\text{bty_avg}_i & \\sim \\operatorname{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i & = \\beta_0 + \\beta_1 \\text{gender}_i \\\\\n\\beta_0 & \\sim \\text{Normal}(5.5,1) \\\\\n\\beta_1 & \\sim \\text{Normal}(0,1) \\\\\n\\sigma & \\sim \\text{Exponential}(1).\n\\end{align}\n$$\n\nOkay, let's fit the real model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check to see if we want to use other priors\n\nfit12.b = brm(\n  data = evals94,\n  family = gaussian,\n  bty_avg ~ 0 + Intercept + gender,\n  prior = prior(normal(5.5, 1), class = b, coef = Intercept) +\n    prior(normal(0, 1), class = b, coef = gendermale) +\n    prior(exponential(1), class = sigma),\n  \n  # yes, you can set your seed for your posteriors, too\n  # this makes the results reproducible\n  seed = 3\n)\n```\n:::\n\n\nCheck the model summary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit12.b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: bty_avg ~ 0 + Intercept + gender \n   Data: evals94 (Number of observations: 94) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      4.93      0.24     4.46     5.39 1.00     2151     1978\ngendermale    -0.55      0.31    -1.18     0.06 1.00     2219     2156\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     1.58      0.12     1.38     1.83 1.00     2709     2289\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nHow does the posterior-predictive check look?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\npp_check(fit12.b, \n         type = \"dens_overlay_grouped\",\n         group = \"gender\",\n         ndraws = 100) +\n  coord_cartesian(xlim = c(-1, 12)) +\n  ggtitle(\"posterior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-23-1.png){width=768}\n:::\n\n```{.r .cell-code}\nset.seed(2)\npp_check(fit12.b, ndraws = 5,\n         type = \"freqpoly_grouped\", group = \"gender\") +\n  # yes, we can add our red lines to our pp-check\n  geom_vline(xintercept = c(1, 10), color = \"red\") +\n  ggtitle(\"prior predictive check\")\n```\n\n::: {.cell-output-display}\n![](Bayes_Lab_3_1_Priors-and-predictive-checks_files/figure-html/unnamed-chunk-23-2.png){width=768}\n:::\n:::\n\n\n#### Question 6: Does the posterior predictive check look satsifactory to you?\n\nThe posterior predictive check look alright. The spread of $y$ for both male and female is quite decently captured by the $y_{rep}$ draws. However, the model still does not respect the upper and lower boundaries sometimes.\n\n\n::: callout-note\nFor more on prior predictive checks, see McElreath (from Chapter 4), and Solomon Kurz's brms/tidverse implementations as well.\n\nFor a comprehensive guide to set priors for a given situation, look at reccomendations made by the Stan team https://github.com/stan-dev/stan/wiki/prior-choice-recommendations\n\nThey generally recommend against uniform priors on $\\beta$ and $\\sigma$ parameters. This is based on a general principle that you should not use a prior that places an artificial boundary on a parameter.\n\nE.g. $\\sigma$ parameters have natural lower boundaries at zero, but they don't have upper boundaries. Thus, a uniform prior adds an unnatural upper boundary. A better prior would be something that is weakly informative\n:::\n\n## References\n\nHamermesh, D. S., & Parker, A. (2005). Beauty in the classroom: Instructors' pulchritude and putative pedagogical productivity. *Economics of Education Review, 24*(4), 369-376. https://doi.org/10.1016/j.econedurev.2004.07.013\n\nKurz, A. S. (2023). *Statistical Rethinking with brms, ggplot2, and the tidyverse: Second Edition* (version 0.4.0). https://bookdown.org/content/4857/\n\nMcElreath, R. (2020). *Statistical rethinking: A Bayesian course with examples in R and Stan* (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/\n\n## Session information\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-apple-darwin20\nRunning under: macOS 15.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n [1] truncnorm_1.0-9 tidybayes_3.0.7 brms_2.22.0     Rcpp_1.0.14    \n [5] lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1   dplyr_1.1.4    \n [9] purrr_1.0.4     readr_2.1.5     tidyr_1.3.1     tibble_3.2.1   \n[13] ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] svUnit_1.0.6         tidyselect_1.2.1     farver_2.1.2        \n [4] loo_2.8.0            fastmap_1.2.0        tensorA_0.36.2.1    \n [7] digest_0.6.37        estimability_1.5.1   timechange_0.3.0    \n[10] lifecycle_1.0.4      StanHeaders_2.32.10  processx_3.8.5      \n[13] magrittr_2.0.3       posterior_1.6.0      compiler_4.4.1      \n[16] rlang_1.1.4          tools_4.4.1          yaml_2.3.10         \n[19] knitr_1.49           labeling_0.4.3       bridgesampling_1.1-2\n[22] htmlwidgets_1.6.4    pkgbuild_1.4.6       curl_6.2.0          \n[25] plyr_1.8.9           abind_1.4-8          withr_3.0.2         \n[28] numDeriv_2016.8-1.1  grid_4.4.1           stats4_4.4.1        \n[31] xtable_1.8-4         colorspace_2.1-1     inline_0.3.21       \n[34] emmeans_1.10.7       scales_1.3.0         cli_3.6.3           \n[37] mvtnorm_1.3-3        rmarkdown_2.28       generics_0.1.3      \n[40] RcppParallel_5.1.10  rstudioapi_0.17.1    reshape2_1.4.4      \n[43] tzdb_0.4.0           rstan_2.32.6         bayesplot_1.11.1    \n[46] parallel_4.4.1       matrixStats_1.5.0    vctrs_0.6.5         \n[49] V8_6.0.3             Matrix_1.7-0         jsonlite_1.8.8      \n[52] callr_3.7.6          hms_1.1.3            arrayhelpers_1.1-0  \n[55] ggdist_3.3.2         glue_1.8.0           codetools_0.2-20    \n[58] ps_1.9.0             distributional_0.5.0 stringi_1.8.4       \n[61] gtable_0.3.6         QuickJSR_1.5.2       munsell_0.5.1       \n[64] pillar_1.10.1        htmltools_0.5.8.1    Brobdingnag_1.2-9   \n[67] R6_2.5.1             evaluate_1.0.3       lattice_0.22-6      \n[70] backports_1.5.0      renv_1.0.7           rstantools_2.4.0    \n[73] coda_0.19-4.1        gridExtra_2.3        nlme_3.1-164        \n[76] checkmate_2.3.2      xfun_0.51            pkgconfig_2.0.3     \n```\n\n\n:::\n:::\n",
    "supporting": [
      "Bayes_Lab_3_1_Priors-and-predictive-checks_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}